\subsection{Semantic landscape of the literature (TF-IDF)}

A primary semantic analysis was performed to assess the relevance of each article to the research objectives. To identify domain-specific terminology during screening and curation, TF-IDF (Term Frequency-Inverse Document Frequency) scores were calculated for all words and phrases found in article titles and abstracts. This analysis was conducted at multiple levels: for the full corpus, for the selected set of articles, with generic AI/ML phrase filtering, and using a context-preserving fine-tuned approach (full methods, detailed results, and visualizations are in Appendix~\ref{sec:tfidf_methods} and Supplementary Figures~\ref{SF1}â€“\ref{SF5}). This helped highlight key terms related to genetics, hereditary diseases, and LLMs. The identified phrases were grouped into three semantic categories:

% [Rest of your original methods text continues here...]

TF-IDF profiling showed a consistent progression from generic to domain-specific themes (Supplementary Figure~\ref{SF1}). In the full corpus ($51{,}613$ articles; SF~\ref{SF1}~A), generic phrases such as "language models", "large language", and "artificial intelligence" dominated, confirming broad field coverage prior to curation. The curated set (195 articles; SF~\ref{SF1}~B) preserved these anchors and surfaced domain cues (e.g., "precision medicine"): evidence that selection retained the core landscape. After removing generic AI/ML phrases (SF~\ref{SF1}~C, SF~\ref{SF3}), specific trends emerged, including "precision medicine", "gene expression", "open source", and "genetic testing", alongside disease-focused ("breast cancer", "alzheimer disease"), resource-oriented ("human phenotype ontology"), and technique-oriented ("attention mechanism", "single cell") terms.

A context-preserving fine-tuned analysis was performed to address potential concerns about removing AI/ML terminology (Supplementary Figure~\ref{SF5}). This approach first trained the TF-IDF model on the curated dataset with full vocabulary, then applied post-hoc reweighting to down-weight generic terms while preserving semantic relationships. The fine-tuned analysis confirmed that domain-specific trends remain stable across different filtering strategies, validating our findings.

Source comparisons (Supplementary Figures~\ref{SF2}, \ref{SF3}, \ref{SF5}) further clarified complementarity. Before filtering, PubMed ($n=131$) and preprints ($n=64$) shared $57\%$ of top phrases ($17/30$), indicating strong consensus on core topics. After filtering, overlap dropped to $23\%$ ($7/30$), revealing distinct emphases (Supplementary Figure~\ref{SF3}). The fine-tuned analysis showed similar patterns with $23\%$ overlap ($7/30$), confirming the robustness of these findings.

PubMed leaned clinical and translational ("precision medicine", "genetic testing"; established disease terms), whereas preprints highlighted emerging computational motifs ("gene expression", "open source", "attention mechanism") and method-forward phrasing. Many key terms from both technical and biological domains ranked highly in preprints but were absent from PubMed, supporting our dual-source strategy and underscoring that inclusion of preprints offers a more comprehensive view of the field.

Topic modeling further revealed the semantic structure of the literature (Supplementary Figure~\ref{SF4}). Eight latent topics were extracted using Latent Dirichlet Allocation, capturing distinct research themes from clinical variant interpretation to computational method development. The topic overlap visualization demonstrates how different research areas interconnect, with some topics (e.g., clinical diagnostics and precision medicine) closely related while others (e.g., protein structure prediction and variant calling) occupy distinct semantic spaces.
