 ,title,abstract,ref,source,review,relevance,code,what section used,subgroup,ai_topic,medicine_topic,notes,not_relevant,partly_relevant,relevant
2,Addressing the Gaps in Early Dementia Detection: A Path Towards Enhanced Diagnostic Models through Machine Learning,"The rapid global aging trend has led to an increase in dementia cases, including Alzheimer's disease, underscoring the urgent need for early and accurate diagnostic methods. Traditional diagnostic techniques, such as cognitive tests, neuroimaging, and biomarker analysis, face significant limitations in sensitivity, accessibility, and cost, particularly in the early stages. This study explores the potential of machine learning (ML) as a transformative approach to enhance early dementia detection by leveraging ML models to analyze and integrate complex multimodal datasets, including cognitive assessments, neuroimaging, and genetic information. A comprehensive review of existing literature was conducted to evaluate various ML models, including supervised learning, deep learning, and advanced techniques such as ensemble learning and transformer models, assessing their accuracy, interpretability, and potential for clinical integration. The findings indicate that while ML models show significant promise in improving diagnostic precision and enabling earlier interventions, challenges remain in their generalizability, interpretability, and ethical deployment. This research concludes by outlining future directions aimed at enhancing the clinical utility of ML models in dementia detection, emphasizing interdisciplinary collaboration and ethically sound frameworks to improve early detection and intervention strategies for Alzheimer's disease and other forms of dementia",moya2024addressinggapsearlydementia,arXiv,1,2,0,intro: rev,specific,,early demencia detection,,FALSE,FALSE,TRUE
3,Artificial intelligence in clinical genetics,"Artificial intelligence (AI) has been growing more powerful and accessible, and will increasingly impact many areas, including virtually all aspects of medicine and biomedical research. This review focuses on previous, current, and especially emerging applications of AI in clinical genetics. Topics covered include a brief explanation of different general categories of AI, including machine learning, deep learning, and generative AI. After introductory explanations and examples, the review discusses AI in clinical genetics in three main categories: clinical diagnostics; management and therapeutics; clinical support. The review concludes with short, medium, and long-term predictions about the ways that AI may affect the field of clinical genetics. Overall, while the precise speed at which AI will continue to change clinical genetics is unclear, as are the overall ramifications for patients, families, clinicians, researchers, and others, it is likely that AI will result in dramatic evolution in clinical genetics. It will be important for all those involved in clinical genetics to prepare accordingly in order to minimize the risks and maximize benefits related to the use of AI in the field",Duong2025-xi,PubMed,1,2,0,intro: rev,,,clinical genetics,,FALSE,FALSE,TRUE
10,Attention mechanism models for precision medicine,"The development of deep learning models plays a crucial role in advancing precision medicine. These models enable personalized medical treatments and interventions based on the unique genetic, environmental and lifestyle factors of individual patients, and the promotion of precision medicine is achieved mainly through genomic data analysis, variant annotation and interpretation, pharmacogenomics research, biomarker discovery, disease typing, clinical decision support and disease mechanism interpretation. Extensive research has been conducted to address precision medicine challenges using attention mechanism models such as SAN, GAT and transformers. Especially, the recent popularity of ChatGPT has significantly propelled the application of this model type to a new height. Therefore, I propose a Special Issue for Briefings in Bioinformatics about the topic 'Attention Mechanism Models for Precision Medicine'. This Special Issue aims to provide a comprehensive overview and presentation of innovative researches on the application of graph attention mechanism models in precision medicine",10.1093/bib/bbae156,PubMed,1,2,0,intro: rev,general,"SAN, GAT, transformers, other",Attention Mechanism Models for Precision Medicine: overview and presentation of innovative researches on the application of graph attention mechanism models in precision medicine,,FALSE,FALSE,TRUE
4,Bioinformatics and Biomedical Informatics with ChatGPT: Year One Review,"The year 2023 marked a significant surge in the exploration of applying large language model chatbots, notably Chat Generative Pre-trained Transformer (ChatGPT), across various disciplines. We surveyed the application of ChatGPT in bioinformatics and biomedical informatics throughout the year, covering omics, genetics, biomedical text mining, drug discovery, biomedical image understanding, bioinformatics programming, and bioinformatics education. Our survey delineates the current strengths and limitations of this chatbot in bioinformatics and offers insights into potential avenues for future developments
==========
The year 2023 marked a significant surge in the exploration of applying large language model (LLM) chatbots, notably ChatGPT, across various disciplines. We surveyed the applications of ChatGPT in bioinformatics and biomedical informatics throughout the year, covering omics, genetics, biomedical text mining, drug discovery, biomedical image understanding, bioinformatics programming, and bioinformatics education. Our survey delineates the current strengths and limitations of this chatbot in bioinformatics and offers insights into potential avenues for future developments",wang2024bioinformaticsbiomedicalinformaticschatgpt,"arXiv,PubMed",1,2,0,intro: rev,chatgpt,ChatGPT; systematic review,"Broad applications of LLMs in biomedical domains (omics, genetics, drug discovery).","Reviews ChatGPT's applications in bioinformatics, highlighting both strengths and limitations in diverse biomedical tasks.",FALSE,FALSE,TRUE
5,Chatbot Artificial Intelligence for Genetic Cancer Risk Assessment and Counseling: A Systematic Review and Meta-Analysis,"Most individuals with a hereditary cancer syndrome are unaware of their genetic status to underutilization of hereditary cancer risk assessment. Chatbots, or programs that use artificial intelligence to simulate conversation, have emerged as a promising tool in health care and, more recently, as a potential tool for genetic cancer risk assessment and counseling. Here, we evaluated the existing literature on the use of chatbots in genetic cancer risk assessment and counseling. A systematic review was conducted using key electronic databases to identify studies which use chatbots for genetic cancer risk assessment and counseling. Eligible studies were further subjected to meta-analysis. Seven studies met inclusion criteria, evaluating five distinct chatbots. Three studies evaluated a chatbot that could perform genetic cancer risk assessment, one study evaluated a chatbot that offered patient counseling, and three studies included both functions. The pooled estimated completion rate for the genetic cancer risk assessment was 36.7% (95% CI, 14.8 to 65.9). Two studies included comprehensive patient characteristics, and none involved a comparison group. Chatbots varied as to the involvement of a health care provider in the process of risk assessment and counseling. Chatbots have been used to streamline genetic cancer risk assessment and counseling and hold promise for reducing barriers to genetic services. Data regarding user and nonuser characteristics are lacking, as are data regarding comparative effectiveness to usual care. Future research may consider the impact of chatbots on equitable access to genetic services",Webster2023-of,PubMed,1,2,0,intro: rev,specific,,,,FALSE,FALSE,TRUE
6,"ChatGPT in action: Harnessing artificial intelligence potential and addressing ethical challenges in medicine, education, and scientific research","Artificial intelligence (AI) tools, like OpenAI's Chat Generative Pre-trained Transformer (ChatGPT), hold considerable potential in healthcare, academia, and diverse industries. Evidence demonstrates its capability at a medical student level in standardized tests, suggesting utility in medical education, radiology reporting, genetics research, data optimization, and drafting repetitive texts such as discharge summaries. Nevertheless, these tools should augment, not supplant, human expertise. Despite promising applications, ChatGPT confronts limitations, including critical thinking tasks and generating false references, necessitating stringent cross-verification. Ensuing concerns, such as potential misuse, bias, blind trust, and privacy, underscore the need for transparency, accountability, and clear policies. Evaluations of AI-generated content and preservation of academic integrity are critical. With responsible use, AI can significantly improve healthcare, academia, and industry without compromising integrity and research quality. For effective and ethical AI deployment, collaboration amongst AI developers, researchers, educators, and policymakers is vital. The development of domain-specific tools, guidelines, regulations, and the facilitation of public dialogue must underpin these endeavors to responsibly harness AI's potential",Jeyaraman2023-dg,PubMed,1,2,0,intro: rev,chatgpt,,,,FALSE,FALSE,TRUE
41,Identifying Health Risks from Family History: A Survey of Natural Language Processing Techniques,"Electronic health records include information on patients' status and medical history, which could cover the history of diseases and disorders that could be hereditary. One important use of family history information is in precision health, where the goal is to keep the population healthy with preventative measures. Natural Language Processing (NLP) and machine learning techniques can assist with identifying information that could assist health professionals in identifying health risks before a condition is developed in their later years, saving lives and reducing healthcare costs.   We survey the literature on the techniques from the NLP field that have been developed to utilise digital health records to identify risks of familial diseases. We highlight that rule-based methods are heavily investigated and are still actively used for family history extraction. Still, more recent efforts have been put into building neural models based on large-scale pre-trained language models. In addition to the areas where NLP has successfully been utilised, we also identify the areas where more research is needed to unlock the value of patients' records regarding data collection, task formulation and downstream applications",dai2024identifyinghealthrisksfamily,arXiv,1,2,0,intro: rev,not_llm,NLP techniques (rule-based and neural models); ML Task: Extracting family history and health risks from electronic health records (EHR).,Risk identification for hereditary diseases using patient family history.,"Surveys NLP methods for extracting family history, emphasizing neural models over rule-based methods.",FALSE,FALSE,TRUE
7,Innovations in Medicine: Exploring ChatGPT's Impact on Rare Disorder Management,"Artificial intelligence (AI) is rapidly transforming the field of medicine, announcing a new era of innovation and efficiency. Among AI programs designed for general use, ChatGPT holds a prominent position, using an innovative language model developed by OpenAI. Thanks to the use of deep learning techniques, ChatGPT stands out as an exceptionally viable tool, renowned for generating human-like responses to queries. Various medical specialties, including rheumatology, oncology, psychiatry, internal medicine, and ophthalmology, have been explored for ChatGPT integration, with pilot studies and trials revealing each field's potential benefits and challenges. However, the field of genetics and genetic counseling, as well as that of rare disorders, represents an area suitable for exploration, with its complex datasets and the need for personalized patient care. In this review, we synthesize the wide range of potential applications for ChatGPT in the medical field, highlighting its benefits and limitations. We pay special attention to rare and genetic disorders, aiming to shed light on the future roles of AI-driven chatbots in healthcare. Our goal is to pave the way for a healthcare system that is more knowledgeable, efficient, and centered around patient needs",genes15040421,PubMed,1,2,0,intro: rev,chatgpt,ChatGPT; review,Managing rare genetic disorders through AI-driven chatbots like ChatGPT.,"Explores the potential and challenges of using ChatGPT in rare genetic disorder management, highlighting its benefits in personalized care. (Limited to just chatGPT, what about other models/methods!!!!!)",FALSE,FALSE,TRUE
274,Leveraging Large Language Models in Gynecologic Oncology: A Systematic Review of Current Applications and Challenges,"Rationale and ObjectivesOver the past year, studies have been conducted to evaluate the performance of Large Language Models (LLMs), such as ChatGPT, in the fields of gynecologic oncology. This review aims to analyze the applications and risks associated with using LLMs in this specialized field.  Materials and MethodsThis systematic review was performed in adherence to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, incorporating elements from the diagnostic test accuracy extension and the CHARMS checklist for reviews of prediction models. A systematic literature search was executed on July 17, 2024, across PubMed, Web of Science, and Scopus databases. We focused on identifying original research that integrates LLMs with gynecologic oncology. We assessed the risk of bias using the adapted QUADAS-2 criteria.  ResultsOur search identified eight studies that met our criteria, focusing on healthcare education, clinical practice, and medical code generation. These studies revealed variability in ChatGPTs performance across different applications. It excelled in genetic testing and counseling, achieving 97% accuracy rate. However, its performance in cervical cancer prevention was less robust, with an accuracy of 83%. While one study demonstrated ChatGPTs high adherence to quality guidelines, another noted that established guidelines significantly outperformed ChatGPTs outputs. Additionally, code generation using tools like Google Bard and RoBERTa have shown potential to improve accuracy in clinical predictions and quality assurance. For example, Natural Language Processing (NLP) assisted by RoBERTa (based on Googles BERT model) has improved the prediction of residual disease in women with advanced epithelial ovarian cancer following cytoreductive surgery. Despite these advancements, challenges related to consistency, specificity, and personalization persist, underscoring the necessity for continuous enhancement of these technologies.  ConclusionLLMs demonstrate inconsistent performance in gynecologic oncology. These findings emphasize the need for continuous evaluation of these models before they are implemented clinically",Mudrik2024.08.08.24311699,medrxiv,1,2,0,intro: rev,specific,,,,FALSE,FALSE,TRUE
286,Natural Language Processing and Schizophrenia: A Scoping Review of Uses and Challenges,"(1) Background: Approximately 1% of the global population is affected by schizophrenia, a disorder marked by cognitive deficits, delusions, hallucinations, and language issues. It is associated with genetic, neurological, and environmental factors, and linked to dopaminergic hyperactivity and neurotransmitter imbalances. Recent research reveals that patients exhibit significant language impairments, such as reduced verbal output and fluency. Advances in machine learning and natural language processing show potential for early diagnosis and personalized treatments, but additional research is required for the practical application and interpretation of such technology. The objective of this study is to explore the applications of natural language processing in patients diagnosed with schizophrenia. (2) Methods: A scoping review was conducted across multiple electronic databases, including Medline, PubMed, Embase, and PsycInfo. The search strategy utilized a combination of text words and subject headings, focusing on schizophrenia and natural language processing. Systematically extracted information included authors, population, primary uses of the natural language processing algorithms, main outcomes, and limitations. The quality of the identified studies was assessed. (3) Results: A total of 516 eligible articles were identified, from which 478 studies were excluded based on the first analysis of titles and abstracts. Of the remaining 38 studies, 18 were selected as part of this scoping review. The following six main uses of natural language processing were identified: diagnostic and predictive modeling, followed by specific linguistic phenomena, speech and communication analysis, social media and online content analysis, clinical and cognitive assessment, and linguistic feature analysis. (4) Conclusions: This review highlights the main uses of natural language processing in the field of schizophrenia and the need for more studies to validate the effectiveness of natural language processing in diagnosing and treating schizophrenia",jpm14070744,PubMed,1,2,0,intro: rev,specific,,,,FALSE,FALSE,TRUE
8,Ocular Pathology and Genetics: Transformative Role of Artificial Intelligence (AI) in Anterior Segment Diseases,"Artificial intelligence (AI) has become a revolutionary influence in the field of ophthalmology, providing unparalleled capabilities in data analysis and pattern recognition. This narrative review delves into the crucial role that AI plays, particularly in the context of anterior segment diseases with a genetic basis. Corneal dystrophies (CDs) exhibit significant genetic diversity, manifested by irregular substance deposition in the cornea. AI-driven diagnostic tools exhibit promising accuracy in the identification and classification of corneal diseases. Importantly, chat generative pre-trained transformer (ChatGPT)-4.0 shows significant advancement over its predecessor, ChatGPT-3.5. In the realm of glaucoma, AI significantly contributes to precise diagnostics through inventive algorithms and machine learning models, surpassing conventional methods. The incorporation of AI in predicting glaucoma progression and its role in augmenting diagnostic efficiency is readily apparent. Additionally, AI-powered models prove beneficial for early identification and risk assessment in cases of congenital cataracts, characterized by diverse inheritance patterns. Machine learning models achieving exceptional discrimination in identifying congenital cataracts underscore AI's remarkable potential. The review concludes by emphasizing the promising implications of AI in managing anterior segment diseases, spanning from early detection to the tailoring of personalized treatment strategies. These advancements signal a paradigm shift in ophthalmic care, offering optimism for enhanced patient outcomes and more streamlined healthcare delivery",Venkatapathappa2024-kq,PubMed,1,2,0,intro: rev,not_llm,different ai methods for ocular pathologies,,,FALSE,FALSE,TRUE
9,"Testing and Evaluation of Health Care Applications of Large Language Models: A Systematic Review
==========
A Systematic Review of Testing and Evaluation of Healthcare Applications of Large Language Models (LLMs)","Large language models (LLMs) can assist in various health care activities, but current evaluation approaches may not adequately identify the most useful application areas. To summarize existing evaluations of LLMs in health care in terms of 5 components: (1) evaluation data type, (2) health care task, (3) natural language processing (NLP) and natural language understanding (NLU) tasks, (4) dimension of evaluation, and (5) medical specialty. A systematic search of PubMed and Web of Science was performed for studies published between January 1, 2022, and February 19, 2024. Studies evaluating 1 or more LLMs in health care. Three independent reviewers categorized studies via keyword searches based on the data used, the health care tasks, the NLP and NLU tasks, the dimensions of evaluation, and the medical specialty. Of 519 studies reviewed, published between January 1, 2022, and February 19, 2024, only 5% used real patient care data for LLM evaluation. The most common health care tasks were assessing medical knowledge such as answering medical licensing examination questions (44.5%) and making diagnoses (19.5%). Administrative tasks such as assigning billing codes (0.2%) and writing prescriptions (0.2%) were less studied. For NLP and NLU tasks, most studies focused on question answering (84.2%), while tasks such as summarization (8.9%) and conversational dialogue (3.3%) were infrequent. Almost all studies (95.4%) used accuracy as the primary dimension of evaluation; fairness, bias, and toxicity (15.8%), deployment considerations (4.6%), and calibration and uncertainty (1.2%) were infrequently measured. Finally, in terms of medical specialty area, most studies were in generic health care applications (25.6%), internal medicine (16.4%), surgery (11.4%), and ophthalmology (6.9%), with nuclear medicine (0.6%), physical medicine (0.4%), and medical genetics (0.2%) being the least represented. Existing evaluations of LLMs mostly focus on accuracy of question answering for medical examinations, without consideration of real patient care data. Dimensions such as fairness, bias, and toxicity and deployment considerations received limited attention. Future evaluations should adopt standardized applications and metrics, use clinical data, and broaden focus to include a wider range of tasks and specialties",Bedi2025-tp,"PubMed, medrxiv",1,2,0,intro: rev,general,,,,FALSE,FALSE,TRUE
18,Biomedical Information Integration via Adaptive Large Language Model Construction,"Integrating diverse biomedical knowledge information is essential to enhance the accuracy and efficiency of medical diagnoses, facilitate personalized treatment plans, and ultimately improve patient outcomes. However, Biomedical Information Integration (BII) faces significant challenges due to variations in terminology and the complex structure of entity descriptions across different datasets. A critical step in BII is biomedical entity alignment, which involves accurately identifying and matching equivalent entities across diverse datasets to ensure seamless data integration. In recent years, Large Language Model (LLMs), such as Bidirectional Encoder Representations from Transformers (BERTs), have emerged as valuable tools for discerning heterogeneous biomedical data due to their deep contextual embeddings and bidirectionality. However, different LLMs capture various nuances and complexity levels within the biomedical data, and none of them can ensure their effectiveness in all heterogeneous entity matching tasks. To address this issue, we propose a novel Two-Stage LLM construction (TSLLM) framework to adaptively select and combine LLMs for Biomedical Information Integration (BII). First, a Multi-Objective Genetic Programming (MOGP) algorithm is proposed for generating versatile high-level LLMs, and then, a Single-Objective Genetic Algorithm (SOGA) employs a confidence-based strategy is presented to combine the built LLMs, which can further improve the discriminative power of distinguishing heterogeneous entities. The experiment utilizes OAEI's entity matching datasets, i.e., Benchmark and Conference, along with LargeBio, Disease and Phenotype datasets to test the performance of TSLLM. The experimental findings validate the efficiency of TSLLM in adaptively differentiating heterogeneous biomedical entities, which significantly outperforms the leading entity matching techniques",Xue2024-qa,PubMed,,1,111,pre: KNLR,extraction,"a novel Two-Stage LLM construction (TSLLM) framework: select and combine LLMs for Biomedical Information Integration (BII). 1) a Multi-Objective Genetic Programming (MOGP) algorithm is proposed for generating versatile high-level LLMs, and then, a Single-Objective Genetic Algorithm (SOGA) employs a confidence-based strategy is presented to combine the built LLMs, which can further improve the discriminative power of distinguishing heterogeneous entities. The experiment utilizes OAEI's entity matching datasets, i.e., Benchmark and Conference, along with LargeBio, Disease and Phenotype datasets to test the performance of TSLLM", adaptively differentiating heterogeneous biomedical entities,,FALSE,TRUE,FALSE
22,Cross-institution natural language processing for reliable clinical association studies: a methodological exploration,"Natural language processing (NLP) of clinical notes in electronic medical records is increasingly used to extract otherwise sparsely available patient characteristics, to assess their association with relevant health outcomes. Manual data curation is resource intensive and NLP methods make these studies more feasible. However, the methodology of using NLP methods reliably in clinical research is understudied. The objective of this study is to investigate how NLP models could be used to extract study variables (specifically exposures) to reliably conduct exposure-outcome association studies. In a convenience sample of patients admitted to the intensive care unit of a US academic health system, multiple association studies are conducted, comparing the association estimates based on NLP-extracted vs. manually extracted exposure variables. The association studies varied in NLP model architecture (Bidirectional Encoder Decoder from Transformers, Long Short-Term Memory), training paradigm (training a new model, fine-tuning an existing external model), extracted exposures (employment status, living status, and substance use), health outcomes (having a do-not-resuscitate/intubate code, length of stay, and in-hospital mortality), missing data handling (multiple imputation vs. complete case analysis), and the application of measurement error correction (via regression calibration). The study was conducted on 1,174 participants (median [interquartile range] age, 61 [50, 73] years; 60.6% male). Additionally, up to 500 discharge reports of participants from the same health system and 2,528 reports of participants from an external health system were used to train the NLP models. Substantial differences were found between the associations based on NLP-extracted and manually extracted exposures under all settings. The error in association was only weakly correlated with the overall F1 score of the NLP models. Associations estimated using NLP-extracted exposures should be interpreted with caution. Further research is needed to set conditions for reliable use of NLP in medical association studies",Sushil2024-jf,PubMed,,1,111,pre: KNLR,extraction,different models (including BERT), how NLP models could be used to extract study variables (specifically exposures) to reliably conduct exposure-outcome association studies,cross-institutional -- по идее полезно,FALSE,TRUE,FALSE
31,Integration of natural and deep artificial cognitive models in medical images: BERT-based NER and relation extraction for electronic medical records,"Medical images and signals are important data sources in the medical field, and they contain key information such as patients' physiology, pathology, and genetics. However, due to the complexity and diversity of medical images and signals, resulting in difficulties in medical knowledge acquisition and decision support. In order to solve this problem, this paper proposes an end-to-end framework based on BERT for NER and RE tasks in electronic medical records. Our framework first integrates NER and RE tasks into a unified model, adopting an end-to-end processing manner, which removes the limitation and error propagation of multiple independent steps in traditional methods. Second, by pre-training and fine-tuning the BERT model on large-scale electronic medical record data, we enable the model to obtain rich semantic representation capabilities that adapt to the needs of medical fields and tasks. Finally, through multi-task learning, we enable the model to make full use of the correlation and complementarity between NER and RE tasks, and improve the generalization ability and effect of the model on different data sets. We conduct experimental evaluation on four electronic medical record datasets, and the model significantly out performs other methods on different datasets in the NER task. In the RE task, the EMLB model also achieved advantages on different data sets, especially in the multi-task learning mode, its performance has been significantly improved, and the ETE and MTL modules performed well in terms of comprehensive precision and recall. Our research provides an innovative solution for medical image and signal data",10.3389/fnins.2023.1266771,PubMed,,1,111,pre: KNLR,extraction,BERT-based NER and relation extraction for electronic medical records in medical images:,,make full use of the correlation and complementarity between NER and RE tasks,FALSE,TRUE,FALSE
12,A Combined Manual Annotation and Deep-Learning Natural Language Processing Study on Accurate Entity Extraction in Hereditary Disease Related Biomedical Literature,"We report a combined manual annotation and deep-learning natural language processing study to make accurate entity extraction in hereditary disease related biomedical literature. A total of 400 full articles were manually annotated based on published guidelines by experienced genetic interpreters at Beijing Genomics Institute (BGI). The performance of our manual annotations was assessed by comparing our re-annotated results with those publicly available. The overall Jaccard index was calculated to be 0.866 for the four entity types-gene, variant, disease and species. Both a BERT-based large name entity recognition (NER) model and a DistilBERT-based simplified NER model were trained, validated and tested, respectively. Due to the limited manually annotated corpus, Such NER models were fine-tuned with two phases. The F1-scores of BERT-based NER for gene, variant, disease and species are 97.28%, 93.52%, 92.54% and 95.76%, respectively, while those of DistilBERT-based NER are 95.14%, 86.26%, 91.37% and 89.92%, respectively. Most importantly, the entity type of variant has been extracted by a large language model for the first time and a comparable F1-score with the state-of-the-art variant extraction model tmVar has been achieved",Huang2024-vl,PubMed,,2,111,"pre: KNLR, disc",extraction,"BERT-based and DistilBERT-based NER models for NER for gene, variant, disease, species extraction - Annotation of Hereditary Disease Related Biomedical Literature.","Entity extraction in hereditary disease-related literature (e.g., gene and variant recognition).","BERT-based NER achieved high F1-scores for gene (97.28%), variant (93.52%), disease (92.54%), and species (95.76%) extraction.",FALSE,FALSE,TRUE
14,A Simplified Retriever to Improve Accuracy of Phenotype Normalizations by Large Language Models,"Large language models have shown improved accuracy in phenotype term normalization tasks when augmented with retrievers that suggest candidate normalizations based on term definitions. In this work, we introduce a simplified retriever that enhances large language model accuracy by searching the Human Phenotype Ontology (HPO) for candidate matches using contextual word embeddings from BioBERT without the need for explicit term definitions. Testing this method on terms derived from the clinical synopses of Online Mendelian Inheritance in Man (OMIM®), we demonstrate that the normalization accuracy of GPT-4o increases from a baseline of 62% without augmentation to 85% with retriever augmentation. This approach is potentially generalizable to other biomedical term normalization tasks and offers an efficient alternative to more complex retrieval methods.",10.3389/fdgth.2025.1495040,arXiv,,2,111,pre: KNLR,extraction,simplified retriever that enhances LLM accuracy by searching the Human Phenotype Ontology (HPO) for candidate matches using contextual word embeddings from BioBERT,"train on HPO, test on OMIM; augmentation and retrieve",,FALSE,FALSE,TRUE
24,DUVEL: an active-learning annotated biomedical corpus for the recognition of oligogenic combinations,"While biomedical relation extraction (bioRE) datasets have been instrumental in the development of methods to support biocuration of single variants from texts, no datasets are currently available for the extraction of digenic or even oligogenic variant relations, despite the reports in literature that epistatic effects between combinations of variants in different loci (or genes) are important to understand disease etiologies. This work presents the creation of a unique dataset of oligogenic variant combinations, geared to train tools to help in the curation of scientific literature. To overcome the hurdles associated with the number of unlabelled instances and the cost of expertise, active learning (AL) was used to optimize the annotation, thus getting assistance in finding the most informative subset of samples to label. By pre-annotating 85 full-text articles containing the relevant relations from the Oligogenic Diseases Database (OLIDA) with PubTator, text fragments featuring potential digenic variant combinations, i.e. gene-variant-gene-variant, were extracted. The resulting fragments of texts were annotated with ALAMBIC, an AL-based annotation platform. The resulting dataset, called DUVEL, is used to fine-tune four state-of-the-art biomedical language models: BiomedBERT, BiomedBERT-large, BioLinkBERT and BioM-BERT. More than 500 000 text fragments were considered for annotation, finally resulting in a dataset with 8442 fragments, 794 of them being positive instances, covering 95% of the original annotated articles. When applied to gene-variant pair detection, BiomedBERT-large achieves the highest F1 score (0.84) after fine-tuning, demonstrating significant improvement compared to the non-fine-tuned model, underlining the relevance of the DUVEL dataset. This study shows how AL may play an important role in the creation of bioRE dataset relevant for biomedical curation applications. DUVEL provides a unique biomedical corpus focusing on 4-ary relations between two genes and two variants. It is made freely available for research on GitHub and Hugging Face. Database URL: https://huggingface.co/datasets/cnachteg/duvel or https://doi.org/10.57967/hf/1571",10.1093/database/baae039,PubMed,,2,111,pre: KNLR,extraction,"Active learning, BiomedBERT, BioLinkBERT, BioBERT; ML Task: Relation extraction of oligogenic variant combinations from biomedical text.",Oligogenic variant relation extraction for understanding disease etiology.,"Active learning aids in constructing a dataset for oligogenic combinations, with BiomedBERT-large achieving the highest F1 score after fine-tuning.",FALSE,FALSE,TRUE
59,Enhancing Biomarker-Based Oncology Trial Matching Using Large Language Models,"Clinical trials are an essential component of drug development for new cancer treatments, yet the information required to determine a patients eligibility for enrollment is scattered in large amounts of unstructured text. Genomic biomarkers are especially important in precision medicine and targeted therapies, making them essential for matching patients to appropriate trials. Large language models (LLMs) offer a promising solution for extracting this information from clinical trial data, aiding both physicians and patients in identifying suitable matches. In this study, we explore various LLM strategies for extracting genetic biomarkers from oncology trials to improve patient enrollment rates. Our results show that open-source language models, when applied out-of-the-box, effectively capture complex logical expressions and structure genomic biomarkers in disjunctive normal form, outperforming closed-source models such as GPT-4 and GPT-3.5-Turbo. Furthermore, fine-tuning these open-source models with additional data significantly enhances their performance",Khoury2024.09.13.612922,biorxiv,,2,111,pre: KNLR,extraction,opensource better than GPT + we can fine-tune them,LLM strategies for extracting genetic biomarkers from oncology trials to improve patient enrollment rates,,FALSE,FALSE,TRUE
25,Enhancing human phenotype ontology term extraction through synthetic case reports and embedding-based retrieval: A novel approach for improved biomedical data annotation,"With the increasing utilization of exome and genome sequencing in clinical and research genetics, accurate and automated extraction of human phenotype ontology (HPO) terms from clinical texts has become imperative. Traditional methods for HPO term extraction, such as PhenoTagger, often face limitations in coverage and precision. In this study, we propose a novel approach that leverages large language models (LLMs) to generate synthetic sentences with clinical context, which were semantically encoded into vector embeddings. These embeddings are linked to HPO terms, creating a robust knowledgebase that facilitates precise information retrieval. Our method circumvents the known issue of LLM hallucinations by storing and querying these embeddings within a true database, ensuring accurate context matching without the need for a predictive model. We evaluated the performance of three different embedding models, all of which demonstrated substantial improvements over PhenoTagger. Top recall (sensitivity), precision (positive-predictive value, PPV), and F1 are 0.64, 0.64, and 0.64, respectively, which were 31%, 10%, and 21% better than PhenoTagger. Furthermore, optimal performance was achieved when we combined the best performing embedding model with PhenoTagger (a.k.a. Fused model), resulting in recall (sensitivity), precision (PPV), and F1 values of 0.7, 0.7, and 0.7, respectively, which are 10%, 10%, and 10% better than the best embedding models. Our findings underscore the potential of this integrated approach to enhance the precision and reliability of HPO term extraction, offering a scalable and effective solution for biomedical data annotation",ALBAYRAK2025100409,PubMed,,2,111,pre: KNLR,extraction,"propose a novel approach that leverages large language models (LLMs) to generate synthetic sentences with clinical context, which were semantically encoded into vector embeddings",Enhancing human phenotype ontology term extractio,(similar to next),FALSE,FALSE,TRUE
26,Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models: PhenoBCBERT and PhenoGPT,"We hypothesize that large language models (LLMs) based on the transformer architecture can enable automated detection of clinical phenotype terms, including terms not documented in the HPO. In this study, we developed two types of models: PhenoBCBERT, a BERT-based model, utilizing Bio+Clinical BERT as its pre-trained model, and PhenoGPT, a GPT-based model that can be initialized from diverse GPT models, including open-source versions such as GPT-J, Falcon, and LLaMA, as well as closed-source versions such as GPT-3 and GPT-3.5. We compared our methods with PhenoTagger, a recently developed HPO recognition tool that combines rule-based and deep learning methods. We found that our methods can extract more phenotype concepts, including novel ones not characterized by HPO. We also performed case studies on biomedical literature to illustrate how new phenotype information can be recognized and extracted. We compared current BERT-based versus GPT-based models for phenotype tagging, in multiple aspects including model architecture, memory usage, speed, accuracy, and privacy protection. We also discussed the addition of a negation step and an HPO normalization layer to the transformer models for improved HPO term tagging. In conclusion, PhenoBCBERT and PhenoGPT enable the automated discovery of phenotype terms from clinical notes and biomedical literature, facilitating automated downstream tasks to derive new biological insights on human diseases
==========
To enhance phenotype recognition in clinical notes of genetic diseases, we developed two models - PhenoBCBERT and PhenoGPT - for expanding the vocabularies of Human Phenotype Ontology (HPO) terms. While HPO offers a standardized vocabulary for phenotypes, existing tools often fail to capture the full scope of phenotypes, due to limitations from traditional heuristic or rule-based approaches. Our models leverage large language models (LLMs) to automate the detection of phenotype terms, including those not in the current HPO. We compared these models to PhenoTagger, another HPO recognition tool, and found that our models identify a wider range of phenotype concepts, including previously uncharacterized ones. Our models also showed strong performance in case studies on biomedical literature. We evaluated the strengths and weaknesses of BERT-based and GPT-based models in aspects such as architecture and accuracy. Overall, our models enhance automated phenotype detection from clinical texts, improving downstream analyses on human diseases",YANG2024100887,"arXiv,PubMed",,2,111,pre: KNLR,extraction,"Bio+Clinical BERT as its pre-trained model, and PhenoGPT, a GPT-based model; compared our methods with PhenoTagger",Enhancing Phenotype Recognition (automated detection of clinical phenotype terms) in Clinical Notes ,(similar to previous,FALSE,FALSE,TRUE
65,GP-GPT: Large Language Model for Gene-Phenotype Mapping,"Pre-trained large language models(LLMs) have attracted increasing attention in biomedical domains due to their success in natural language processing. However, the complex traits and heterogeneity of multi-sources genomics data pose significant challenges when adapting these models to the bioinformatics and biomedical field. To address these challenges, we present GP-GPT, the first specialized large language model for genetic-phenotype knowledge representation and genomics relation analysis. Our model is fine-tuned in two stages on a comprehensive corpus composed of over 3,000,000 terms in genomics, proteomics, and medical genetics, derived from multiple large-scale validated datasets and scientific publications. GP-GPT demonstrates proficiency in accurately retrieving medical genetics information and performing common genomics analysis tasks, such as genomics information retrieval and relationship determination. Comparative experiments across domain-specific tasks reveal that GP-GPT outperforms state-of-the-art LLMs, including Llama2, Llama3 and GPT-4. These results highlight GP-GPT's potential to enhance genetic disease relation research and facilitate accurate and efficient analysis in the fields of genomics and medical genetics. Our investigation demonstrated the subtle changes of bio-factor entities' representations in the GP-GPT, which suggested the opportunities for the application of LLMs to advancing gene-phenotype research",lyu2024gpgptlargelanguagemodel,arXiv,,2,111,pre: KNLR,extraction,GP-GPT,first specialized large language model for genetic-phenotype knowledge representation and genomics relation analysis,,FALSE,FALSE,TRUE
66,GPAD: a natural language processing-based application to extract the gene-disease association discovery information from OMIM,"Thousands of genes have been associated with different Mendelian conditions. One of the valuable sources to track these gene-disease associations (GDAs) is the Online Mendelian Inheritance in Man (OMIM) database. However, most of the information in OMIM is textual, and heterogeneous (e.g. summarized by different experts), which complicates automated reading and understanding of the data. Here, we used Natural Language Processing (NLP) to make a tool (Gene-Phenotype Association Discovery (GPAD)) that could syntactically process OMIM text and extract the data of interest. GPAD applies a series of language-based techniques to the text obtained from OMIM API to extract GDA discovery-related information. GPAD can inform when a particular gene was associated with a specific phenotype, as well as the type of validation-whether through model organisms or cohort-based patient-matching approaches-for such an association. GPAD extracted data was validated with published reports and was compared with large language model. Utilizing GPAD's extracted data, we analysed trends in GDA discoveries, noting a significant increase in their rate after the introduction of exome sequencing, rising from an average of about 150-250 discoveries each year. Contrary to hopes of resolving most GDAs for Mendelian disorders by now, our data indicate a substantial decline in discovery rates over the past five years (2017-2022). This decline appears to be linked to the increasing necessity for larger cohorts to substantiate GDAs. The rising use of zebrafish and Drosophila as model organisms in providing evidential support for GDAs is also observed. GPAD's real-time analyzing capacity offers an up-to-date view of GDA discovery and could help in planning and managing the research strategies. In future, this solution can be extended or modified to capture other information in OMIM and scientific literature",Rahit2024,PubMed,,2,111,pre: KNLR,extraction,Gene-Phenotype Association Discovery (GPAD)," inform when a particular gene was associated with a specific phenotype, as well as the type of validation-whether through model organisms or cohort-based patient-matching approaches-for such an association.",,FALSE,FALSE,TRUE
139,Harnessing generative AI to annotate the severity of all phenotypic abnormalities within the Human Phenotype Ontology,"0.1There are thousands of human phenotypes which are linked to genetic variation. These range from the benign (white eyelashes) to the deadly (respiratory failure). The Human Phenotype Ontology has categorised all human phenotypic variation into a unified framework that defines the relationships between them (e.g. missing arms and missing legs are both abnormalities of the limb). This has made it possible to perform phenome-wide analyses, e.g. to prioritise which make the best candidates for gene therapies. However, there is currently limited metadata describing the clinical characteristics / severity of these phenotypes. With >17500 phenotypic abnormalities across >8600 rare diseases, manual curation of such phenotypic annotations by experts would be exceedingly labour-intensive and time-consuming. Leveraging advances in artificial intelligence, we employed the OpenAI GPT-4 large language model (LLM) to systematically annotate the severity of all phenotypic abnormalities in the HPO. Phenotypic severity was defined using a set of clinical characteristics and their frequency of occurrence. First, we benchmarked the generative LLM clinical characteristic annotations against ground-truth labels within the HPO (e.g. phenotypes in the  Cancer HPO branch were annotated as causing cancer by GPT-4). True positive recall rates across different clinical characteristics ranged from 89-100% (mean=96%), clearly demonstrating the ability of GPT-4 to automate the curation process with a high degree of fidelity. Using a novel approach, we developed a severity scoring system that incorporates both the nature of the clinical characteristic and the frequency of its occurrence. These clinical characteristic severity metrics will enable efforts to systematically prioritise which human phenotypes are most detrimental to human health, and best targets for therapeutic intervention",Murphy2024.06.10.24308475,medrxiv,,2,111,pre: KNLR,extraction,,annotate patients by HPO (using GPT-4),,FALSE,FALSE,TRUE
34,PheNormGPT: a framework for extraction and normalization of key medical findings,"This manuscript presents PheNormGPT, a framework for extraction and normalization of key findings in clinical text. PheNormGPT relies on an innovative approach, leveraging large language models to extract key findings and phenotypic data in unstructured clinical text and map them to Human Phenotype Ontology concepts. It utilizes OpenAI's GPT-3.5 Turbo and GPT-4 models with fine-tuning and few-shot learning strategies, including a novel few-shot learning strategy for custom-tailored few-shot example selection per request. PheNormGPT was evaluated in the BioCreative VIII Track 3: Genetic Phenotype Extraction from Dysmorphology Physical Examination Entries shared task. PheNormGPT achieved an F1 score of 0.82 for standard matching and 0.72 for exact matching, securing first place for this shared task",10.1093/database/baae103,PubMed,,2,111,"pre: KNLR, disc",extraction,"PheNormGPT, a framework for extraction and normalization of key findings in clinical text; OpenAI's GPT-3.5 Turbo and GPT-4 models with fine-tuning and few-shot learning strategies, including a novel few-shot learning strategy for custom-tailored few-shot example selection per request",,good prompting technique (few-shot ...),FALSE,FALSE,TRUE
43,"PheNorm, a language model normalizer of physical examinations from genetics clinical notes
==========
PhenoID, a language model normalizer of physical examinations from genetics clinical notes","AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSBackgroundC_ST_ABSPhenotypes identified during dysmorphology physical examinations are critical to genetic diagnosis and nearly universally documented as free-text in the electronic health record (EHR). Variation in how phenotypes are recorded in free-text makes large-scale computational analysis extremely challenging. Existing natural language processing (NLP) approaches to address phenotype extraction are trained largely on the biomedical literature or on case vignettes rather than actual EHR data.  MethodsWe implemented a tailored system at the Childrens Hospital of Philadelpia that allows clinicians to document dysmorphology physical exam findings. From the underlying data, we manually annotated a corpus of 3136 organ system observations using the Human Phenotype Ontology (HPO). We provide this corpus publicly. We trained a transformer based NLP system to identify HPO terms from exam observations. The pipeline includes an extractor, which identifies tokens in the sentence expected to contain an HPO term, and a normalizer, which uses those tokens together with the original observation to determine the specific term mentioned.  FindingsWe find that our labeler and normalizer NLP pipeline, which we call PhenoID, achieves state-of-the-art performance for the dysmorphology physical exam phenotype extraction task. PhenoIDs performance on the test set was 0.717, compared to the nearest baseline system (Pheno-Tagger) performance of 0.633. An analysis of our systems normalization errors shows possible imperfections in the HPO terminology itself but also reveals a lack of semantic understanding by our transformer models.  InterpretationTransformers-based NLP models are a promising approach to genetic phenotype extraction and, with recent development of larger pre-trained causal language models, may improve semantic understanding in the future. We believe our results also have direct applicability to more general extraction of medical signs and symptoms.  FundingUS National Institutes of Health",Weissenbacher2024-gm,"PubMed,medrxiv",,2,111,pre: KNLR,extraction,Transformer-based NLP system (PhenoID);,"phenotype extraction (+NER) and normalization from clinical notes using HPO terms, outperforms baselines",,FALSE,FALSE,TRUE
100,RelCurator: a text mining-based curation system for extracting gene-phenotype relationships specific to neurodegenerative disorders,"The identification of gene-phenotype relationships is important in medical genetics as it serves as a basis for precision medicine. However, most of the gene-phenotype relationship data are buried in the biomedical literature in textual form. We propose RelCurator, a curation system that extracts sentences including both gene and phenotype entities related to specific disease categories from PubMed articles, provides rich additional information such as entity taggings, and predictions of gene-phenotype relationships. We targeted neurodegenerative disorders and developed a deep learning model using Bidirectional Gated Recurrent Unit (BiGRU) networks and BioWordVec word embeddings for predicting gene-phenotype relationships from biomedical texts. The prediction model is trained with more than 130,000 labeled PubMed sentences including gene and phenotype entities, which are related to or unrelated to neurodegenerative disorders. We compared the performance of our deep learning model with those of Bidirectional Encoder Representations from Transformers (BERT), Support Vector Machine (SVM), and simple Recurrent Neural Network (simple RNN) models. Our model performed better with an F1-score of 0.96. Furthermore, the evaluation done using a few curation cases in the real scenario showed the effectiveness of our work. Therefore, we conclude that RelCurator can identify not only new causative genes, but also new genes associated with neurodegenerative disorders' phenotype. RelCurator is a user-friendly method for accessing deep learning-based supporting information and a concise web interface to assist curators while browsing the PubMed articles. Our curation process represents an important and broadly applicable improvement to the state of the art for the curation of gene-phenotype relationships",Lee2023-pz,PubMed,,2,111,pre: KNLR,extraction,RelCurator: a text mining-based curation system,extracting gene-phenotype relationships specific to neurodegenerative disorders,,FALSE,FALSE,TRUE
35,PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge,"PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a biomedical literature resource using state-of-the-art AI techniques to offer semantic and relation searches for key concepts like proteins, genetic variants, diseases, and chemicals. It currently provides over one billion entity and relation annotations across approximately 36 million PubMed abstracts and 6 million full-text articles from the PMC open access subset, updated weekly. PubTator 3.0's online interface and API utilize these precomputed entity relations and synonyms to provide advanced search capabilities and enable large-scale analyses, streamlining many complex information needs. We showcase the retrieval quality of PubTator 3.0 using a series of entity pair queries, demonstrating that PubTator 3.0 retrieves a greater number of articles than either PubMed or Google Scholar, with higher precision in the top 20 results. We further show that integrating ChatGPT (GPT-4) with PubTator APIs dramatically improves the factuality and verifiability of its responses. In summary, PubTator 3.0 offers a comprehensive set of features and tools that allow researchers to navigate the ever-expanding wealth of biomedical literature, expediting research and unlocking valuable insights for scientific discovery",10.1093/nar/gkae235,"arXiv,PubMed",,1,112,pre: KNLR,qa,se gpt4 in literature resource - pubtator,navigate literature,,FALSE,TRUE,FALSE
16,AutoPM3: Enhancing Variant Interpretation via LLM-driven PM3 Evidence Extraction from Scientific Literature,"Rare diseases, affecting 300 million people globally, often result from genetic variants. Wholegenome sequencing has made variant detection more cost-effective, but interpreting these variants remains challenging. Current clinical practice combines quantitative evidence and literature, which is complex and time-consuming. We introduce AutoPM3, a method for automating the extraction of ACMG/AMP PM3 evidence from scientific literature using open-source LLMs. It combines an optimized RAG system for text comprehension and a TableLLM equipped with Text2SQL for data extraction. We evaluated AutoPM3 using our collected PM3-Bench, a dataset from ClinGen with 1,027 variant-publication pairs. AutoPM3 significantly outperformed other methods in variant hit and in trans variant identification, thanks to the four key modules. Additionally, we wrapped AutoPM3 with a user-friendly interface to enhance its accessibility. This study presents a powerful tool to improve rare disease diagnosis workflows by facilitating PM3-relevant evidence extraction from scientific literature",Li2024.10.29.621006,biorxiv,,2,112,"pre: KNLR, disc",qa,rag,,also: benchmark: pm3 bench,FALSE,FALSE,TRUE
19,BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text,"Models such as GPT-4 and Med-PaLM 2 have demonstrated impressive performance on a wide variety of biomedical NLP tasks. However, these models have hundreds of billions of parameters, are computationally expensive to run, require users to send their input data over the internet, and are trained on unknown data sources. Can smaller, more targeted models compete? To address this question, we build and release BioMedLM, a 2.7 billion parameter GPT-style autoregressive model trained exclusively on PubMed abstracts and full articles. When fine-tuned, BioMedLM can produce strong multiple-choice biomedical question-answering results competitive with much larger models, such as achieving a score of 57.3% on MedMCQA (dev) and 69.0% on the MMLU Medical Genetics exam. BioMedLM can also be fine-tuned to produce useful answers to patient questions on medical topics. This demonstrates that smaller models can potentially serve as transparent, privacy-preserving, economical and environmentally friendly foundations for particular NLP applications, such as in biomedicine. The model is available on the Hugging Face Hub: https://huggingface.co/stanford-crfm/BioMedLM",bolton2024biomedlm27bparameterlanguage,arXiv,,2,112,pre: KNLR,qa,BioMedLM (GPT-style) for Biomedical question answering and text analysis.,Biomedical knowledge extraction from PubMed text for clinical decision-making.,"Smaller GPT-style model, fine-tuned for biomedical text, competes with larger models in biomedical QA.",FALSE,FALSE,TRUE
23,Deep-GenMut: Automated genetic mutation classification in oncology: A deep learning comparative study,"Early cancer detection and treatment depend on the discovery of specific genes that cause cancer. The classification of genetic mutations was initially done manually. However, this process relies on pathologists and can be a time-consuming task. Therefore, to improve the precision of clinical interpretation, researchers have developed computational algorithms that leverage next-generation sequencing technologies for automated mutation analysis. This paper utilized four deep learning classification models with training collections of biomedical texts. These models comprise bidirectional encoder representations from transformers for Biomedical text mining (BioBERT), a specialized language model implemented for biological contexts. Impressive results in multiple tasks, including text classification, language inference, and question answering, can be obtained by simply adding an extra layer to the BioBERT model. Moreover, bidirectional encoder representations from transformers (BERT), long short-term memory (LSTM), and bidirectional LSTM (BiLSTM) have been leveraged to produce very good results in categorizing genetic mutations based on textual evidence. The dataset used in the work was created by Memorial Sloan Kettering Cancer Center (MSKCC), which contains several mutations. Furthermore, this dataset poses a major classification challenge in the Kaggle research prediction competitions. In carrying out the work, three challenges were identified: enormous text length, biased representation of the data, and repeated data instances. Based on the commonly used evaluation metrics, the experimental results show that the BioBERT model outperforms other models with an F1 score of 0.87 and 0.850 MCC, which can be considered as improved performance compared to similar results in the literature that have an F1 score of 0.70 achieved with the BERT model",ELSAMAHY2024e32279,PubMed,,2,112,pre: KNLR,qa,Deep-GenMut,comparison study: genetic mutation classification in oncology,,FALSE,FALSE,TRUE
27,"Evaluating large language models on medical, lay-language, and self-reported descriptions of genetic conditions","Large language models (LLMs) are generating interest in medical settings. For example, LLMs can respond coherently to medical queries by providing plausible differential diagnoses based on clinical notes. However, there are many questions to explore, such as evaluating differences between open- and closed-source LLMs as well as LLM performance on queries from both medical and non-medical users. In this study, we assessed multiple LLMs, including Llama-2-chat, Vicuna, Medllama2, Bard/Gemini, Claude, ChatGPT3.5, and ChatGPT-4, as well as non-LLM approaches (Google search and Phenomizer) regarding their ability to identify genetic conditions from textbook-like clinician questions and their corresponding layperson translations related to 63 genetic conditions. For open-source LLMs, larger models were more accurate than smaller LLMs: 7b, 13b, and larger than 33b parameter models obtained accuracy ranges from 21%-49%, 41%-51%, and 54%-68%, respectively. Closed-source LLMs outperformed open-source LLMs, with ChatGPT-4 performing best (89%-90%). Three of 11 LLMs and Google search had significant performance gaps between clinician and layperson prompts. We also evaluated how in-context prompting and keyword removal affected open-source LLM performance. Models were provided with 2 types of in-context prompts: list-type prompts, which improved LLM performance, and definition-type prompts, which did not. We further analyzed removal of rare terms from descriptions, which decreased accuracy for 5 of 7 evaluated LLMs. Finally, we observed much lower performance with real individuals' descriptions; LLMs answered these questions with a maximum 21% accuracy",FLAHARTY20241819,PubMed,,2,112,pre: KNLR,qa,LLM for description of genetic conditions,,,FALSE,FALSE,TRUE
158,FindZebra online search delving into rare disease case reports using natural language processing,"Early diagnosis is crucial for well-being and life quality of the rare disease patient. Access to the most complete knowledge about diseases through intelligent user interfaces can play an important role in supporting the physician reaching the correct diagnosis. Case reports may offer information about heterogeneous phenotypes which often further complicate rare disease diagnosis. The rare disease search engine FindZebra.com is extended to also access case report abstracts extracted from PubMed for several diseases. A search index for each disease is built in Apache Solr adding age, sex and clinical features extracted using text segmentation to enhance the specificity of search. Clinical experts performed retrospective validation of the search engine, utilising real-world Outcomes Survey data on Gaucher and Fabry patients. Medical experts evaluated the search results as being clinically relevant for the Fabry patients and less clinically relevant for the Gaucher patients. The shortcomings for Gaucher patients mainly reflect a mismatch between the current understanding and treatment of the disease and how it is reported in PubMed, notably in the older case reports. In response to this observation, a filter for the publication date was added in the final version of the tool available from deep.findzebra.com/<disease> with <disease> = gaucher, fabry, hae (Hereditary angioedema)",Lievin2023-pw,PubMed,,2,112,pre: KNLR,qa,used BERT! for Case report extraction and analysis for rare disease diagnosis - Rare diseases searching engine,Diagnosis support for rare diseases using case reports and clinical data extracted from PubMed.,FindZebra enhances diagnostic relevance for rare diseases like Gaucher and Fabry using NLP to extract case-specific features.,FALSE,FALSE,TRUE
90,From Text to Translation: Using Language Models to Prioritize Variants for Clinical Review,"Despite rapid advances in genomic sequencing, most rare genetic variants remain insufficiently characterized for clinical use, limiting the potential of personalized medicine. When classifying whether a variant is pathogenic, clinical labs adhere to diagnostic guidelines that comprehensively evaluate many forms of evidence including case data, computational predictions, and functional screening. While a substantial amount of clinical evidence has been developed for these variants, the majority cannot be definitively classified as  pathogenic or  benign, and thus persist as  Variants of Uncertain Significance (VUS). We processed over 2.4 million plaintext variant summaries from ClinVar, employing sentence-level classification to remove content that does not contain evidence and removing uninformative summaries. We developed ClinVar-BERT to discern clinical evidence within these summaries by fine-tuning a BioBERT-based model with labeled records. When validated classifications from this model against orthogonal functional screening data, ClinVar-BERT significantly separated estimates of functional impact in clinically actionable genes, including BRCA1 (p = 1.90 x 10-20), TP53 (p = 1.14 x 10-47), and PTEN (p = 3.82 x 10-7). Additionally, ClinVar-BERT achieved an AUROC of 0.927 in classifying ClinVar VUS against this functional screening data. This suggests that ClinVar-BERT is capable of discerning evidence from diagnostic reports and can be used to prioritize variants for re-assessment by diagnostic labs and expert curation panels
==========
Despite rapid advances in genomic sequencing, most rare genetic variants remain insufficiently characterized for clinical use, limiting the potential of personalized medicine. When classifying whether a variant is pathogenic, clinical labs adhere to diagnostic guidelines that comprehensively evaluate many forms of evidence including case data, computational predictions, and functional screening. While a substantial amount of clinical evidence has been developed for these variants, the majority cannot be definitively classified as 'pathogenic' or 'benign', and thus persist as 'Variants of Uncertain Significance' (VUS). We processed over 2.4 million plaintext variant summaries from ClinVar, employing sentence-level classification to remove content that does not contain evidence and removing uninformative summaries. We developed ClinVar-BERT to discern clinical evidence within these summaries by fine-tuning a BioBERT-based model with labeled records. When validated classifications from this model against orthogonal functional screening data, ClinVar-BERT significantly separated estimates of functional impact in clinically actionable genes, including BRCA1 (p = 1.90 × 10<sup>-20</sup> ), TP53 (p = 1.14 × 10<sup>-47</sup> ), and PTEN (p = 3.82 × 10<sup>-7</sup> ). Additionally, ClinVar-BERT achieved an AUROC of 0.927 in classifying ClinVar VUS against this functional screening data. This suggests that ClinVar-BERT is capable of discerning evidence from diagnostic reports and can be used to prioritize variants for re-assessment by diagnostic labs and expert curation panels",Li2024-ul,"PubMed,medrxiv",,2,112,pre: KNLR,qa,"Use biobert, clinvarbert",prioritize variants for review,new subtopic of KNLR?,FALSE,FALSE,TRUE
30,GeneGPT: augmenting large language models with domain tools for improved access to biomedical information,"Motivation While large language models (LLMs) have been successfully applied to various tasks, they still face challenges with hallucinations. Augmenting LLMs with domain-specific tools such as database utilities can facilitate easier and more precise access to specialized knowledge. In this article, we present GeneGPT, a novel method for teaching LLMs to use the Web APIs of the National Center for Biotechnology Information (NCBI) for answering genomics questions. Specifically, we prompt Codex to solve the GeneTuring tests with NCBI Web APIs by in-context learning and an augmented decoding algorithm that can detect and execute API calls. Results Experimental results show that GeneGPT achieves state-of-the-art performance on eight tasks in the GeneTuring benchmark with an average score of 0.83, largely surpassing retrieval-augmented LLMs such as the new Bing (0.44), biomedical LLMs such as BioMedLM (0.08) and BioGPT (0.04), as well as GPT-3 (0.16) and ChatGPT (0.12). Our further analyses suggest that: First, API demonstrations have good cross-task generalizability and are more useful than documentations for in-context learning; second, GeneGPT can generalize to longer chains of API calls and answer multi-hop questions in GeneHop, a novel dataset introduced in this work; finally, different types of errors are enriched in different tasks, providing valuable insights for future improvements. Availability and implementation The GeneGPT code and data are publicly available at https://github.com/ncbi/GeneGPT.",10.1093/bioinformatics/btae075,PubMed,,2,112,pre: KNLR,qa,,,,FALSE,FALSE,TRUE
91,Genetic Discovery Enabled by A Large Language Model,"Artificial intelligence (AI) has been used in many areas of medicine, and recently large language models (LLMs) have shown potential utility for clinical applications. However, since we do not know if the use of LLMs can accelerate the pace of genetic discovery, we used data generated from mouse genetic models to investigate this possibility. We examined whether a recently developed specialized LLM (Med-PaLM 2) could analyze sets of candidate genes generated from analysis of murine models of biomedical traits. In response to free-text input, Med-PaLM 2 correctly identified the murine genes that contained experimentally verified causative genetic factors for six biomedical traits, which included susceptibility to diabetes and cataracts. Med-PaLM 2 was also able to analyze a list of genes with high impact alleles, which were identified by comparative analysis of murine genomic sequence data, and it identified a causative murine genetic factor for spontaneous hearing loss. Based upon this Med-PaLM 2 finding, a novel bigenic model for susceptibility to spontaneous hearing loss was developed. These results demonstrate Med-PaLM 2 can analyze gene-phenotype relationships and generate novel hypotheses, which can facilitate genetic discovery",Tu2023.11.09.566468,"PubMed,biorxiv",,2,112,pre: KNLR,qa,specialized LLM (Med-PaLM) assesment,LLM for analyzing sets of candidate genes,,FALSE,FALSE,TRUE
69,Large language models assisted multi-effect variants mining on cerebral cavernous malformation familial whole genome sequencing,"Cerebral cavernous malformation (CCM) is a polygenic disease with intricate genetic interactions contributing to quantitative pathogenesis across multiple factors. The principal pathogenic genes of CCM, specifically KRIT1, CCM2, and PDCD10, have been reported, accompanied by a growing wealth of genetic data related to mutations. Furthermore, numerous other molecules associated with CCM have been unearthed. However, tackling such massive volumes of unstructured data remains challenging until the advent of advanced large language models. In this study, we developed an automated analytical pipeline specialized in single nucleotide variants (SNVs) related biomedical text analysis called BRLM. To facilitate this, BioBERT was employed to vectorize the rich information of SNVs, while a deep residue network was used to discriminate the classes of the SNVs. BRLM was initially constructed on mutations from 12 different types of TCGA cancers, achieving an accuracy exceeding 99%. It was further examined for CCM mutations in familial sequencing data analysis, highlighting an upstream master regulator gene fibroblast growth factor 1 (FGF1). With multi-omics characterization and validation in biological function, FGF1 demonstrated to play a significant role in the development of CCMs, which proved the effectiveness of our model. The BRLM web server is available at http://1.117.230.196",WANG2024843,PubMed,,2,112,pre: KNLR,qa,BRLM (BioBERT Encoder ResNet Classifier Language Learning Model),multi-effect variants mining,,FALSE,FALSE,TRUE
99,"Preparing to Integrate Generative Pretrained Transformer Series 4 models into Genetic Variant Assessment Workflows: Assessing Performance, Drift, and Nondeterminism Characteristics Relative to Classifying Functional Evidence in Literature","Background. Large Language Models (LLMs) hold promise for improving genetic variant literature review in clinical testing. We assessed Generative Pretrained Transformer 4's (GPT-4) performance, nondeterminism, and drift to inform its suitability for use in complex clinical processes. Methods. A 2-prompt process for classification of functional evidence was optimized using a development set of 45 articles. The prompts asked GPT-4 to supply all functional data present in an article related to a variant or indicate that no functional evidence is present. For articles indicated as containing functional evidence, a second prompt asked GPT-4 to classify the evidence into pathogenic, benign, or intermediate/inconclusive categories. A final test set of 72 manually classified articles was used to test performance. Results. Over a 2.5-month period (Dec 2023-Feb 2024), we observed substantial differences in intraday (nondeterminism) and across day (drift) results, which lessened after 1/18/24. This variability is seen within and across models in the GPT-4 series, affecting different performance statistics to different degrees. Twenty runs after 1/18/24 identified articles containing functional evidence with 92.2% sensitivity, 95.6% positive predictive value (PPV) and 86.3% negative predictive value (NPV). The second prompt's identified pathogenic functional evidence with 90.0% sensitivity, 74.0% PPV and 95.3% NVP and for benign evidence with 88.0% sensitivity, 76.6% PPV and 96.9% NVP. Conclusion. Nondeterminism and drift within LLMs must be assessed and monitored when introducing LLM based functionality into clinical workflows. Failing to do this assessment or accounting for these challenges could lead to incorrect or missing information that is critical for patient care. The performance of our prompts appears adequate to assist in article prioritization but not in automated decision making",aronson2024preparingintegrategenerativepretrained,arXiv,,2,112,pre: KNLR,qa,GPT-4 for Classifying functional evidence from genetic variant literature.,Genetic variant literature review and classification for clinical testing.,nondeterminism therefore requiring monitoring for reliable clinical use.,FALSE,FALSE,TRUE
84,"Artificial Intelligence-Assisted Comparative Analysis of the Overlapping Molecular Pathophysiology of Alzheimer's Disease, Amyotrophic Lateral Sclerosis, and Frontotemporal Dementia","The overlapping molecular pathophysiology of Alzheimer's Disease (AD), Amyotrophic Lateral Sclerosis (ALS), and Frontotemporal Dementia (FTD) was analyzed using relationships from a knowledge graph of 33+ million biomedical journal articles. The unsupervised learning rank aggregation algorithm from SemNet 2.0 compared the most important amino acid, peptide, and protein (AAPP) nodes connected to AD, ALS, or FTD. FTD shared 99.9% of its nodes with ALS and AD; AD shared 64.2% of its nodes with FTD and ALS; and ALS shared 68.3% of its nodes with AD and FTD. The results were validated and mapped to functional biological processes using supervised human supervision and an external large language model. The overall percentages of mapped intersecting biological processes were as follows: inflammation and immune response, 19%; synapse and neurotransmission, 19%; cell cycle, 15%; protein aggregation, 12%; membrane regulation, 11%; stress response and regulation, 9%; and gene regulation, 4%. Once normalized for node count, biological mappings for cell cycle regulation and stress response were more prominent in the intersection of AD and FTD. Protein aggregation, gene regulation, and energetics were more prominent in the intersection of ALS and FTD. Synapse and neurotransmission, membrane regulation, and inflammation and immune response were greater at the intersection of AD and ALS. Given the extensive molecular pathophysiology overlap, small differences in regulation, genetic, or environmental factors likely shape the underlying expressed disease phenotype. The results help prioritize testable hypotheses for future clinical or experimental research",ijms252413450,PubMed,,1,113,pre: KNLR,creation,The results were validated and mapped to functional biological processes using supervised human supervision and an external large language model.,"molecular pathophysiology of Alzheimer's Disease (AD), Amyotrophic Lateral Sclerosis (ALS), and Frontotemporal Dementia (FTD) was analyzed using relationships from a knowledge graph of 33+ million biomedical journal articles","they got most important amino acid, peptide, and protein (AAPP) nodes connected to AD, ALS, or FTD from previous analyses, and validated using LLM",FALSE,TRUE,FALSE
13,A Multimodal Foundation Model for Discovering Genetic Associations with Brain Imaging Phenotypes,"Due to the intricate etiology of neurological disorders, finding interpretable associations between multi-omics features can be challenging using standard approaches. We propose COMICAL, a contrastive learning approach leveraging multi-omics data to generate associations between genetic markers and brain imaging-derived phenotypes. COMICAL jointly learns omic representations utilizing transformer-based encoders with custom tokenizers. Our modality-agnostic approach uniquely identi-fies many-to-many associations via self-supervised learning schemes and cross-modal attention encoders. COMICAL discovered several significant associations between genetic markers and imaging-derived phenotypes for a variety of neurological disorders in the UK Biobank as well as predicting across diseases and unseen clinical outcomes from the learned representations. Source code of COMICAL along with pre-trained weights, enabling transfer learning is available at https://github.com/IBM/comical",Machado_Reyes2024.11.02.24316653,medrxiv,,2,113,"pre: KNLR, ana: MIA",creation,COMICAL: contrastive learning approach leveraging multi-omics data to generate associations between genetic markers and brain imaging-derived phenotypes. - transformer-based encoder,,,FALSE,FALSE,TRUE
51,An Expert-guided Hierarchical Graph Attention Network for Post-traumatic Stress Disorder Highlyassociative Genetic Biomarkers Identification,"Post-traumatic Stress Disorder (PTSD) is a common debilitating mental disorder, that occurs in some individuals following extremely traumatic events. Traditional identification of Genetic Markers (GM) for PTSD is mainly based on a statistical clinical approach by comparing PTSD patients with normal controls. However, these statistical studies present limitations, often generating inconsistent results. Few studies have yet examined thoroughly the role of somatic mutations, PTSD disease pathways and their relationships. Capitalizing on deep learning techniques, we have developed a novel hierarchical graph attention network to identify highly correlational GM (HGMs) of PTSD. The network presents the following novelties: First, both a hierarchical graph structure and a graph attention mechanism have been integrated into a model to develop a graph attention network (GAtN) model. Second, domain-specific knowledge, including somatic mutations, genes, PTSD pathways and their correlations have been incorporated into the graph structures. Third, 12 somatic mutations having high or moderate impacts on proteins or genes have been identified as the potential HGMs for PTSD. Fourth, our study is carefully guided by prominent PTSD literature or clinical experts of the field; any high saliency HGMs generated from our model are further verified by existing PTSD-related authoritative medical journals. Our study illustrates the utility and significance of a hybrid approach, integrating both AI and expert-guided/domain-specific knowledge for thorough identification of biomarkers of PTSD, while building on the nature of convergence and divergence of PTSD pathways. Our expert-guided AI-driven methodology can be extended to other pathological-based HGM identification studies; it will transform the methodology of biomarker identification for different life-threatening diseases to speed up the complex lengthy procedures of new biomarkers identification",Zhang2023.01.30.23285175,medrxiv,,2,113,pre: KNLR,creation,hierarchical graph attention network to identify highly correlational GM (HGMs) of PTSD - sample data and knowledge-based data; but for aggregation,"Genetic markers identification, associated with post traumatic stress disorder ptsd)",,FALSE,FALSE,TRUE
21,CPMKG: a condition-based knowledge graph for precision medicine,"Personalized medicine tailors treatments and dosages based on a patient's unique characteristics, particularly its genetic profile. Over the decades, stratified research and clinical trials have uncovered crucial drug-related information-such as dosage, effectiveness, and side effects-affecting specific individuals with particular genetic backgrounds. This genetic-specific knowledge, characterized by complex multirelationships and conditions, cannot be adequately represented or stored in conventional knowledge systems. To address these challenges, we developed CPMKG, a condition-based platform that enables comprehensive knowledge representation. Through information extraction and meticulous curation, we compiled 307 614 knowledge entries, encompassing thousands of drugs, diseases, phenotypes (complications/side effects), genes, and genomic variations across four key categories: drug side effects, drug sensitivity, drug mechanisms, and drug indications. CPMKG facilitates drug-centric exploration and enables condition-based multiknowledge inference, accelerating knowledge discovery through three pivotal applications. To enhance user experience, we seamlessly integrated a sophisticated large language model that provides textual interpretations for each subgraph, bridging the gap between structured graphs and language expressions. With its comprehensive knowledge graph and user-centric applications, CPMKG serves as a valuable resource for clinical research, offering drug information tailored to personalized genetic profiles, syndromes, and phenotypes. Database URL: https://www.biosino.org/cpmkg/",10.1093/database/baae102,PubMed,,2,113,pre: KNLR,creation,"condition-based knowledge graph: integrated a sophisticated large language model that provides textual interpretations for each subgraph, bridging the gap between structured graphs and language expressions",,,FALSE,FALSE,TRUE
89,End-to-end interpretable disease-gene association prediction,"Identifying disease-gene associations is a fundamental and critical biomedical task towards understanding molecular mechanisms, the diagnosis and treatment of diseases. It is time-consuming and expensive to experimentally verify causal links between diseases and genes. Recently, deep learning methods have achieved tremendous success in identifying candidate genes for genetic diseases. The gene prediction problem can be modeled as a link prediction problem based on the features of nodes and edges of the gene-disease graph. However, most existing researches either build homogeneous networks based on one single data source or heterogeneous networks based on multi-source data, and artificially define meta-paths, so as to learn the network representation of diseases and genes. The former cannot make use of abundant multi-source heterogeneous information, while the latter needs domain knowledge and experience when defining meta-paths, and the accuracy of the model largely depends on the definition of meta-paths. To address the aforementioned challenges above bottlenecks, we propose an end-to-end disease-gene association prediction model with parallel graph transformer network (DGP-PGTN), which deeply integrates the heterogeneous information of diseases, genes, ontologies and phenotypes. DGP-PGTN can automatically and comprehensively capture the multiple latent interactions between diseases and genes, discover the causal relationship between them and is fully interpretable at the same time. We conduct comprehensive experiments and show that DGP-PGTN outperforms the state-of-the-art methods significantly on the task of disease-gene association prediction. Furthermore, DGP-PGTN can automatically learn the implicit relationship between diseases and genes without manually defining meta paths",10.1093/bib/bbad118,PubMed,,2,113,pre: KNLR,creation,disease-gene association prediction model with parallel graph transformer network (DGP-PGTN),"identify candidate genes (link prediction), using multi sources, integrates heterogeneous information of diseases, genes, ontologies and phenotypes",,FALSE,FALSE,TRUE
62,Gene-associated Disease Discovery Powered by Large Language Models,"The intricate relationship between genetic variation and human diseases has been a focal point of medical research, evidenced by the identification of risk genes regarding specific diseases. The advent of advanced genome sequencing techniques has significantly improved the efficiency and cost-effectiveness of detecting these genetic markers, playing a crucial role in disease diagnosis and forming the basis for clinical decision-making and early risk assessment. To overcome the limitations of existing databases that record disease-gene associations from existing literature, which often lack real-time updates, we propose a novel framework employing Large Language Models (LLMs) for the discovery of diseases associated with specific genes. This framework aims to automate the labor-intensive process of sifting through medical literature for evidence linking genetic variations to diseases, thereby enhancing the efficiency of disease identification. Our approach involves using LLMs to conduct literature searches, summarize relevant findings, and pinpoint diseases related to specific genes. This paper details the development and application of our LLM-powered framework, demonstrating its potential in streamlining the complex process of literature retrieval and summarization to identify diseases associated with specific genetic variations",chang2024geneassociateddiseasediscoverypowered,arXiv,,2,113,pre: KNLR,creation,use LLMs (for real-life updating), discovery of diseases associated with specific genes,,FALSE,FALSE,TRUE
33,Leveraging Generative AI to Accelerate Biocuration of Medical Actions for Rare Disease,"Structured representations of clinical data can support computational analysis of individuals and cohorts, and ontologies representing disease entities and phenotypic abnormalities are now commonly used for translational research. The Medical Action Ontology (MAxO) provides a computational representation of treatments and other actions taken for the clinical management of patients. Currently, manual biocuration is used to assign MAxO terms to rare diseases, enabling clinical management of rare diseases to be described computationally for use in clinical decision support and mechanism discovery. However, it is challenging to scale manual curation to comprehensively capture information about medical actions for the more than 10,000 rare diseases. We present AutoMAxO, a semi-automated workflow that leverages Large Language Models (LLMs) to streamline MAxO biocuration for rare diseases. AutoMAxO first uses LLMs to retrieve candidate curations from abstracts of relevant publications. Next, the candidate curations are matched to ontology terms from MAxO, Human Phenotype Ontology (HPO), and MONDO disease ontology via a combination of LLMs and post-processing techniques. Finally, the matched terms are presented in a structured form to a human curator for approval. We used this approach to process 4,918 unique medical abstracts and identified annotations for 21 rare genetic diseases, we extracted 18,631 candidate disease-treatment curations, 538 of which were confirmed and transferred to the MAxO annotation dataset. The results of this project underscore the potential of generative AI to accelerate precision medicine by enabling a robust and comprehensive curation of the primary literature to represent information about diseases and procedures in a structured fashion. Although we focused on MAxO in this project, similar approaches could be taken for other biomedical curation tasks
==========
Structured representations of clinical data can support computational analysis of individuals and cohorts, and ontologies representing disease entities and phenotypic abnormalities are now commonly used for translational research. The Medical Action Ontology (MAxO) provides a computational representation of treatments and other actions taken for the clinical management of patients. Currently, manual biocuration is used to assign MAxO terms to rare diseases, enabling clinical management of rare diseases to be described computationally for use in clinical decision support and mechanism discovery. However, it is challenging to scale manual curation to comprehensively capture information about medical actions for the more than 10,000 rare diseases.  We present AutoMAxO, a semi-automated workflow that leverages Large Language Models (LLMs) to streamline MAxO biocuration for rare diseases. AutoMAxO first uses LLMs to retrieve candidate curations from abstracts of relevant publications. Next, the candidate curations are matched to ontology terms from MAxO, Human Phenotype Ontology (HPO), and MONDO disease ontology via a combination of LLMs and post-processing techniques. Finally, the matched terms are presented in a structured form to a human curator for approval. We used this approach to process 4,918 unique medical abstracts and identified annotations for 21 rare genetic diseases, we extracted 18,631 candidate disease-treatment curations, 538 of which were confirmed and transferred to the MAxO annotation dataset.  The results of this project underscore the potential of generative AI to accelerate precision medicine by enabling a robust and comprehensive curation of the primary literature to represent information about diseases and procedures in a structured fashion. Although we focused on MAxO in this project, similar approaches could be taken for other biomedical curation tasks",Niyonkuru2024.08.22.24310814,"PubMed,medrxiv",,2,113,pre: KNLR,creation,"AutoMAxO first uses LLMs to retrieve candidate curations from abstracts of relevant publications. Next, the candidate curations are matched to ontology terms from MAxO, Human Phenotype Ontology (HPO), and MONDO disease ontology via a combination of LLMs and post-processing techniques",HPO mapping again,,FALSE,FALSE,TRUE
147,Literature mining discerns latent disease-gene relationships,"Dysregulation of a gene's function, either due to mutations or impairments in regulatory networks, often triggers pathological states in the affected tissue. Comprehensive mapping of these apparent gene-pathology relationships is an ever-daunting task, primarily due to genetic pleiotropy and lack of suitable computational approaches. With the advent of high throughput genomics platforms and community scale initiatives such as the Human Cell Landscape project, researchers have been able to create gene expression portraits of healthy tissues resolved at the level of single cells. However, a similar wealth of knowledge is currently not at our finger-tip when it comes to diseases. This is because the genetic manifestation of a disease is often quite diverse and is confounded by several clinical and demographic covariates. To circumvent this, we mined ∼18 million PubMed abstracts published till May 2019 and automatically selected ∼4.5 million of them that describe roles of particular genes in disease pathogenesis. Further, we fine-tuned the pretrained bidirectional encoder representations from transformers (BERT) for language modeling from the domain of natural language processing to learn vector representation of entities such as genes, diseases, tissues, cell-types, etc., in a way such that their relationship is preserved in a vector space. The repurposed BERT predicted disease-gene associations that are not cited in the training data, thereby highlighting the feasibility of in silico synthesis of hypotheses linking different biological entities such as genes and conditions. PathoBERT pretrained model: https://github.com/Priyadarshini-Rai/Pathomap-Model. BioSentVec-based abstract classification model: https://github.com/Priyadarshini-Rai/Pathomap-Model. Pathomap R package: https://github.com/Priyadarshini-Rai/Pathomap",10.1093/bioinformatics/btae185,PubMed,,2,113,pre: KNLR,creation,PathoBERT/pathomap - fine-tuned bert,predict disease-gene associations that are not cited in the training data,,FALSE,FALSE,TRUE
148,LitGene: a transformer-based model that uses contrastive learning to integrate textual information into gene representations,"Representation learning approaches leverage sequence, expression, and network data, but utilize only a fraction of the rich textual knowledge accumulated in the scientific literature. We present LitGene, an interpretable transformer-based model that refines gene representations by integrating textual information. The model is enhanced through a Contrastive Learning (CL) approach that identifies semantically similar genes sharing a Gene Ontology (GO) term. LitGene demonstrates accuracy across eight benchmark predictions of protein properties and robust zero-shot learning capabilities, enabling the prediction of new potential disease risk genes in obesity, asthma, hypertension, and schizophrenia. LitGenes SHAP-based interpretability tool illuminates the basis for identified disease-gene associations. An automated statistical framework gauges literature support for AI biomedical predictions, providing validation and improving reliability. LitGenes integration of textual and genetic information mitigates data biases, enhances biomedical predictions, and promotes ethical AI practices by ensuring transparent, equitable, open, and evidence-based insights. LitGene code is open source and also available for use via a public web interface at litgene.avisahuai.com",Jararweh2024.08.07.606674,biorxiv,,2,113,pre: KNLR,creation,LitGene: a transformer-based model that uses contrastive learning to integrate textual information into gene representations,enhanced through a Contrastive Learning (CL) approach that identifies semantically similar genes sharing a Gene Ontology (GO) term,,FALSE,FALSE,TRUE
36,SCREENER: Streamlined collaborative learning of NER and RE model for discovering gene-disease relations,"Finding relations between genes and diseases is essential in developing a clinical diagnosis, treatment, and drug design for diseases. One successful approach for mining the literature is the document-based relation extraction method. Despite recent advances in document-level extraction of entity-entity, there remains a difficulty in understanding the relations between distant words in a document. To overcome the above limitations, we propose an AI-based text-mining model that learns the document-level relations between genes and diseases using an attention mechanism. Furthermore, we show that including a direct edge (DE) and indirect edges between genetic targets and diseases when training improves the model's performance. Such relation edges can be visualized as graphs, enhancing the interpretability of the model. For the performance, we achieved an F1-score of 0.875, outperforming state-of-the-art document-level extraction models. In summary, the SCREENER identifies biological connections between target genes and diseases with superior performance by leveraging direct and indirect target-disease relations. Furthermore, we developed a web service platform named SCREENER (Streamlined CollaboRativE lEarning of NEr and Re), which extracts the gene-disease relations from the biomedical literature in real-time. We believe this interactive platform will be useful for users to uncover unknown gene-disease relations in the world of fast-paced literature publications, with sufficient interpretation supported by graph visualizations. The interactive website is available at: https://ican.standigm.com",Park2023-ec,PubMed,,2,113,pre: KNLR,creation,SCREENER: Streamlined collaborative learning of NER and RE,discover gene-disease ralations from biomed literature,,FALSE,FALSE,TRUE
101,Therapeutic gene target prediction using novel deep hypergraph representation learning,"Identifying therapeutic genes is crucial for developing treatments targeting genetic causes of diseases, but experimental trials are costly and time-consuming. Although many deep learning approaches aim to identify biomarker genes, predicting therapeutic target genes remains challenging due to the limited number of known targets. To address this, we propose HIT (Hypergraph Interaction Transformer), a deep hypergraph representation learning model that identifies a gene's therapeutic potential, biomarker status, or lack of association with diseases. HIT uses hypergraph structures of genes, ontologies, diseases, and phenotypes, employing attention-based learning to capture complex relationships. Experiments demonstrate HIT's state-of-the-art performance, explainability, and ability to identify novel therapeutic targets",10.1093/bib/bbaf019,PubMed,,2,113,pre: KNLR,creation,"HIT (Hypergraph Interaction Transformer), a deep hypergraph representation learning model: uses hypergraph structures of genes, ontologies, diseases, and phenotypes, employing attention-based learning to capture complex relationships","Therapeutic gene target prediction: identifies a gene's therapeutic potential, biomarker status, or lack of association with diseases",,FALSE,FALSE,TRUE
136,Accuracy of generative artificial intelligence models in differential diagnoses of familial Mediterranean fever and deficiency of Interleukin-1 receptor antagonist,"With the increasing development of artificial intelligence, large language models (LLMs) have been utilized to solve problems in natural language processing tasks. More recently, LLMs have shown unique potential in numerous applications within medicine but have been particularly investigated for their ability in clinical reasoning. Although the diagnostic accuracy of LLMs in forming differential diagnoses has been reviewed in general internal medicine applications, much is unknown in autoinflammatory disorders. From the nature of autoinflammatory diseases, forming a differential diagnosis is challenging due to the overlapping symptoms between disorders and even more difficult without genetic screening. In this work, the diagnostic accuracy of the Generative Pre-Trained Transformer Model-4 (GPT-4), GPT-3.5, and Large Language Model Meta AI (LLaMa) were evaluated in clinical vignettes of Deficiency of Interleukin-1 Receptor Antagonist (DIRA) and Familial Mediterranean Fever (FMF). We then compared these models to a control group including one internal medicine physician. It was found that GPT-4 did not significantly differ in correctly identifying DIRA and FMF patients compared to the internist. However, the physician maintained a significantly higher accuracy than GPT-3.5 and LLaMa 2 for either disease. Overall, we explore and discuss the unique potential of LLMs in diagnostics for autoimmune diseases",PILLAI2023100213,PubMed,,2,121,pre: RS,predisposition,"gpt, llama vs interns",identify  familial Mediterranean fever and deficiency of Interleukin-1 receptor antagonist,,FALSE,FALSE,TRUE
153,AI-Powered Neurogenetics: Supporting Patient's Evaluation with Chatbot,"Artificial intelligence and large language models like ChatGPT and Google's Gemini are promising tools with remarkable potential to assist healthcare professionals. This study explores ChatGPT and Gemini's potential utility in assisting clinicians during the first evaluation of patients with suspected neurogenetic disorders. By analyzing the model's performance in identifying relevant clinical features, suggesting differential diagnoses, and providing insights into possible genetic testing, this research seeks to determine whether these AI tools could serve as a valuable adjunct in neurogenetic assessments. Ninety questions were posed to ChatGPT (Versions 4o, 4, and 3.5) and Gemini: four questions about clinical diagnosis, seven about genetic inheritance, estimable recurrence risks, and available tests, and four questions about patient management, each for six different neurogenetic rare disorders (Hereditary Spastic Paraplegia type 4 and type 7, Huntington Disease, Fragile X-associated Tremor/Ataxia Syndrome, Becker Muscular Dystrophy, and FacioScapuloHumeral Muscular Dystrophy). According to the results of this study, GPT chatbots demonstrated significantly better performance than Gemini. Nonetheless, all AI chatbots showed notable gaps in diagnostic accuracy and a concerning level of hallucinations. As expected, these tools can empower clinicians in assessing neurogenetic disorders, yet their effective use demands meticulous collaboration and oversight from both neurologists and geneticists",genes16010029,PubMed,,2,121,pre: RS,predisposition,"GPT (4o, 4, 3.5) vs Gemini","assisting healthcare professionals,  empower clinicians in assessing neurogenetic disorders",,FALSE,FALSE,TRUE
152,The application of Large Language Models to the phenotype-based prioritization of causative genes in rare disease patients,"Computational methods for identifying gene-disease associations can use both genomic and phenotypic information to prioritize genes and variants that may be associated with genetic diseases. Phenotype-based methods commonly rely on comparing phenotypes observed in a patient with a database of genotype-to-phenotype associations using a measure of semantic similarity, and are primarily limited by the quality and completeness of this database as well as the quality of phenotypes assigned to a patient. Genotype-to-phenotype associations used by these methods are largely derived from literature and coded using phenotype ontologies. Large Language Models (LLMs) have been trained on large amounts of text and have shown their potential to answer complex questions across multiple domains. Here, we demonstrate that LLMs can prioritize disease-associated genes as well, or better than, dedicated bioinformatics methods relying on calculated phenotype similarity. The LLMs use only natural language information as background knowledge and do not require ontology-based phenotyping or structured genotype-to-phenotype knowledge. We use a cohort of undiagnosed patients with rare diseases and show that LLMs can be used to provide diagnostic support that helps in identifying plausible candidate genes",Kafkas2023.11.16.23298615,medrxiv,,2,121,pre: RS,predisposition,LLMs (text only),phenotype-based prioritization of causative genes in rare disease patients,reverse: phenotype to prioritization ,FALSE,FALSE,TRUE
37,Using ChatGPT to Predict Cancer Predisposition Genes: A Promising Tool for Pediatric Oncologists,"Determining genetic susceptibility for cancer predisposition syndromes (CPS) through cancer predisposition genes (CPGs) testing is critical in facilitating appropriate prevention and surveillance strategies. This study investigates the use of ChatGPT, a large language model, in predicting CPGs using clinical notes. Our study involved 53 patients with pathogenic CPG mutations. Two kinds of clinical notes were used: the first visit note, containing a thorough history and physical exam, and the genetic clinic note, summarizing the patient's diagnosis and family history. We asked ChatGPT to recommend CPS genes based on these notes and compared these predictions with previously identified mutations. Rb1 was the most frequently mutated gene in our cohort (34%), followed by NF1 (9.4%), TP53 (5.7%), and VHL (5.7%). Out of 53 patients, 30 had genetic clinic notes of a median length of 54 words. ChatGPT correctly predicted the gene in 93% of these cases. However, it failed to predict EPCAM and VHL genes in specific patients. For the first visit notes (median length: 461 words), ChatGPT correctly predicted the gene in 64% of these cases. ChatGPT shows promise in predicting CPGs from clinical notes, particularly genetic clinic notes. This approach may be useful in enhancing CPG testing, especially in areas lacking genetic testing resources. With further training, there is a possibility for ChatGPT to improve its predictive potential and expand its clinical applicability. However, additional research is needed to explore the full potential and applicability of ChatGPT",Sultan2023-eu,PubMed,,2,121,pre: RS,predisposition,use chagtp on clinical notes,Predict Cancer Predisposition Genes,,FALSE,FALSE,TRUE
44,SRTRP-Net: A multi-task learning network for segmentation and prediction of stereotactic radiosurgery treatment response in brain metastases,"Before the Stereotactic Radiosurgery (SRS) treatment, it is of great clinical significance to avoid secondary genetic damage and guide the personalized treatment plans for patients with brain metastases (BM) by predicting the response to SRS treatment of brain metastatic lesions. Thus, we developed a multi-task learning model termed SRTRP-Net to provide prior knowledge of BM ROI and predict the SRS treatment response of the lesion. In dual-encoder tumor segmentation Network (DTS-Net), two parallel encoders encode the original and mirrored multi-modal MRI images. The differences in the dual-encoder features between foreground and background are enhanced by the symmetrical visual difference block (SVDB). In the bottom layer of the encoder, a transformer is used to extract local contextual features in the spatial and depth dimensions of low-resolution images. Then, the decoder of DTS-Net provides the prior knowledge for predicting the response to SRS treatment by performing BM segmentation. SRS response prediction network (SRP-Net) directly utilizes shared multi-modal MRI features weighted by the signed distance map (SDM) of the masks. The bidirectional multi-dimensional feature fusion module (BMDF) fuses the shared features and the clinical text information features to obtain comprehensive tumor information for characterizing tumors and predicting SRS treatment response. Experiments based on internal and external clinical datasets have shown that SRTRP-Net achieves comparable or better results. We believe that SRTRP-Net can help clinicians accurately develop personalized first-time treatment regimens for BM patients and improve their survival",LIU2024108503,PubMed,,1,122,"pre: RS, ana: MIA",patient,,,predict prior knowledge: treatment response,FALSE,TRUE,FALSE
38,Enhancing patient representation learning from electronic health records through predicted family relations,"Artificial intelligence and machine learning are powerful tools in analyzing electronic health records (EHRs) for healthcare research. Despite the recognized importance of family health history, in healthcare research individual patients are often treated as independent samples, overlooking family relations. To address this gap, we present ALIGATEHR, which models predicted family relations in a graph attention network and integrates this information with a medical ontology representation. Taking disease risk prediction as a use case, we demonstrate that explicitly modeling family relations significantly improves predictions across the disease spectrum. We then show how ALIGATEHRs attention mechanism, which links patients disease risk to their relatives clinical profiles, successfully captures genetic aspects of diseases using only EHR diagnosis data. Finally, we use ALIGATHER to successfully distinguish the two main inflammatory bowel disease subtypes (Crohns disease and ulcerative colitis), illustrating its great potential for improving patient representation learning for predictive and descriptive modeling of EHRs",Huang2024.03.12.24304163,medrxiv,,2,122,pre: RS,patient,family relations using graph attention network,"family history: ALIGATEHR - analyze EHR, predicted family relations",,FALSE,FALSE,TRUE
157,Evolution of publicly available large language models for complex decision-making in breast cancer care,"This study investigated the concordance of five different publicly available Large Language Models (LLM) with the recommendations of a multidisciplinary tumor board regarding treatment recommendations for complex breast cancer patient profiles. Five LLM, including three versions of ChatGPT (version 4 and 3.5, with data access until September 3021 and January 2022), Llama2, and Bard were prompted to produce treatment recommendations for 20 complex breast cancer patient profiles. LLM recommendations were compared to the recommendations of a multidisciplinary tumor board (gold standard), including surgical, endocrine and systemic treatment, radiotherapy, and genetic testing therapy options. GPT4 demonstrated the highest concordance (70.6%) for invasive breast cancer patient profiles, followed by GPT3.5 September 2021 (58.8%), GPT3.5 January 2022 (41.2%), Llama2 (35.3%) and Bard (23.5%). Including precancerous lesions of ductal carcinoma in situ, the identical ranking was reached with lower overall concordance for each LLM (GPT4 60.0%, GPT3.5 September 2021 50.0%, GPT3.5 January 2022 35.0%, Llama2 30.0%, Bard 20.0%). GPT4 achieved full concordance (100%) for radiotherapy. Lowest alignment was reached in recommending genetic testing, demonstrating a varying concordance (55.0% for GPT3.5 January 2022, Llama2 and Bard up to 85.0% for GPT4). This early feasibility study is the first to compare different LLM in breast cancer care with regard to changes in accuracy over time, i.e., with access to more data or through technological upgrades. Methodological advancement, i.e., the optimization of prompting techniques, and technological development, i.e., enabling data input control and secure data processing, are necessary in the preparation of large-scale and multicenter studies to provide evidence on their safe and reliable clinical application. At present, safe and evidenced use of LLM in clinical breast cancer care is not yet feasible",Griewing2024,PubMed,,2,122,pre: RS,patient,evolution of LLM (check quality) in comples decision-making in breast cancer care,,,FALSE,FALSE,TRUE
40,hART: Deep Learning-Informed Lifespan Heart Failure Risk Trajectories,"Heart failure (HF) results in persistent risk and long-term comorbidities. This is particularly true for patients with lifelong HF sequelae of cardiovascular disease such as patients with congenital heart disease (CHD). We developed hART (heart failure Attentive Risk Trajectory), a deep-learning model to predict HF trajectories in CHD patients. hART is designed to capture the contextual relationships between medical events within a patient's history. It is trained to predict future HF risk by using the masked self-attention mechanism that forces it to focus only on the most relevant segments of the past medical events. To demonstrate the utility of hART, we used a large cohort containing healthcare administrative data from the Quebec CHD database (137,493 patients, 35-year follow-up). hART achieves an area under the precision-recall of 28% for HF risk prediction, which is 33% improvement over existing methods. Patients with severe CHD lesion showed a consistently elevated predicted HF risks throughout their lifespan, and patients with genetic syndromes exhibited elevated HF risks until the age of 50. The impact of the birth condition decreases on long-term HF risk. The timing of interventions such as arrhythmia surgery had varying impacts on the lifespan HF risk among the individuals. Arrhythmic surgery performed at a younger age had minimal long-term effects on HF risk, while surgeries during adulthood had a significant lasting impact. Together, we show that hART can detect meaningful lifelong HF risk in CHD patients by capturing both long and short-range dependencies in their past medical events",MOROZ2024105384,"PubMed, medrxiv",,2,122,pre: RS,patient,hART: Deep Learning-Informed Lifespan Heart Failure Risk Trajectories, predict future HF risk by using the masked self-attention mechanism that forces it to focus only on the most relevant segments of the past medical events,,FALSE,FALSE,TRUE
42,MM-SurvNet: Deep Learning-Based Survival Risk Stratification in Breast Cancer Through Multimodal Data Fusion,"Survival risk stratification is an important step in clinical decision making for breast cancer management. We propose a novel deep learning approach for this purpose by integrating histopathological imaging, genetic and clinical data. It employs vision transformers, specifically the MaxViT model, for image feature extraction, and self-attention to capture intricate image relationships at the patient level. A dual cross-attention mechanism fuses these features with genetic data, while clinical data is incorporated at the final layer to enhance predictive accuracy. Experiments on the public TCGA-BRCA dataset show that our model, trained using the negative log likelihood loss function, can achieve superior performance with a mean C-index of 0.64, surpassing existing methods. This advancement facilitates tailored treatment strategies, potentially leading to improved patient outcomes",mondol2024mmsurvnetdeeplearningbasedsurvival,arXiv,,2,122,"pre: RS, ana: MIA",patient,MM-SurvNet: image extraction,Survival risk stratification,,FALSE,FALSE,TRUE
72,MethylGPT: a foundation model for the DNA methylome,"DNA methylation serves as a powerful biomarker for disease diagnosis and biological age assessment. However, current analytical approaches often rely on linear models that cannot capture the complex, context-dependent nature of methylation regulation. Here we present MethylGPT, a transformer-based foundation model trained on 226,555 (154,063 after QC and deduplication) human methylation profiles spanning diverse tissue types from 5,281 datasets, curated 49,156 CpG sites, and 7.6 billion training tokens. MethylGPT learns biologically meaningful representations of CpG sites, capturing both local genomic context and higher-order chromosomal features without external supervision. The model demonstrates robust methylation value prediction (Pearson R=0.929) and maintains stable performance in downstream tasks with up to 70% missing data. Applied to age prediction across multiple tissue types, MethylGPT achieves superior accuracy compared to existing methods. Analysis of the model's attention patterns reveals distinct methylation signatures between young and old samples, with differential enrichment of developmental and aging-associated pathways. When finetuned to mortality and disease prediction across 60 major conditions using 18,859 samples from Generation Scotland, MethylGPT achieves robust predictive performance and enables systematic evaluation of intervention effects on disease risks, demonstrating potential for clinical applications. Our results demonstrate that transformer architectures can effectively model DNA methylation patterns while preserving biological interpretability, suggesting broad utility for epigenetic analysis and clinical applications
==========
DNA methylation serves as a powerful biomarker for disease diagnosis and biological age assessment. However, current analytical approaches often rely on linear models that cannot capture the complex, context-dependent nature of methylation regulation. Here we present MethylGPT, a transformer-based foundation model trained on 226,555 (154,063 after QC and deduplication) human methylation profiles spanning diverse tissue types from 5,281 datasets, curated 49,156 CpG sites, and 7.6 billion training tokens. MethylGPT learns biologically meaningful representations of CpG sites, capturing both local genomic context and higher-order chromosomal features without external supervision. The model demonstrates robust methylation value prediction (Pearson R=0.929) and maintains stable performance in downstream tasks with up to 70% missing data. Applied to age prediction across multiple tissue types, MethylGPT achieves superior accuracy compared to existing methods. Analysis of the models attention patterns reveals distinct methylation signatures between young and old samples, with differential enrichment of developmental and aging-associated pathways. When finetuned to mortality and disease prediction across 60 major conditions using 18,859 samples from Generation Scotland, MethylGPT achieves robust predictive performance and enables systematic evaluation of intervention effects on disease risks, demonstrating potential for clinical applications. Our results demonstrate that transformer architectures can effectively model DNA methylation patterns while preserving biological interpretability, suggesting broad utility for epigenetic analysis and clinical applications",Ying2024-vf,"PubMed,biorxiv",,1,211,ana: AVE,sequence,MethylGPT: transformer-based foundation model," MethylGPT learns biologically meaningful representations of CpG sites, capturing both local genomic context and higher-order chromosomal features without external supervision.",can be used than for multiple purposes,FALSE,TRUE,FALSE
57,Distinguishing word identity and sequence context in DNA language models,"Transformer-based large language models (LLMs) are very suited for biological sequence data, because of analogies to natural language. Complex relationships can be learned, because a concept of ""words"" can be generated through tokenization. Training the models with masked token prediction, they learn both token sequence identity and larger sequence context. We developed methodology to interrogate model learning, which is both relevant for the interpretability of the model and to evaluate its potential for specific tasks. We used DNABERT, a DNA language model trained on the human genome with overlapping k-mers as tokens. To gain insight into the model's learning, we interrogated how the model performs predictions, extracted token embeddings, and defined a fine-tuning benchmarking task to predict the next tokens of different sizes without overlaps. This task evaluates foundation models without interrogating specific genome biology, it does not depend on tokenization strategies, vocabulary size, the dictionary, or the number of training parameters. Lastly, there is no leakage of information from token identity into the prediction task, which makes it particularly useful to evaluate the learning of sequence context. We discovered that the model with overlapping k-mers struggles to learn larger sequence context. Instead, the learned embeddings largely represent token sequence. Still, good performance is achieved for genome-biology-inspired fine-tuning tasks. Models with overlapping tokens may be used for tasks where a larger sequence context is of less relevance, but the token sequence directly represents the desired learning features. This emphasizes the need to interrogate knowledge representation in biological LLMs
==========
Transformer-based large language models (LLMs) are very suited for biological sequence data, because the structure of protein and nucleic acid sequences show many analogies to natural language. Complex relationships in biological sequence can be learned, although there may not be a clear concept of words, because they can be generated through tokenization. Training is subsequently performed for masked token prediction. With this strategy, the models learn both the token sequence identity and a larger sequence context. We developed a framework to interrogate what a model learns, which is both relevant for the interpretability of the model and to evaluate its potential for specific tasks.  We used a DNA language model, which is trained on the human reference genome with a Bidirectional Encoder Representations from Transformers (BERT) model. In this model, tokens are defined with overlapping k-mers. To gain insight into the models learning, we interrogated how the model performs predictions, extracted token embeddings, and defined a fine-tuning benchmarking task to predict the next tokens of different sizes without overlaps. This task is very suited to evaluate different pretrained DNA language models, also called foundation models, since it does not interrogate specific genome biology, does not depend on the tokenization strategy, the size of the vocabulary, the dictionary, or the number of parameters used to train the model. Lastly, the task performs without leakage of information from token identity into the prediction task, which makes it particularly useful to evaluate the learning of sequence context.  Through this assessment we discovered that the model with overlapping k-mers struggles to learn larger sequence context. Instead, the learned embeddings largely represent token sequence. Still, good performance is achieved for genome biology inspired fine-tuning tasks. Models with overlapping tokens may be used for tasks where a larger sequence context is of less relevance, but the token sequence directly represents the desired learning feature. This emphasizes the need to interrogate knowledge representation in biological large language models. Transparency is particularly important for biomedical use cases and an understanding of what the models are learning can be used to match the model to the desired task",Sanabria2024,"PubMed,biorxiv",,2,211,ana: AVE,sequence,used DNABERT," interrogated how the model performs predictions, extracted token embeddings, and defined a fine-tuning benchmarking task to predict the next tokens of different sizes without overlaps",explainability investigations: seqs to understanding patterns,FALSE,FALSE,TRUE
61,GENA-LM: A Family of Open-Source Foundational,"The field of genomics has seen substantial advancements through the application of artificial intelligence (AI), with machine learning revealing the potential to interpret genomic sequences without necessitating an exhaustive experimental analysis of all the intricate and interconnected molecular processes involved in DNA functioning. However, precise decoding of genomic sequences demands the comprehension of rich contextual information spread over thousands of nucleotides. Presently, only a few architectures exist that can process such extensive inputs, and they require exceptional computational resources. To address this need, we introduce GENA-LM, a suite of transformer-based foundational DNA language models capable of handling input lengths up to 36 thousands base pairs. We offer pre-trained versions of GENA-LM and demonstrate their capacity for fine-tuning to address complex biological questions with modest computational requirements. We also illustrate diverse applications of GENA-LM for various downstream genomic tasks, showcasing its performance in either matching or exceeding that of prior models, whether task-specific or universal. All models are publicly accessible on GitHub https://github.com/AIRI-Institute/GENA_LM and as pre-trained models with gena-lm-prefix on HuggingFace https://huggingface.co/AIRI-Institute.",Fishman2023.06.12.544594,bioRxiv,,2,211,ana: AVE,sequence,,,,FALSE,FALSE,TRUE
73,Nucleotide Transformer: building and evaluating robust foundation models for human genomics,"The prediction of molecular phenotypes from DNA sequences remains a longstanding challenge in genomics, often driven by limited annotated data and the inability to transfer learnings between tasks. Here, we present an extensive study of foundation models pre-trained on DNA sequences, named Nucleotide Transformer, ranging from 50 million up to 2.5 billion parameters and integrating information from 3,202 human genomes and 850 genomes from diverse species. These transformer models yield context-specific representations of nucleotide sequences, which allow for accurate predictions even in low-data settings. We show that the developed models can be fine-tuned at low cost to solve a variety of genomics applications. Despite no supervision, the models learned to focus attention on key genomic elements and can be used to improve the prioritization of genetic variants. The training and application of foundational models in genomics provides a widely applicable approach for accurate molecular phenotype prediction from DNA sequence",Dalla-Torre2025,"PubMed, biorxiv",,2,211,ana: AVE,sequence,nucleotide transformer foundation model,foundation model-- multiple tasks,,FALSE,FALSE,TRUE
45,Accurate proteome-wide missense variant effect prediction with AlphaMissense,"INTRODUCTION Genome sequencing has revealed extensive genetic variation in human populations. Missense variants are genetic variants that alter the amino acid sequence of proteins. Pathogenic missense variants disrupt protein function and reduce organismal fitness, while benign missense variants have limited effect. RATIONALE Classifying these variants is an important ongoing challenge in human genetics. Of more than 4 million observed missense variants, only an estimated 2% have been clinically classified as pathogenic or benign, while the vast majority of them are of unknown clinical significance. This limits the diagnosis of rare diseases, as well as the development or application of clinical treatments that target the underlying genetic cause. Machine learning approaches could close the variant interpretation gap by exploiting patterns in biological data to predict the pathogenicity of unannotated variants. Specifically, AlphaFold, which accurately predicts protein structure from protein sequence, may be used as a foundation to predict the pathogenicity of variants on proteins. RESULTS We developed AlphaMissense to leverage advances on multiple fronts: (i) unsupervised protein language modeling to learn amino acid distributions conditioned on sequence context; (ii) incorporating structural context by using an AlphaFold-derived system; and (iii) fine-tuning on weak labels from population frequency data, thereby avoiding bias from human-curated annotations. AlphaMissense achieves state-of-the-art missense pathogenicity predictions in clinical annotation, de novo disease variants, and experimental assay benchmarks without explicitly training on such data. As a resource to the community, we provide a database of predictions for all possible single amino acid substitutions in the human proteome. We classify 32% of all missense variants as likely pathogenic and 57% as likely benign using a cutoff yielding 90% precision on the ClinVar dataset, thereby providing a confident prediction for most human missense variants. We show how this resource can be used to accelerate research in multiple fields. Molecular biologists could use the database as a starting point for designing and interpreting experiments that probe saturating amino acid substitutions across the human proteome. Human geneticists could combine gene-level AlphaMissense predictions with population cohort–based approaches to quantify the functional significance of genes, especially for shorter human genes where cohort-based approaches lack statistical power. Finally, clinicians could benefit from the boost in coverage of confidently classified pathogenic variants when prioritizing de novo variants for rare disease diagnostics, and AlphaMissense predictions could inform studies of complex trait genetics that use annotations of rare, likely deleterious variants. CONCLUSION AlphaMissense predictions may illuminate the molecular effects of variants on protein function, contribute to the identification of pathogenic missense mutations and previously unknown disease-causing genes, and increase the diagnostic yield of rare genetic diseases. AlphaMissense will also foster further development of specialized protein variant effect predictors from structure prediction models.",doi:10.1126/science.adg7492,,,1,212,ana: AVE,effect,,,,FALSE,TRUE,FALSE
68,Inferring the Effects of Protein Variants on Protein-Protein Interactions with Interpretable Transformer Representations,"Identifying pathogenetic variants and inferring their impact on protein-protein interactions sheds light on their functional consequences on diseases. Limited by the availability of experimental data on the consequences of protein interaction, most existing methods focus on building models to predict changes in protein binding affinity. Here, we introduced MIPPI, an end-to-end, interpretable transformer-based deep learning model that learns features directly from sequences by leveraging the interaction data from IMEx. MIPPI was specifically trained to determine the types of variant impact (increasing, decreasing, disrupting, and no effect) on protein-protein interactions. We demonstrate the accuracy of MIPPI and provide interpretation through the analysis of learned attention weights, which exhibit correlations with the amino acids interacting with the variant. Moreover, we showed the practicality of MIPPI in prioritizing de novo mutations associated with complex neurodevelopmental disorders and the potential to determine the pathogenic and driving mutations. Finally, we experimentally validated the functional impact of several variants identified in patients with such disorders. Overall, MIPPI emerges as a versatile, robust, and interpretable model, capable of effectively predicting mutation impacts on protein-protein interactions and facilitating the discovery of clinically actionable variants",Liu2023-vl,PubMed,,1,212,ana: AVE,effect,"MIPPI, an end-to-end, interpretable transformer-based deep learning model that learns features directly from sequences by leveraging the interaction data from IMEx.",predict changes in proein affinity,,FALSE,TRUE,FALSE
53,Boosting GPT Models for Genomics Analysis: Generating Trusted Genetic Variant Annotations and Interpretations through RAG and fine-tuning,"Large language models (LLMs) have acquired a remarkable level of knowledge through their initial training. However, they lack expertise in particular domains such as genomics. Variant annotation data, an important component of genomics, is crucial for interpreting and prioritizing disease-related variants among millions of variants identified by genetic sequencing. In our project, we aimed to improve LLM performance in genomics by adding variant annotation data to LLMs by retrieval-augmented generation (RAG) and fine-tuning techniques. Using RAG, we successfully integrated 190 million highly accurate variant annotations, curated from 5 major annotation datasets and tools, into GPT-4o. This integration empowers users to query specific variants and receive accurate variant annotations and interpretations supported by advanced reasoning and language understanding capabilities of LLMs. Additionally, fine-tuning GPT-4 on variant annotation data also improved model performance in some annotation fields, although the accuracy across more fields remains suboptimal. Our model significantly improved the accessibility and efficiency of the variant interpretation process by leveraging LLM capabilities. Our project also revealed that RAG outperforms fine-tuning in factual knowledge injection in terms of data volume, accuracy, and cost-effectiveness. As a pioneering study for adding genomics knowledge to LLMs, our work paves the way for developing more comprehensive and informative genomics AI systems to support clinical diagnosis and research projects, and it demonstrates the potential of LLMs in specialized domains",10.1093/bioadv/vbaf019,biorxiv,,2,212,"ana: AVE, ana: CVI",effect,rusted Genetic Variant Annotations and Interpretations through RAG and fine-tuning (gpt 4o),,both anno and interpret,FALSE,FALSE,TRUE
56,Deep learning predicts DNA methylation regulatory variants in specific brain cell types and enhances fine mapping for brain disorders,"DNA methylation (DNAm) is essential for brain development and function and potentially mediates the effects of genetic risk variants underlying brain disorders. We present INTERACT, a transformer-based deep learning model to predict regulatory variants impacting DNAm levels in specific brain cell types, leveraging existing single-nucleus DNAm data from the human brain. We show that INTERACT accurately predicts cell type-specific DNAm profiles, achieving an average area under the Receiver Operating Characteristic curve of 0.98 across cell types. Furthermore, INTERACT predicts cell type-specific DNAm regulatory variants, which reflect cellular context and enrich the heritability of brain-related traits in relevant cell types. Importantly, we demonstrate that incorporating predicted variant effects and DNAm levels of CpG sites enhances the fine mapping for three brain disorders-schizophrenia, depression, and Alzheimer's disease-and facilitates mapping causal genes to particular cell types. Our study highlights the power of deep learning in identifying cell type-specific regulatory variants, which will enhance our understanding of the genetics of complex traits
==========
DNA methylation (DNAm) is essential for brain development and function and potentially mediates the effects of genetic risk variants underlying brain disorders. We present INTERACT, a transformer-based deep learning model to predict regulatory variants affecting DNAm levels in specific brain cell types, leveraging existing single-nucleus DNAm data from the human brain. We show that INTERACT accurately predicts cell type-specific DNAm profiles, achieving an average area under the receiver operating characteristic curve of 0.99 across cell types. Furthermore, INTERACT predicts cell type-specific DNAm regulatory variants, which reflect cellular context and enrich the heritability of brain-related traits in relevant cell types. We demonstrate that incorporating predicted variant effects and DNAm levels of CpG sites enhances the fine mapping for three brain disorders-schizophrenia, depression, and Alzheimer's disease-and facilitates mapping causal genes to particular cell types. Our study highlights the power of deep learning in identifying cell type-specific regulatory variants, which will enhance our understanding of the genetics of complex traits
==========
DNA methylation (DNAm) is essential for brain development and function and potentially mediates the effects of genetic risk variants underlying brain disorders. We present INTERACT, a transformer-based deep learning model to predict regulatory variants impacting DNAm levels in specific brain cell types, leveraging existing single-nucleus DNAm data from the human brain. We show that INTERACT accurately predicts cell type-specific DNAm profiles, achieving an average area under the Receiver Operating Characteristic curve of 0.98 across cell types. Furthermore, INTERACT predicts cell type-specific DNAm regulatory variants, which reflect cellular context and enrich the heritability of brain-related traits in relevant cell types. Importantly, we demonstrate that incorporating predicted variant effects and DNAm levels of CpG sites enhances the fine mapping for three brain disorders--schizophrenia, depression, and Alzheimers disease--and facilitates mapping causal genes to particular cell types. Our study highlights the power of deep learning in identifying cell type-specific regulatory variants, which will enhance our understanding of the genetics of complex traits.  TeaserDeep learning reveals genetic variations impacting brain cell type-specific DNA methylation and illuminates genetic bases of brain disorders",Zhou2024-hq,"PubMed,biorxiv",,2,212,ana: AVE,effect,Transformer-based deep learning model (INTERACT);for Prediction of DNA methylation regulatory variants,"Brain disorders (e.g., schizophrenia, depression, Alzheimer’s); methylation data in brain cell types.","INTERACT predicts DNA methylation levels, enhances fine mapping for brain disorders, and identifies causal genes in specific cell types.",FALSE,FALSE,TRUE
58,Emden: A novel method integrating graph and transformer representations for predicting the effect of mutations on clinical drug response,"Precision medicine based on personalized genomics provides promising strategies to enhance the efficacy of molecular-targeted therapies. However, the clinical effectiveness of drugs has been severely limited due to genetic variations that lead to drug resistance. Predicting the impact of missense mutations on clinical drug response is an essential way to reduce the cost of clinical trials and understand genetic diseases. Here, we present Emden, a novel method integrating graph and transformer representations that predicts the effect of missense mutations on drug response through binary classification with interpretability. Emden utilized protein sequences-based features and drug structures as inputs for rapid prediction, employing competitive representation learning and demonstrating strong generalization capabilities and robustness. Our study showed promising potential for clinical drug guidance and deep insight into computer-assisted precision medicine. Emden is freely available as a web server at https://www.psymukb.net/Emden",LIU2023107678,PubMed,,2,212,ana: AVE,effect,graph and transformer representations,predicting the effect of missense mutations on drug response,,FALSE,FALSE,TRUE
63,Generative AI impact on protein stability prediction in breast cancer genes,"The functional classification of a missense variant in cancer predisposition genes is often challenging due to how rare the variant is observed in the population. When available, clinicians utilize a combination of family history, in vitro functional assays and in silico methods to infer protein function. In silico methods, such as missense predictors (predict changes in protein function) and protein stability predictors (predict changes in free energy) have been used to help classify a missense variant in accordance with the American College of Medical Genetics and Genomics (ACMG) guideline. To measure protein stability, many in silico algorithms predict stability based on the change of free energy and most accurate protein stability predictors require a wild-type protein template. In this study, we examine the use of generative AI to predict high-resolution protein structures as templates analyzed with protein stability methods to evaluate loss of function (LOF) activity in cancer predisposition genes BRCA1, BRCA2, PALB2 and RAD51C upon the presence of missense variant. Utilizing multiplexed assay of variant effect measurements and variant classifications from ClinVar, we find that prediction of Gibbs free energy ({Delta}{Delta}G) from AlphaFold2 (AF2) structures analyzed with FoldX predicts LOF better than experimental-derived wild type structures in the BRCT domain of BRCA1 and the DNA binding domain (DBD) of BRCA2, but not in PALB2 and RAD51C. We also find that AF2 structures in the BRCT domain of BRCA1 and DBD-Dss1 domain of BRCA2 analyzed with FoldX measure homologous DNA recombination (HDR) activity significantly better than Rosetta and DDGun3D. Our study also revealed that there are other factors that contribute to predicting loss of function activity other than protein stability, with AlphaMissense ranking the best overall predictor of LOF activity in these tumor suppressor breast cancer genes.  Author SummaryThe stability of a protein, often expressed in terms of Gibbs free energy ({Delta}{Delta}G), is a critical factor in predicting loss of function (LOF) activity when a missense variant is present. The effect is higher in haploinsufficient genes like the tumor suppressor genes BRCA1, BRCA2, PALB2 and RAD51C. Protein stability predictors that utilizes a wild-type structure to make its predictions is often limited by the availability of experimentally-derived protein structures. Here, in our study we show that generative AI, like AlphaFold2 (AF2) can predict structures similar to experimentally-derived structures with high similarity. Furthermore, protein stability tools such as FoldX, Rosetta, and DDGun3D can be used in conjunction to measure changes in stability. From our study, we find that complex AF2 structures representing the BRCT domain of BRCA1 and DBD domain of BRCA2 analyzed by FoldX predicts function significantly better than the experimentally-derived structures. However, predicted |{Delta}{Delta}G| does not predict function better than purpose-built in silico missense predictors for protein function. Overall, we find the AlphaMissense is the best predictor to predict function in these tumor suppressor breast cancer genes",Gnanaolivu2024.06.03.597089,biorxiv,,2,212,ana: AVE,effect," Generative AI (AlphaFold2), protein stability predictors (FoldX, Rosetta) for Protein stability prediction for missense variants.","Breast cancer genes (BRCA1, BRCA2, PALB2, RAD51C); evaluating loss-of-function mutations."," AlphaFold2 predicts protein structures, improving stability predictions for cancer predisposition genes, with AlphaMissense being the best loss-of-function predictor.",FALSE,FALSE,TRUE
80,The EN-TEx resource of multi-tissue personal epigenomes & variant-impact models,"Understanding how genetic variants impact molecular phenotypes is a key goal of functional genomics, currently hindered by reliance on a single haploid reference genome. Here, we present the EN-TEx resource of 1,635 open-access datasets from four donors (∼30 tissues × ∼15 assays). The datasets are mapped to matched, diploid genomes with long-read phasing and structural variants, instantiating a catalog of >1 million allele-specific loci. These loci exhibit coordinated activity along haplotypes and are less conserved than corresponding, non-allele-specific ones. Surprisingly, a deep-learning transformer model can predict the allele-specific activity based only on local nucleotide-sequence context, highlighting the importance of transcription-factor-binding motifs particularly sensitive to variants. Furthermore, combining EN-TEx with existing genome annotations reveals strong associations between allele-specific and GWAS loci. It also enables models for transferring known eQTLs to difficult-to-profile tissues (e.g., from skin to heart). Overall, EN-TEx provides rich data and generalizable models for more accurate personal functional genomics",Rozowsky2023-hd,PubMed,,2,212,ana: AVE,effect," deep-learning transformer model can predict the allele-specific activity based only on local nucleotide-sequence context, highlighting the importance of transcription-factor-binding motifs particularly sensitive to variants. ",,,FALSE,FALSE,TRUE
94,Incomplete Multimodal Learning for Complex Brain Disorders Prediction,"Recent advancements in the acquisition of various brain data sources have created new opportunities for integrating multimodal brain data to assist in early detection of complex brain disorders. However, current data integration approaches typically need a complete set of biomedical data modalities, which may not always be feasible, as some modalities are only available in large-scale research cohorts and are prohibitive to collect in routine clinical practice. Especially in studies of brain diseases, research cohorts may include both neuroimaging data and genetic data, but for practical clinical diagnosis, we often need to make disease predictions only based on neuroimages. As a result, it is desired to design machine learning models which can use all available data (different data could provide complementary information) during training but conduct inference using only the most common data modality. We propose a new incomplete multimodal data integration approach that employs transformers and generative adversarial networks to effectively exploit auxiliary modalities available during training in order to improve the performance of a unimodal model at inference. We apply our new method to predict cognitive degeneration and disease outcomes using the multimodal imaging genetic data from Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort. Experimental results demonstrate that our approach outperforms the related machine learning and deep learning methods by a significant margin",shirkavand2023incompletemultimodallearningcomplex,arXiv,,1,213,ana: AVE,phenotype,new incomplete multimodal data integration approach that employs transformers and generative adversarial networks to effectively exploit auxiliary modalities available during training in order to improve the performance of a unimodal model at inference,predict cognitive degeneration and disease outcomes using the multimodal imaging genetic data from Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort.,,FALSE,TRUE,FALSE
92,GENEVIC: GENetic data Exploration and Visualization via Intelligent interactive Console,"The vast generation of genetic data poses a significant challenge in efficiently uncovering valuable knowledge. Introducing GENEVIC, an AI-driven chat framework that tackles this challenge by bridging the gap between genetic data generation and biomedical knowledge discovery. Leveraging generative AI, notably ChatGPT, it serves as a biologist's ""copilot."" It automates the analysis, retrieval, and visualization of customized domain-specific genetic information, and integrates functionalities to generate protein interaction networks, enrich gene sets, and search scientific literature from PubMed, Google Scholar, and arXiv, making it a comprehensive tool for biomedical research. In its pilot phase, GENEVIC is assessed using a curated database that ranks genetic variants associated with Alzheimer's disease, schizophrenia, and cognition, based on their effect weights from the Polygenic Score (PGS) Catalog, thus enabling researchers to prioritize genetic variants in complex diseases. GENEVIC's operation is user-friendly, accessible without any specialized training, secured by Azure OpenAI's HIPAA-compliant infrastructure, and evaluated for its efficacy through real-time query testing. As a prototype, GENEVIC is set to advance genetic research, enabling informed biomedical decisions. GENEVIC is publicly accessible at https://genevicanath2024.streamlit.app. The underlying code is open-source and available via GitHub at https://github.com/bsml320/GENEVIC.git (also at https://github.com/anath2110/GENEVIC.git)
==========
Summary: The vast generation of genetic data poses a significant challenge in efficiently uncovering valuable knowledge. Introducing GENEVIC, an AI-driven chat framework that tackles this challenge by bridging the gap between genetic data generation and biomedical knowledge discovery. Leveraging generative AI, notably ChatGPT, it serves as a biologist's 'copilot'. It automates the analysis, retrieval, and visualization of customized domain-specific genetic information, and integrates functionalities to generate protein interaction networks, enrich gene sets, and search scientific literature from PubMed, Google Scholar, and arXiv, making it a comprehensive tool for biomedical research. In its pilot phase, GENEVIC is assessed using a curated database that ranks genetic variants associated with Alzheimer's disease, schizophrenia, and cognition, based on their effect weights from the Polygenic Score Catalog, thus enabling researchers to prioritize genetic variants in complex diseases. GENEVIC's operation is user-friendly, accessible without any specialized training, secured by Azure OpenAI's HIPAA-compliant infrastructure, and evaluated for its efficacy through real-time query testing. As a prototype, GENEVIC is set to advance genetic research, enabling informed biomedical decisions.   Availability and implementation: GENEVIC is publicly accessible at https://genevic-anath2024.streamlit.app. The underlying code is open-source and available via GitHub at https://github.com/anath2110/GENEVIC.git",10.1093/bioinformatics/btae500,"arXiv,PubMed",,2,213,ana: AVE,phenotype,"ChatGPT-based for Data exploration, retrieval, and visualization of genetic data.","Exploring genetic variants in complex diseases (Alzheimer's, schizophrenia) with integrated biomedical tools.","GENEVIC integrates PubMed, Google Scholar, and protein interaction networks, helping prioritize variants in complex genetic diseases.",FALSE,FALSE,TRUE
93,Genomics transformer for diagnosing Parkinson's disease,"Parkinson's disease (PD) is the second most common neurodegenerative disease and presents a complex etiology with genomic and environmental factors and no recognized cures. Genotype data, such as single nucleotide polymorphisms (SNPs), could be used as a prodromal factor for early detection of PD. However, the polygenic nature of PD presents a challenge as the complex relationships between SNPs towards disease development are difficult to model. Traditional assessment methods such as polygenic risk scores and machine learning approaches struggle to capture the complex interactions present in the genotype data, thus limiting their discriminative capabilities in diagnosis. On the other hand, deep learning models are better suited for this task. Nevertheless, they encounter difficulties of their own such as a lack of interpretability. To overcome these limitations, in this work, a novel transformer encoder-based model is introduced to classify PD patients from healthy controls based on their genotype. This method is designed to effectively model complex global feature interactions and enable increased interpretability through the learned attention scores. The proposed framework outperformed traditional machine learning models and multilayer perceptron (MLP) baseline models. Moreover, visualization of the learned SNP-SNP associations provides not only interpretability to the model but also valuable insights into the biochemical pathways underlying PD development, which are corroborated by pathway enrichment analysis. Our results suggest novel SNP interactions to be further studied in wet lab and clinical settings",9926815,PubMed,,2,213,ana: AVE,phenotype,Genomics transformer - novel transformer encoder-based model,parcinson disease diagnosis,"goog, that encoder, not decoder:)",FALSE,FALSE,TRUE
67,How to improve polygenic prediction from whole-genome sequencing data by leveraging predicted epigenomic features?,"Polygenic risk scores (PRS) are crucial in genetics for predicting individual susceptibility to complex diseases by aggregating the effects of numerous genetic variants. Whole-genome sequencing (WGS) has revolutionized our ability to detect rare and even de novo variants, creating an exciting opportunity for developing new PRS methods that can effectively leverage rare variants and capture the complex relationships among different variants. Furthermore, regulatory mechanisms play a crucial role in gene expression and disease manifestation, offering avenues to further enhance the performance and interpretation of PRS predictions. Through simulation studies, we highlighted aspects where current PRS methods face challenges when applied to WGS data, aiming to shed light on potential opportunities for further improvement. To address these challenges, we developed Epi-PRS, an approach that leverages the power of genomic large language models (LLM) to impute epigenomic signals across diverse cellular contexts, for use as intermediate variables between genotype and phenotype. A pretrained LLM is employed to transform genotypes into epigenomic signals using personal diploid sequences as inputs, and the genetic risk is then estimated based on the imputed personal epigenomic signals. Epi-PRS enhances the assessment of personal variant impacts, enabling a comprehensive and holistic consideration of genotypic and regulatory information within large genomic regions. Our simulation results demonstrated that incorporating the nuanced effects of non-linear models, rare variants, and regulatory information can provide more precise PRS prediction and better understanding of genetic risk. Applying Epi-PRS to real data from the UK Biobank, our results further showed that Epi-PRS significantly outperforms existing PRS methods in two major diseases: breast cancer and diabetes. This study suggests that PRS methods can benefit from incorporating non-linear models, rare variants, and regulatory information, highlighting the potential for significant advancements in disease risk modeling and enhancing the understanding of precision medicine.  Significance StatementEpi-PRS improves polygenic risk scoring by integrating genomic large language models (LLMs) to impute epigenomic signals as intermediaries between genotype and phenotype. This approach enables a more comprehensive assessment of personal variant impacts by incorporating non-linear models, rare variants, and regulatory mechanisms. By leveraging the power of genomic LLM trained on massive amount of reference epigenomics data, Epi-PRS has demonstrated superior performance over existing PRS methods in predicting genetic risk for breast cancer and diabetes in UK Biobank data. These results highlight the potential of Epi-PRS to improve disease risk modeling and advance the field of precision medicine",Zeng2024.10.04.24314860,medrxiv,,2,213,ana: AVE,phenotype," Epi-PRS, an approach that leverages the power of genomic large language models (LLM) to impute epigenomic signals across diverse cellular contexts, for use as intermediate variables between genotype and phenotype", improve polygenic prediction from whole-genome sequencing data by leveraging predicted epigenomic features,,FALSE,FALSE,TRUE
32,Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models,"Predicting phenotypes with complex genetic bases based on a small, interpretable set of variant features remains a challenging task. Conventionally, data-driven approaches are utilized for this task, yet the high dimensional nature of genotype data makes the analysis and prediction difficult. Motivated by the extensive knowledge encoded in pre-trained LLMs and their success in processing complex biomedical concepts, we set to examine the ability of LLMs in feature selection and engineering for tabular genotype data, with a novel knowledge-driven framework. We develop FREEFORM, Free-flow Reasoning and Ensembling for Enhanced Feature Output and Robust Modeling, designed with chain-of-thought and ensembling principles, to select and engineer features with the intrinsic knowledge of LLMs. Evaluated on two distinct genotype-phenotype datasets, genetic ancestry and hereditary hearing loss, we find this framework outperforms several data-driven methods, particularly on low-shot regimes. FREEFORM is available as open-source framework at GitHub: https://github.com/PennShenLab/FREEFORM",lee2025knowledgedrivenfeatureselectionengineering,arXiv,,2,213,ana: AVE,phenotype,"FREEFORM, Free-flow Reasoning and Ensembling for Enhanced Feature Output and Robust Modeling, designed with chain-of-thought and ensembling principles, to select and engineer features with the intrinsic knowledge of LLMs",feature selection,Chain-Of-Thought!!!!! -- good example,FALSE,FALSE,TRUE
70,Leveraging genomic large language models to enhance causal genotype-brain-clinical pathways in Alzheimer's disease,"Genome-wide association studies (GWAS) have identified numerous Alzheimers disease (AD)- associated variants. However, how these variants contribute to the etiology of AD remains largely elusive. Recent advances in genomic large language models (LLMs) offer new opportunities to interpret the genetic variation observed in personal genome. In this study, we propose epiBrainLLM, a novel computational framework that leverages genomic LLM to enhance our understanding of the causal pathways from genotypes to brain measures to AD-related clinical phenotypes. epiBrainLLM will first convert the personal DNA sequence into a diverse set of genomic and epigenomic features using a pretrained genomic LLM and then use these features to further predict phenotypes. Across various experimental settings, epiBrainLLM significantly improves causal analysis compared to traditional genotype association approach. We conclude that epiBrainLLM provides a novel perspective for understanding the regulatory mechanisms underlying the AD disease etiology, potentially offering insights into complex disease mechanisms beyond AD",Liu2024.10.03.24314824,medrxiv,,2,213,ana: AVE,phenotype,, enhance causal genotype-brain-clinical pathways in Alzheimer's disease,,FALSE,FALSE,TRUE
71,Mechanistic genotype-phenotype translation using hierarchical transformers,"Genome-wide association studies have linked millions of genetic variants to biomedical phenotypes, but their utility has been limited by a lack of mechanistic understanding and widespread epistatic interactions. Recently, Transformer models have emerged as a powerful general-purpose architecture in machine learning, with potential to address these and other challenges. Accordingly, here we introduce the Genotype-to-Phenotype Transformer (G2PT), a framework for modeling hierarchical information flow among variants, genes, multigenic functions, and phenotypes. As proof-of-concept, we use G2PT to model the genetics of TG/HDL (triglycerides to high-density lipoprotein cholesterol), an indicator of metabolic health. G2PT learns to predict this trait via high attention to genetic variants underlying 24 functions, including immune response and cholesterol transport, with accuracy exceeding state-of-the-art. It implicates unexpected epistatic interactions, including those among APOC1 and CETP. This work positions Hierarchical Transformers as a general approach to functionally interpret polygenic risk. The source code is available at https://github.com/idekerlab/G2PT",Lee2024.10.23.619940,biorxiv,,2,213,ana: AVE,phenotype,Genotype-to-Phenotype Transformer (G2PT) - hierarchical transformer,"predict this trait via high attention to genetic variants underlying 24 functions, including immune response and cholesterol transport, with accuracy exceeding state-of-the-art. It implicates unexpected epistatic interactions, including those among APOC1 and CETP.",,FALSE,FALSE,TRUE
78,Scalable and universal prediction of cellular phenotypes,"Biological systems can be understood by perturbing individual components and studying the systems response. Cell biology experiments are defined by the applied treatment, cellular state, and the assayed phenotype. Given the vast number of possible combinations, testing every scenario is impractical. We present Prophet, a transformer-based computational model for cellular phenotype prediction. Prophet learns a representation of the cell biology experiment space, enabling it to predict the outcomes of untested small molecule or genetic perturbations in new cellular contexts across diverse phenotypes including gene expression, cell viability, and cell morphology. Its scalable architecture facilitates training across independent assays, using transfer learning to enhance performance across phenotypes. In vitro validation shows Prophets potential to guide experimental design, making it a valuable tool for accelerating biological discovery",Ji2024.08.12.607533,biorxiv,,2,213,ana: AVE,phenotype,prophet -- transforer for cellular phenotype prediction,"predict the outcomes of untested small molecule or genetic perturbations in new cellular contexts across diverse phenotypes including gene expression, cell viability, and cell morphology",,FALSE,FALSE,TRUE
79,Tabular deep learning: a comparative study applied to multi-task genome-wide prediction,"More accurate prediction of phenotype traits can increase the success of genomic selection in both plant and animal breeding studies and provide more reliable disease risk prediction in humans. Traditional approaches typically use regression models based on linear assumptions between the genetic markers and the traits of interest. Non-linear models have been considered as an alternative tool for modeling genomic interactions (i.e. non-additive effects) and other subtle non-linear patterns between markers and phenotype. Deep learning has become a state-of-the-art non-linear prediction method for sound, image and language data. However, genomic data is better represented in a tabular format. The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports successful results on various datasets. Tabular deep learning applications in genome-wide prediction (GWP) are still rare. In this work, we perform an overview of the main families of recent deep learning architectures for tabular data and apply them to multi-trait regression and multi-class classification for GWP on real gene datasets. The study involves an extensive overview of recent deep learning architectures for tabular data learning: NODE, TabNet, TabR, TabTransformer, FT-Transformer, AutoInt, GANDALF, SAINT and LassoNet. These architectures are applied to multi-trait GWP. Comprehensive benchmarks of various tabular deep learning methods are conducted to identify best practices and determine their effectiveness compared to traditional methods. Extensive experimental results on several genomic datasets (three for multi-trait regression and two for multi-class classification) highlight LassoNet as a standout performer, surpassing both other tabular deep learning models and the highly efficient tree based LightGBM method in terms of both best prediction accuracy and computing efficiency. Through series of evaluations on real-world genomic datasets, the study identifies LassoNet as a standout performer, surpassing decision tree methods like LightGBM and other tabular deep learning architectures in terms of both predictive accuracy and computing efficiency. Moreover, the inherent variable selection property of LassoNet provides a systematic way to find important genetic markers that contribute to phenotype expression",Fan2024,PubMed,,2,213,ana: AVE,phenotype," extensive overview of recent deep learning architectures for tabular data learning: NODE, TabNet, TabR, TabTransformer, FT-Transformer, AutoInt, GANDALF, SAINT and LassoNet. These architectures are applied to multi-trait GWP",multi-task tabular genome-wide prediction,,FALSE,FALSE,TRUE
88,Deep structured learning for variant prioritization in Mendelian diseases,"Effective computer-aided or automated variant evaluations for monogenic diseases will expedite clinical diagnostic and research efforts of known and novel disease-causing genes. Here we introduce MAVERICK: a Mendelian Approach to Variant Effect pRedICtion built in Keras. MAVERICK is an ensemble of transformer-based neural networks that can classify a wide range of protein-altering single nucleotide variants (SNVs) and indels and assesses whether a variant would be pathogenic in the context of dominant or recessive inheritance. We demonstrate that MAVERICK outperforms all other major programs that assess pathogenicity in a Mendelian context. In a cohort of 644 previously solved patients with Mendelian diseases, MAVERICK ranks the causative pathogenic variant within the top five variants in over 95% of cases. Seventy-six percent of cases were solved by the top-ranked variant. MAVERICK ranks the causative pathogenic variant in hitherto novel disease genes within the first five candidate variants in 70% of cases. MAVERICK has already facilitated the identification of a novel disease gene causing a degenerative motor neuron disease. These results represent a significant step towards automated identification of causal variants in patients with Mendelian diseases",Danzi2023,PubMed,,2,221,ana: CVI,classify,Maverick (transformer-based neural network); ML Task: Variant effect prediction for Mendelian (monogenic) diseases.  -> also for dna-level,Prioritization of pathogenic variants in Mendelian diseases using SNVs and indels.,"Maverick ranks causative pathogenic variants within the top five in 95% of cases, improving diagnostic accuracy in Mendelian disorders.",FALSE,FALSE,TRUE
64,Genetic Transformer: An Innovative Large Language Model Driven Approach for Rapid and Accurate Identification of Causative Variants in Rare Genetic Diseases,"BackgroundIdentifying causative variants is crucial for the diagnosis of rare genetic diseases. Over the past two decades, the application of genome sequencing technologies in the field has significantly improved diagnostic outcomes. However, the complexity of data analysis and interpretation continues to limit the efficiency and accuracy of these applications. Various genotype and phenotype-driven filtering and prioritization strategies are used to generate a candidate list of variants for expert curation, with the final report variants determined through knowledge-intensive and labor-intensive expert review. Despite these efforts, the current methods fall short of meeting the growing demand for accurate and efficient diagnosis of rare disease. Recent developments in large language models (LLMs) suggest that LLMs possess the potential to augment or even supplant human labor in this context.  MethodsIn this study, we have developed Genetic Transformer (GeneT), an innovative large language model (LLM) driven approach to accelerate identification of candidate causative variants for rare genetic disease. A comprehensive evaluation was conducted between the fine-tuned large language models and four phenotype-driven methods, including Xrare, Exomiser, PhenIX and PHIVE, alongside six pre-trained LLMs (Qwen1.5-0.5B, Qwen1.5-1.8B, Qwen1.5-4B, Mistral-7B, Meta-Llama-3-8B, Meta-Llama-3-70B). This evaluation focused on performance and hallucinations.  ResultsGenetic Transformer (GeneT) as an innovative LLM-driven approach demonstrated outstanding performance on identification of candidate causative variants, identified the average number of candidate causative variants reduced from an average of 418 to 8, achieving recall rate of 99% in synthetic datasets. Application in real-world clinical setting demonstrated the potential for a 20-fold increase in processing speed, reducing the time required to analyze each sample from approximately 60 minutes to around 3 minutes. Concurrently, the recall rate has improved from 94.36% to 97.85%. An online analysis platform iGeneT was developed to integrate GeneT into the workflow of rare genetic disease analysis.  ConclusionOur study represents the inaugural application of fine-tuned LLMs for identifying candidate causative variants, introducing GeneT as an innovative LLM-driven approach, demonstrating its superiority in both simulated data and real-world clinical setting. The study is unique in that it represents a paradigm shift in addressing the complexity of variant filtering and prioritization of whole exome or genome sequencing data, effectively resolving the challenge akin to finding a needle in a haystack",Liang2024.07.18.24310666,medrxiv,,2,221,ana: CVI,classify,"Genetic Transformer (Genet), fine-tuned LLMs; ML Task: Variant filtering and prioritization for rare genetic diseases.",Identification of causative variants in whole exome or genome sequencing data for rare genetic diseases.,"Genet reduces the average number of candidate variants with high recall rate, speeding up variant analysis by 20x.",FALSE,FALSE,TRUE
95,Integrating Large Language Models for Genetic Variant Classification,"The classification of genetic variants, particularly Variants of Uncertain Significance (VUS), poses a significant challenge in clinical genetics and precision medicine. Large Language Models (LLMs) have emerged as transformative tools in this realm. These models can uncover intricate patterns and predictive insights that traditional methods might miss, thus enhancing the predictive accuracy of genetic variant pathogenicity.   This study investigates the integration of state-of-the-art LLMs, including GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data alongside structural insights to form a comprehensive analytical framework for variant classification. Our approach evaluates these integrated models using the well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in classification performance. The models were rigorously tested on a set of challenging variants, demonstrating substantial improvements over existing state-of-the-art tools, especially in handling ambiguous and clinically uncertain variants.   The results of this research underline the efficacy of combining multiple modeling approaches to significantly refine the accuracy and reliability of genetic variant classification systems. These findings support the deployment of these advanced computational models in clinical environments, where they can significantly enhance the diagnostic processes for genetic disorders, ultimately pushing the boundaries of personalized medicine by offering more detailed and actionable genetic insights",boulaimen2024integratinglargelanguagemodels,arXiv,,2,221,ana: CVI,classify," integration of state-of-the-art LLMs, including GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data alongside structural insights to form a comprehensive analytical framework for variant classification",Genetic Variant Classificationm particularry VUS on proteinGYM and clinvar datasets,,FALSE,FALSE,TRUE
102,VarChat: the generative AI assistant for the interpretation of human genomic variations,"In the modern era of genomic research, the scientific community is witnessing an explosive growth in the volume of published findings. While this abundance of data offers invaluable insights, it also places a pressing responsibility on genetic professionals and researchers to stay informed about the latest findings and their clinical significance. Genomic variant interpretation is currently facing a challenge in identifying the most up-to-date and relevant scientific papers, while also extracting meaningful information to accelerate the process from clinical assessment to reporting. Computer-aided literature search and summarization can play a pivotal role in this context. By synthesizing complex genomic findings into concise, interpretable summaries, this approach facilitates the translation of extensive genomic datasets into clinically relevant insights. To bridge this gap, we present VarChat (varchat.engenome.com), an innovative tool based on generative AI, developed to find and summarize the fragmented scientific literature associated with genomic variants into brief yet informative texts. VarChat provides users with a concise description of specific genetic variants, detailing their impact on related proteins and possible effects on human health. In addition, VarChat offers direct links to related scientific trustable sources, and encourages deeper research. varchat.engenome.com",De_Paoli2024-jy,PubMed,,2,221,ana: CVI,classify,Generative AI for Literature search and summarization of genomic variant findings.,Interpretation of genomic variants using summarized scientific literature.,"VarChat summarizes genomic variant data from scientific literature, aiding clinical and research insights.",FALSE,FALSE,TRUE
85,Assessing the Utility of Large Language Models for Phenotype-Driven Gene Prioritization in Rare Genetic Disorder Diagnosis,"Phenotype-driven gene prioritization is a critical process in the diagnosis of rare genetic disorders for identifying and ranking potential disease-causing genes based on observed physical traits or phenotypes. While traditional approaches rely on curated knowledge graphs with phenotype-gene relations, recent advancements in large language models have opened doors to the potential of AI predictions through extensive training on diverse corpora and complex models. This study conducted a comprehensive evaluation of five large language models, including two Generative Pre-trained Transformers series, and three Llama2 series, assessing their performance across three key metrics: task completeness, gene prediction accuracy, and adherence to required output structures. Various experiments explored combinations of models, prompts, input types, and task difficulty levels. Our findings reveal that even the best-performing LLM, GPT-4, achieved an accuracy of 16.0%, which still lags behind traditional bioinformatics tools. Prediction accuracy increased with the parameter/model size. A similar increasing trend was observed for the task completion rate, with complicated prompts more likely to increase task completeness in models smaller than GPT-4. However, complicated prompts are more likely to decrease the structure compliance rate, but no prompt effects on GPT-4. Compared to HPO term-based input, LLM was also able to achieve better than random prediction accuracy by taking free-text input, but slightly lower than with the HPO input. Bias analysis showed that certain genes, such as MECP2, CDKL5, and SCN1A, are more likely to be top-ranked, potentially explaining the variances observed across different datasets. This study provides valuable insights into the integration of LLMs within genomic analysis, contributing to the ongoing discussion on the utilization of advanced LLMs in clinical workflows",Kim2024,"arXiv,PubMed",,2,222,"ana: CVI, disc",prioritize," GPT-4, achieved an accuracy of 16.0%, which still lags behind traditional bioinformatics tools",Phenotype-Driven Gene Prioritization in Rare Genetic Disorder Diagnosis,"wrong usage: gpt is generation -- encoder, not ""embedding"" - better use decoders",FALSE,FALSE,TRUE
97,MGI: Multimodal Contrastive pre-training of Genomic and Medical Imaging,"Medicine is inherently a multimodal discipline. Medical images can reflect the pathological changes of cancer and tumors, while the expression of specific genes can influence their morphological characteristics. However, most deep learning models employed for these medical tasks are unimodal, making predictions using either image data or genomic data exclusively. In this paper, we propose a multimodal pre-training framework that jointly incorporates genomics and medical images for downstream tasks. To address the issues of high computational complexity and difficulty in capturing long-range dependencies in genes sequence modeling with MLP or Transformer architectures, we utilize Mamba to model these long genomic sequences. We aligns medical images and genes using a self-supervised contrastive learning approach which combines the Mamba as a genetic encoder and the Vision Transformer (ViT) as a medical image encoder. We pre-trained on the TCGA dataset using paired gene expression data and imaging data, and fine-tuned it for downstream tumor segmentation tasks. The results show that our model outperformed a wide range of related methods",zhou2024mgimultimodalcontrastivepretraining,arXiv,,2,222,"ana: CVI, ana: MIA",prioritize,"Mamba to model these long genomic sequences (capture lkong term dependencies), aligns medical images and genes",downstream tumor segmentantion task,,FALSE,FALSE,TRUE
98,PhenoSV: interpretable phenotype-aware model for the prioritization of genes affected by structural variants,"Structural variants (SVs) represent a major source of genetic variation associated with phenotypic diversity and disease susceptibility. While long-read sequencing can discover over 20,000 SVs per human genome, interpreting their functional consequences remains challenging. Existing methods for identifying disease-related SVs focus on deletion/duplication only and cannot prioritize individual genes affected by SVs, especially for noncoding SVs. Here, we introduce PhenoSV, a phenotype-aware machine-learning model that interprets all major types of SVs and genes affected. PhenoSV segments and annotates SVs with diverse genomic features and employs a transformer-based architecture to predict their impacts under a multiple-instance learning framework. With phenotype information, PhenoSV further utilizes gene-phenotype associations to prioritize phenotype-related SVs. Evaluation on extensive human SV datasets covering all SV types demonstrates PhenoSV's superior performance over competing methods. Applications in diseases suggest that PhenoSV can determine disease-related genes from SVs. A web server and a command-line tool for PhenoSV are available at https://phenosv.wglab.org ",Xu2023-tq,PubMed,,2,222,ana: CVI,prioritize,PhenoSV: interpretable phenotype-aware model, prioritization of genes affected by structural variants, segments and annotates SVs with diverse genomic features and employs a transformer-based architecture to predict their impacts under a multiple-instance learning framework,FALSE,FALSE,TRUE
108,A Feature-Fusion Technique-Based Alzheimer's Disease Classification Using Magnetic Resonance Imaging,"Early identification of Alzheimer's disease (AD) is essential for optimal treatment and management. Deep learning (DL) technologies, including convolutional neural networks (CNNs) and vision transformers (ViTs) can provide promising outcomes in AD diagnosis. However, these technologies lack model interpretability and demand substantial computational resources, causing challenges in the resource-constrained environment. Hybrid ViTs can outperform individual ViTs by visualizing key features with limited computational power. This synergy enhances feature extraction and promotes model interpretability. Thus, the authors present an innovative model for classifying AD using MRI images with limited computational resources. The authors improved the AD feature-extraction process by modifying the existing ViTs. A CatBoost-based classifier was used to classify the extracted features into multiple classes. The proposed model was generalized using the OASIS dataset. The model obtained an exceptional classification accuracy of 98.8% with a minimal loss of 0.12. The findings highlight the potential of the proposed AD classification model in providing an interpretable and resource-efficient solution for healthcare centers. To improve model robustness and applicability, subsequent research can include genetic and clinical data",diagnostics14212363,PubMed,,1,231,ana: MIA,abnormalities, Feature-Fusion using magnetic-resonanse imaging + ViT,clasisfying MRI using limited resources,Hybrid ViTs can outperform individual ViTs by visualizing key features with limited computational power. This synergy enhances feature extraction and promotes model interpretability.,FALSE,TRUE,FALSE
115,CKD-TransBTS: Clinical Knowledge-Driven Hybrid Transformer With Modality-Correlated Cross-Attention for Brain Tumor Segmentation,"Brain tumor segmentation (BTS) in magnetic resonance image (MRI) is crucial for brain tumor diagnosis, cancer management and research purposes. With the great success of the ten-year BraTS challenges as well as the advances of CNN and Transformer algorithms, a lot of outstanding BTS models have been proposed to tackle the difficulties of BTS in different technical aspects. However, existing studies hardly consider how to fuse the multi-modality images in a reasonable manner. In this paper, we leverage the clinical knowledge of how radiologists diagnose brain tumors from multiple MRI modalities and propose a clinical knowledge-driven brain tumor segmentation model, called CKD-TransBTS. Instead of directly concatenating all the modalities, we re-organize the input modalities by separating them into two groups according to the imaging principle of MRI. A dual-branch hybrid encoder with the proposed modality-correlated cross-attention block (MCCA) is designed to extract the multi-modality image features. The proposed model inherits the strengths from both Transformer and CNN with the local feature representation ability for precise lesion boundaries and long-range feature extraction for 3D volumetric images. To bridge the gap between Transformer and CNN features, we propose a Trans&CNN Feature Calibration block (TCFC) in the decoder. We compare the proposed model with six CNN-based models and six transformer-based models on the BraTS 2021 challenge dataset. Extensive experiments demonstrate that the proposed model achieves state-of-the-art brain tumor segmentation performance compared with all the competitors",Lin2023-yd,PubMed,,1,231,"ana: MIA, pre: KNLR",abnormalities,Knowledge navigation + computer vision,,"also pre:KNLR, not only ana:MIA - since we navigate knowledges",FALSE,TRUE,FALSE
118,Dual-task kidney MR segmentation with transformers in autosomal-dominant polycystic kidney disease,"Autosomal-dominant polycystic kidney disease is a prevalent genetic disorder characterized by the development of renal cysts, leading to kidney enlargement and renal failure. Accurate measurement of total kidney volume through polycystic kidney segmentation is crucial to assess disease severity, predict progression and evaluate treatment effects. Traditional manual segmentation suffers from intra- and inter-expert variability, prompting the exploration of automated approaches. In recent years, convolutional neural networks have been employed for polycystic kidney segmentation from magnetic resonance images. However, the use of Transformer-based models, which have shown remarkable performance in a wide range of computer vision and medical image analysis tasks, remains unexplored in this area. With their self-attention mechanism, Transformers excel in capturing global context information, which is crucial for accurate organ delineations. In this paper, we evaluate and compare various convolutional-based, Transformers-based, and hybrid convolutional/Transformers-based networks for polycystic kidney segmentation. Additionally, we propose a dual-task learning scheme, where a common feature extractor is followed by per-kidney decoders, towards better generalizability and efficiency. We extensively evaluate various architectures and learning schemes on a heterogeneous magnetic resonance imaging dataset collected from 112 patients with polycystic kidney disease. Our results highlight the effectiveness of Transformer-based models for polycystic kidney segmentation and the relevancy of exploiting dual-task learning to improve segmentation accuracy and mitigate data scarcity issues. A promising ability in accurately delineating polycystic kidneys is especially shown in the presence of heterogeneous cyst distributions and adjacent cyst-containing organs. This work contribute to the advancement of reliable delineation methods in nephrology, paving the way for a broad spectrum of clinical applications",CONZE2024102349,PubMed,,1,231,ana: MIA,abnormalities,,kidney MR segmentation with transformers," no link to genetics, but the disease itself is genetic",FALSE,TRUE,FALSE
111,Approximating facial expression effects on diagnostic accuracy via generative AI in medical genetics,"Artificial intelligence (AI) is increasingly used in genomics research and practice, and generative AI has garnered significant recent attention. In clinical applications of generative AI, aspects of the underlying datasets can impact results, and confounders should be studied and mitigated. One example involves the facial expressions of people with genetic conditions. Stereotypically, Williams (WS) and Angelman (AS) syndromes are associated with a ""happy"" demeanor, including a smiling expression. Clinical geneticists may be more likely to identify these conditions in images of smiling individuals. To study the impact of facial expression, we analyzed publicly available facial images of approximately 3500 individuals with genetic conditions. Using a deep learning (DL) image classifier, we found that WS and AS images with non-smiling expressions had significantly lower prediction probabilities for the correct syndrome labels than those with smiling expressions. This was not seen for 22q11.2 deletion and Noonan syndromes, which are not associated with a smiling expression. To further explore the effect of facial expressions, we computationally altered the facial expressions for these images. We trained HyperStyle, a GAN-inversion technique compatible with StyleGAN2, to determine the vector representations of our images. Then, following the concept of InterfaceGAN, we edited these vectors to recreate the original images in a phenotypically accurate way but with a different facial expression. Through online surveys and an eye-tracking experiment, we examined how altered facial expressions affect the performance of human experts. We overall found that facial expression is associated with diagnostic accuracy variably in different genetic conditions",Patel2024-jf,PubMed,,2,232,ana: MIA,risk evaluation,"Generative AI (GAN-based, HyperStyle + StyleGAN2) for Image classification, facial expression analysis."," Diagnosis of genetic syndromes (Williams, Angelman); facial image data.",generative AI's role in altering facial expressions to study their effect on genetic syndrome diagnosis accuracy.,FALSE,FALSE,TRUE
114,BioFusionNet: Deep Learning-Based Survival Risk Stratification in ER+ Breast Cancer Through Multifeature and Multimodal Data Fusion,"Breast cancer is a significant health concern affecting millions of women worldwide. Accurate survival risk stratification plays a crucial role in guiding personalised treatment decisions and improving patient outcomes. Here we present BioFusionNet, a deep learning framework that fuses image-derived features with genetic and clinical data to obtain a holistic profile and achieve survival risk stratification of ER+ breast cancer patients. We employ multiple self-supervised feature extractors (DINO and MoCoV3) pretrained on histopathological patches to capture detailed image features. These features are then fused by a variational autoencoder and fed to a self-attention network generating patient-level features. A co-dual-cross-attention mechanism combines the histopathological features with genetic data, enabling the model to capture the interplay between them. Additionally, clinical data is incorporated using a feed-forward network, further enhancing predictive performance and achieving comprehensive multimodal feature integration. Furthermore, we introduce a weighted Cox loss function, specifically designed to handle imbalanced survival data, which is a common challenge. Our model achieves a mean concordance index of 0.77 and a time-dependent area under the curve of 0.84, outperforming state-of-the-art methods. It predicts risk (high versus low) with prognostic significance for overall survival in univariate analysis (HR=2.99, 95% CI: 1.88-4.78, p 0.005), and maintains independent significance in multivariate analysis incorporating standard clinicopathological variables (HR=2.91, 95% CI: 1.80-4.68, p 0.005)
==========
Breast cancer is a significant health concern affecting millions of women worldwide. Accurate survival risk stratification plays a crucial role in guiding personalised treatment decisions and improving patient outcomes. Here we present BioFusionNet, a deep learning framework that fuses image-derived features with genetic and clinical data to obtain a holistic profile and achieve survival risk stratification of ER+ breast cancer patients. We employ multiple self-supervised feature extractors (DINO and MoCoV3) pretrained on histopathological patches to capture detailed image features. These features are then fused by a variational autoencoder and fed to a self-attention network generating patient-level features. A co-dual-cross-attention mechanism combines the histopathological features with genetic data, enabling the model to capture the interplay between them. Additionally, clinical data is incorporated using a feed-forward network, further enhancing predictive performance and achieving comprehensive multimodal feature integration. Furthermore, we introduce a weighted Cox loss function, specifically designed to handle imbalanced survival data, which is a common challenge. Our model achieves a mean concordance index of 0.77 and a time-dependent area under the curve of 0.84, outperforming state-of-the-art methods. It predicts risk (high versus low) with prognostic significance for overall survival in univariate analysis (HR=2.99, 95% CI: 1.88--4.78, p<0.005), and maintains independent significance in multivariate analysis incorporating standard clinicopathological variables (HR=2.91, 95\% CI: 1.80--4.68, p<0.005)",Mondol_2024,"arXiv,PubMed",,2,232,"ana: MIA, post: DRA",risk evaluation,Multifeature and Multimodal Data Fusion,risk stratification + cancer,here more insights how MIA and PRS related ,FALSE,FALSE,TRUE
116,CroMAM: A Cross-Magnification Attention Feature Fusion Model for Predicting Genetic Status and Survival of Gliomas using Histological Images,"Predicting the gene mutation status in whole slide images (WSI) is crucial for the clinical treatment, cancer management, and research of gliomas. With advancements in CNN and Transformer algorithms, several promising models have been proposed. However, existing studies have paid little attention on fusing multi-magnification information, and the model requires processing all patches from a whole slide image. In this paper, we propose a cross-magnification attention model called CroMAM for predicting the genetic status and survival of gliomas. The CroMAM first utilizes a systematic patch extraction module to sample a subset of representative patches for downstream analysis. Next, the CroMAM applies Swin Transformer to extract local and global features from patches at different magnifications, followed by acquiring high-level features and dependencies among single-magnification patches through the application of a Vision Transformer. Subsequently, the CroMAM exchanges the integrated feature representations of different magnifications and encourage the integrated feature representations to learn the discriminative information from other magnification. Additionally, we design a cross-magnification attention analysis method to examine the effect of cross-magnification attention quantitatively and qualitatively which increases the model's explainability. To validate the performance of the model, we compare the proposed model with other multi-magnification feature fusion models on three tasks in two datasets. Extensive experiments demonstrate that the proposed model achieves state-of-the-art performance in predicting the genetic status and survival of gliomas. The implementation of the CroMAM will be publicly available upon the acceptance of this manuscript at https://github.com/GuoJisen/CroMAM",10605027,PubMed,,2,232,ana: MIA,risk evaluation,"CroMAM: A Cross-Magnification Attention Feature Fusion Model for Predicting Genetic Status and Survival of Gliomas using Histological Images.   Swin Transformer to extract local and global features from patches at different magnifications, followed by acquiring high-level features and dependencies among single-magnification patches through the application of a Vision Transformer",Predicting the gene mutation status and survival in gliomas in whole slide images (WSI) ,,FALSE,FALSE,TRUE
121,GestaltMML: Enhancing Rare Genetic Disease Diagnosis through Multimodal Machine Learning Combining Facial Images and Clinical Texts,"Individuals with suspected rare genetic disorders often undergo multiple clinical evaluations, imaging studies, laboratory tests and genetic tests, to find a possible answer over a prolonged period of time. Addressing this ""diagnostic odyssey"" thus has substantial clinical, psychosocial, and economic benefits. Many rare genetic diseases have distinctive facial features, which can be used by artificial intelligence algorithms to facilitate clinical diagnosis, in prioritizing candidate diseases to be further examined by lab tests or genetic assays, or in helping the phenotype-driven reinterpretation of genome/exome sequencing data. Existing methods using frontal facial photos were built on conventional Convolutional Neural Networks (CNNs), rely exclusively on facial images, and cannot capture non-facial phenotypic traits and demographic information essential for guiding accurate diagnoses. Here we introduce GestaltMML, a multimodal machine learning (MML) approach solely based on the Transformer architecture. It integrates facial images, demographic information (age, sex, ethnicity), and clinical notes (optionally, a list of Human Phenotype Ontology terms) to improve prediction accuracy. Furthermore, we also evaluated GestaltMML on a diverse range of datasets, including 528 diseases from the GestaltMatcher Database, several in-house datasets of Beckwith-Wiedemann syndrome (BWS, over-growth syndrome with distinct facial features), Sotos syndrome (overgrowth syndrome with overlapping features with BWS), NAA10-related neurodevelopmental syndrome, Cornelia de Lange syndrome (multiple malformation syndrome), and KBG syndrome (multiple malformation syndrome). Our results suggest that GestaltMML effectively incorporates multiple modalities of data, greatly narrowing candidate genetic diagnoses of rare diseases and may facilitate the reinterpretation of genome/exome sequencing data",wu2024gestaltmmlenhancingraregenetic,"arXiv,PubMed",,2,232,"ana: MIA, pre: RS",risk evaluation,,Rare Genetic Disease Diagnosis through Multimodal Machine Learning Combining Facial Images and Clinical Texts,,FALSE,FALSE,TRUE
105,Identifying facial phenotypes of genetic disorders using deep learning,"Syndromic genetic conditions, in aggregate, affect 8% of the population1. Many syndromes have recognizable facial features2 that are highly informative to clinical geneticists3,4,5. Recent studies show that facial analysis technologies measured up to the capabilities of expert clinicians in syndrome identification6,7,8,9. However, these technologies identified only a few disease phenotypes, limiting their role in clinical settings, where hundreds of diagnoses must be considered. Here we present a facial image analysis framework, DeepGestalt, using computer vision and deep-learning algorithms, that quantifies similarities to hundreds of syndromes. DeepGestalt outperformed clinicians in three initial experiments, two with the goal of distinguishing subjects with a target syndrome from other syndromes, and one of separating different genetic subtypes in Noonan syndrome. On the final experiment reflecting a real clinical setting problem, DeepGestalt achieved 91% top-10 accuracy in identifying the correct syndrome on 502 different images. The model was trained on a dataset of over 17,000 images representing more than 200 syndromes, curated through a community-driven phenotyping platform. DeepGestalt potentially adds considerable value to phenotypic evaluations in clinical genetics, genetic testing, research and precision medicine.",Gurovich2019,,,2,232,ana: MIA,risk evaluation,,,,FALSE,FALSE,TRUE
109,A novel transformer-based aggregation model for predicting gene mutations in lung adenocarcinoma,"In recent years, predicting gene mutations on whole slide imaging (WSI) has gained prominence. The primary challenge is extracting global information and achieving unbiased semantic aggregation. To address this challenge, we propose a novel Transformer-based aggregation model, employing a self-learning weight aggregation mechanism to mitigate semantic bias caused by the abundance of features in WSI. Additionally, we adopt a random patch training method, which enhances model learning richness by randomly extracting feature vectors from WSI, thus addressing the issue of limited data. To demonstrate the model's effectiveness in predicting gene mutations, we leverage the lung adenocarcinoma dataset from Shandong Provincial Hospital for prior knowledge learning. Subsequently, we assess TP53, CSMD3, LRP1B, and TTN gene mutations using lung adenocarcinoma tissue pathology images and clinical data from The Cancer Genome Atlas (TCGA). The results indicate a notable increase in the AUC (Area Under the ROC Curve) value, averaging 4%, attesting to the model's performance improvement. Our research offers an efficient model to explore the correlation between pathological image features and molecular characteristics in lung adenocarcinoma patients. This model introduces a novel approach to clinical genetic testing, expected to enhance the efficiency of identifying molecular features and genetic testing in lung adenocarcinoma patients, ultimately providing more accurate and reliable results for related studies",Sun2024,PubMed,,2,233,"ana: MIA, pre: KNLR",predict genetics,"novel Transformer-based aggregation model, employing a self-learning weight aggregation mechanism to mitigate semantic bias caused by the abundance of features in WSI + use clinical data genome atlas",predicting gene mutations on whole slide imaging (WSI) - achieving unbiased semantic aggregation,"use of texts, atlases during images processing => thats why knlr",FALSE,FALSE,TRUE
49,A robust and lightweight deep attention multiple instance learning algorithm for predicting genetic alterations,"Self-attention mechanism-based algorithms are attractive in digital pathology due to their interpretability, but suffer from computation complexity. This paper presents a novel, lightweight Attention-based Multiple Instance Mutation Learning (AMIML) model to allow small-scale attention operations for predicting gene mutations. Compared to the standard self-attention model, AMIML reduces the number of model parameters by approximately 70%. Using data for 24 clinically relevant genes from four cancer cohorts in TCGA studies (UCEC, BRCA, GBM, and KIRC), we compare AMIML with a standard self-attention model, five other deep learning models, and four traditional machine learning models. The results show that AMIML has excellent robustness and outperforms all the baseline algorithms in the vast majority of the tested genes. Conversely, the performance of the reference deep learning and machine learning models vary across different genes, and produce suboptimal prediction for certain genes. Furthermore, with the flexible and interpretable attention-based pooling mechanism, AMIML can further zero in and detect predictive image patches",GUO2023102189,PubMed,,2,233,ana: MIA,predict genetics,lightweight Attention-based Multiple Instance Mutation Learning (AMIML) model to allow small-scale attention operations for predicting gene mutations,predict genetic alterations from WSI,,FALSE,FALSE,TRUE
54,ChromTR: chromosome detection in raw metaphase cell images via deformable transformers,"Chromosome karyotyping is a critical way to diagnose various hematological malignancies and genetic diseases, of which chromosome detection in raw metaphase cell images is the most critical and challenging step. In this work, focusing on the joint optimization of chromosome localization and classification, we propose ChromTR to accurately detect and classify 24 classes of chromosomes in raw metaphase cell images. ChromTR incorporates semantic feature learning and class distribution learning into a unified DETR-based detection framework. Specifically, we first propose a Semantic Feature Learning Network (SFLN) for semantic feature extraction and chromosome foreground region segmentation with object-wise supervision. Next, we construct a Semantic-Aware Transformer (SAT) with two parallel encoders and a Semantic-Aware decoder to integrate global visual and semantic features. To provide a prediction with a precise chromosome number and category distribution, a Category Distribution Reasoning Module (CDRM) is built for foreground-background objects and chromosome class distribution reasoning. We evaluate ChromTR on 1404 newly collected R-band metaphase images and the public G-band dataset AutoKary2022. Our proposed ChromTR outperforms all previous chromosome detection methods with an average precision of 92.56% in R-band chromosome detection, surpassing the baseline method by 3.02%. In a clinical test, ChromTR is also confident in tackling normal and numerically abnormal karyotypes. When extended to the chromosome enumeration task, ChromTR also demonstrates state-of-the-art performances on R-band and G-band two metaphase image datasets. Given these superior performances to other methods, our proposed method has been applied to assist clinical karyotype diagnosis",Xia2024,PubMed,,2,233,ana: MIA,predict genetics,vision transformer (semantic aware transformer) for karyotyping,,,FALSE,FALSE,TRUE
120,Genetic InfoMax: Exploring Mutual Information Maximization in High-Dimensional Imaging Genetics Studies,"Genome-wide association studies (GWAS) are used to identify relationships between genetic variations and specific traits. When applied to high-dimensional medical imaging data, a key step is to extract lower-dimensional, yet informative representations of the data as traits. Representation learning for imaging genetics is largely under-explored due to the unique challenges posed by GWAS in comparison to typical visual representation learning. In this study, we tackle this problem from the mutual information (MI) perspective by identifying key limitations of existing methods. We introduce a trans-modal learning framework Genetic InfoMax (GIM), including a regularized MI estimator and a novel genetics-informed transformer to address the specific challenges of GWAS. We evaluate GIM on human brain 3D MRI data and establish standardized evaluation protocols to compare it to existing approaches. Our results demonstrate the effectiveness of GIM and a significantly improved performance on GWAS",xie2023geneticinfomaxexploringmutual,"arXiv,PubMed",,2,233,"ana: MIA, ana: AVE",predict genetics,"Genetics-informed transformer,  Representation learning in high-dimensional genomic and imaging data.",GWAS with MRI imaging data; predicting genetic traits from medical images.,a framework to improve genetic trait prediction from high-dimensional medical imaging data.,FALSE,FALSE,TRUE
122,KRASFormer: a fully vision transformer-based framework for predictingKRASgene mutations in histopathological images of colorectal cancer,"Detecting the Kirsten Rat Sarcoma Virus (KRAS) gene mutation is significant for colorectal cancer (CRC) patients. TheKRASgene encodes a protein involved in the epidermal growth factor receptor (EGFR) signaling pathway, and mutations in this gene can negatively impact the use of monoclonal antibodies in anti-EGFR therapy and affect treatment decisions. Currently, commonly used methods like next-generation sequencing (NGS) identifyKRASmutations but are expensive, time-consuming, and may not be suitable for every cancer patient sample. To address these challenges, we have developedKRASFormer, a novel framework that predictsKRASgene mutations from Haematoxylin and Eosin (H & E) stained WSIs that are widely available for most CRC patients.KRASFormerconsists of two stages: the first stage filters out non-tumor regions and selects only tumour cells using a quality screening mechanism, and the second stage predicts theKRASgene either wildtype' or mutant' using a Vision Transformer-based XCiT method. The XCiT employs cross-covariance attention to capture clinically meaningful long-range representations of textural patterns in tumour tissue andKRASmutant cells. We evaluated the performance of the first stage using an independent CRC-5000 dataset, and the second stage included both The Cancer Genome Atlas colon and rectal cancer (TCGA-CRC-DX) and in-house cohorts. The results of our experiments showed that the XCiT outperformed existing state-of-the-art methods, achieving AUCs for ROC curves of 0.691 and 0.653 on TCGA-CRC-DX and in-house datasets, respectively. Our findings emphasize three key consequences: the potential of using H & E-stained tissue slide images for predictingKRASgene mutations as a cost-effective and time-efficient means for guiding treatment choice with CRC patients; the increase in performance metrics of a Transformer-based model; and the value of the collaboration between pathologists and data scientists in deriving a morphologically meaningful model",Singh2024-ut,PubMed,,2,233,"ana: MIA, post: PCS",predict genetics,vision transformer - KRASFormer, Kirsten Rat Sarcoma Virus (KRAS) gene mutation  prediction from images,,FALSE,FALSE,TRUE
74,Predicting Genetic Mutation from Whole Slide Images via Biomedical-Linguistic Knowledge Enhanced Multi-label Classification,"Predicting genetic mutations from whole slide images is indispensable for cancer diagnosis. However, existing work training multiple binary classification models faces two challenges: (a) Training multiple binary classifiers is inefficient and would inevitably lead to a class imbalance problem. (b) The biological relationships among genes are overlooked, which limits the prediction performance. To tackle these challenges, we innovatively design a Biological-knowledge enhanced PathGenomic multi-label Transformer to improve genetic mutation prediction performances. BPGT first establishes a novel gene encoder that constructs gene priors by two carefully designed modules: (a) A gene graph whose node features are the genes' linguistic descriptions and the cancer phenotype, with edges modeled by genes' pathway associations and mutation consistencies. (b) A knowledge association module that fuses linguistic and biomedical knowledge into gene priors by transformer-based graph representation learning, capturing the intrinsic relationships between different genes' mutations. BPGT then designs a label decoder that finally performs genetic mutation prediction by two tailored modules: (a) A modality fusion module that firstly fuses the gene priors with critical regions in WSIs and obtains gene-wise mutation logits. (b) A comparative multi-label loss that emphasizes the inherent comparisons among mutation status to enhance the discrimination capabilities. Sufficient experiments on The Cancer Genome Atlas benchmark demonstrate that BPGT outperforms the state-of-the-art",huang2024predictinggeneticmutationslide,arXiv,,2,233,ana: MIA,predict genetics,pedict mutation,"whole slide imaging, cancer",,FALSE,FALSE,TRUE
141,Prediction of molecular subclasses of uveal melanoma by deep learning using routine haematoxylin-eosin-stained tissue slides,"Uveal melanoma has a high propensity to metastasize. Prognosis is associated with specific driver mutations and copy number variations, and these can only be obtained after genetic testing. In this study we evaluated the efficacy of patient outcome prediction using deep learning on haematoxylin and eosin (HE)-stained primary uveal melanoma slides in comparison to molecular testing. In this retrospective study of patients with uveal melanoma, 113 patients from the Erasmus Medical Centre who underwent enucleation had tumour tissue analysed for molecular classification between 1993 and 2020. Routine HE-stained slides were scanned to obtain whole-slide images (WSI). After annotation of regions of interest, tiles of 1024 × 1024 pixels were extracted at a magnification of 40×. An ablation study to select the best-performing deep-learning model was carried out using three state-of-the-art deep-learning models (EfficientNet, Vision Transformer, and Swin Transformer). Deep-learning models were subjected to a training cohort (n = 40), followed by a validation cohort (n = 20), and finally underwent a test cohort (n = 48). A k-fold cross-validation (k = 3) of validation and test cohorts (n = 113 of three classes: BAP1, SF3B1, EIF1AX) demonstrated Swin Transformer as the best-performing deep-learning model to predict molecular subclasses based on HE stains. The model achieved an accuracy of 0.83 ± 0.09 on the validation cohort and 0.75 ± 0.04 on the test cohort. Within the subclasses, this model correctly predicted 70% BAP1-mutated, 61% SF3B1-mutated and 80% EIF1AX-mutated UM in the test set. This study showcases the potential of the deep-learning methodology for predicting molecular subclasses in a multiclass manner using HE-stained WSI. This development holds promise for advanced prognostication of UM patients without the need of molecular or immunohistochemical testing. Additionally, this study suggests there are distinct histopathological features per subclass; mainly utilizing epithelioid cellular morphology for BAP1-classification, but an unknown feature distinguishes EIF1AX and SF3B1",Akram2024-zn,PubMed,,2,233,ana: MIA; post: PCS,predict genetics,swin transformer,molecular subclasses of uveal melanoma,,FALSE,FALSE,TRUE
75,Prompting Whole Slide Image Based Genetic Biomarker Prediction,"Prediction of genetic biomarkers, e.g., microsatellite instability and BRAF in colorectal cancer is crucial for clinical decision making. In this paper, we propose a whole slide image (WSI) based genetic biomarker prediction method via prompting techniques. Our work aims at addressing the following challenges: (1) extracting foreground instances related to genetic biomarkers from gigapixel WSIs, and (2) the interaction among the fine-grained pathological components in WSIs.Specifically, we leverage large language models to generate medical prompts that serve as prior knowledge in extracting instances associated with genetic biomarkers. We adopt a coarse-to-fine approach to mine biomarker information within the tumor microenvironment. This involves extracting instances related to genetic biomarkers using coarse medical prior knowledge, grouping pathology instances into fine-grained pathological components and mining their interactions. Experimental results on two colorectal cancer datasets show the superiority of our method, achieving 91.49% in AUC for MSI classification. The analysis further shows the clinical interpretability of our method. Code is publicly available at https://github.com/DeepMed-Lab-ECNU/PromptBio",zhang2024promptingslideimagebased,arXiv,,2,233,ana: MIA,predict genetics,PromptBio model: text+img encoders +MLP,"whole slide imaging, cancer",,FALSE,FALSE,TRUE
126,Single-cell Heterogeneity-aware Transformer-guided Multiple Instance Learning for Cancer Aneuploidy Prediction from Whole Slide Histopathology Images,"Aneuploidy is a hallmark of aggressive malignancies associated with therapeutic resistance and poor survival. Measuring aneuploidy requires expensive specialized techniques that are not clinically applicable. Deep learning analysis of routine histopathology slides has revealed associations with genetic mutations. However, existing studies focus on image patches or tiles, and there is no prior work that predicts aneuploidy using single-cell analysis. Here, we present a single-cell heterogeneity-aware and transformer-guided deep learning framework to predict aneuploidy from whole slide histopathology images. First, we perform nuclei segmentation and classification to obtain individual cancer cells, which are clustered into multiple subtypes. The cell subtype distributions are computed to measure cancer cell heterogeneity. Additionally, morphological features of different cell subtypes are extracted. Further, we leverage a multiple instance learning module with Transformer, which encourages the network to focus on the most informative cancer cells. Lastly, a hybrid network is built to unify cell heterogeneity, morphology, and deep features for aneuploidy prediction. We train and validate our method on two public datasets from TCGA: lung adenocarcinoma (LUAD) and head and neck squamous cell carcinoma (HNSC), with 339 and 245 patients. Our model achieves promising performance with AUC of 0.818 (95% CI: 0.718-0.919) and 0.827 (95% CI: 0.704-0.949) on the LUAD and HNSC test sets, respectively. Through extensive ablation and comparison studies, we demonstrate the effectiveness of each component of the model and superior performance over alternative networks. In conclusion, we present a novel deep learning approach to predict aneuploidy from histopathology images, which could inform personalized cancer treatment",10083175,PubMed,,2,233,"ana: MIA, post: PCS",predict genetics, single-cell heterogeneity-aware and transformer-guided deep learning framework,Slide Histopathology Images for cancer prediction  on Single cell,,FALSE,FALSE,TRUE
127,Tokensome: Towards a Genetic Vision-Language GPT for Explainable and Cognitive Karyotyping,"Automatic karyotype analysis is often defined as a visual perception task focused solely on chromosomal object-level modeling. This definition has led most existing methods to overlook componential and holistic information, significantly constraining model performance. Moreover, the lack of interpretability in current technologies hinders clinical adoption. In this paper, we introduce Tokensome, a novel vision-language model based on chromosome tokenization for explainable and cognitive karyotyping. Tokensome elevates the method from the conventional visual perception layer to the cognitive decision-making layer. This elevation enables the integration of domain knowledge and cognitive reasoning via knowledge graphs and LLMs, markedly enhancing model's explainability and facilitating abnormality detection",zhang2024tokensomegeneticvisionlanguagegpt,arXiv,,2,233,ana: MIA,predict genetics,vision transformers for karyotyping,,,FALSE,FALSE,TRUE
138,Ensemble transformer-based multiple instance learning to predict pathological subtypes and tumor mutational burden from histopathological whole slide images of endometrial and colorectal cancer,"In endometrial cancer (EC) and colorectal cancer (CRC), in addition to microsatellite instability, tumor mutational burden (TMB) has gradually gained attention as a genomic biomarker that can be used clinically to determine which patients may benefit from immune checkpoint inhibitors. High TMB is characterized by a large number of mutated genes, which encode aberrant tumor neoantigens, and implies a better response to immunotherapy. Hence, a part of EC and CRC patients associated with high TMB may have higher chances to receive immunotherapy. TMB measurement was mainly evaluated by whole-exome sequencing or next-generation sequencing, which was costly and difficult to be widely applied in all clinical cases. Therefore, an effective, efficient, low-cost and easily accessible tool is urgently needed to distinguish the TMB status of EC and CRC patients. In this study, we present a deep learning framework, namely Ensemble Transformer-based Multiple Instance Learning with Self-Supervised Learning Vision Transformer feature encoder (ETMIL-SSLViT), to predict pathological subtype and TMB status directly from the H&E stained whole slide images (WSIs) in EC and CRC patients, which is helpful for both pathological classification and cancer treatment planning. Our framework was evaluated on two different cancer cohorts, including an EC cohort with 918 histopathology WSIs from 529 patients and a CRC cohort with 1495 WSIs from 594 patients from The Cancer Genome Atlas. The experimental results show that the proposed methods achieved excellent performance and outperforming seven state-of-the-art (SOTA) methods in cancer subtype classification and TMB prediction on both cancer datasets. Fisher's exact test further validated that the associations between the predictions of the proposed models and the actual cancer subtype or TMB status are both extremely strong (p<0.001). These promising findings show the potential of our proposed methods to guide personalized treatment decisions by accurately predicting the EC and CRC subtype and the TMB status for effective immunotherapy planning for EC and CRC patients",WANG2025103372,PubMed,,2,311,"post: PCS, ana: MIA",disease,Ensemble  transformer-based multiple instance learning, predict pathological subtypes and tumor mutational burden from histopathological whole slide images,,FALSE,FALSE,TRUE
140,"Identifying Progression-Specific Alzheimer's Subtypes Using Multimodal Transformer
==========
Multimodal Neurodegenerative Disease Subtyping Explained by ChatGPT","Alzheimer's disease (AD) is the most prevalent neurodegenerative disease, yet its current treatments are limited to stopping disease progression. Moreover, the effectiveness of these treatments remains uncertain due to the heterogeneity of the disease. Therefore, it is essential to identify disease subtypes at a very early stage. Current data-driven approaches can be used to classify subtypes during later stages of AD or related disorders, but making predictions in the asymptomatic or prodromal stage is challenging. Furthermore, the classifications of most existing models lack explainability, and these models rely solely on a single modality for assessment, limiting the scope of their analysis. Thus, we propose a multimodal framework that utilizes early-stage indicators, including imaging, genetics, and clinical assessments, to classify AD patients into progression-specific subtypes at an early stage. In our framework, we introduce a tri-modal co-attention mechanism (Tri-COAT) to explicitly capture cross-modal feature associations. Data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) (slow progressing = 177, intermediate = 302, and fast = 15) were used to train and evaluate Tri-COAT using a 10-fold stratified cross-testing approach. Our proposed model outperforms baseline models and sheds light on essential associations across multimodal features supported by known biological mechanisms. The multimodal design behind Tri-COAT allows it to achieve the highest classification area under the receiver operating characteristic curve while simultaneously providing interpretability to the model predictions through the co-attention mechanism
==========
Alzheimer's disease (AD) is the most prevalent neurodegenerative disease; yet its currently available treatments are limited to stopping disease progression. Moreover, effectiveness of these treatments is not guaranteed due to the heterogenetiy of the disease. Therefore, it is essential to be able to identify the disease subtypes at a very early stage. Current data driven approaches are able to classify the subtypes at later stages of AD or related disorders, but struggle when predicting at the asymptomatic or prodromal stage. Moreover, most existing models either lack explainability behind the classification or only use a single modality for the assessment, limiting scope of its analysis. Thus, we propose a multimodal framework that uses early-stage indicators such as imaging, genetics and clinical assessments to classify AD patients into subtypes at early stages. Similarly, we build prompts and use large language models, such as ChatGPT, to interpret the findings of our model. In our framework, we propose a tri-modal co-attention mechanism (Tri-COAT) to explicitly learn the cross-modal feature associations. Our proposed model outperforms baseline models and provides insight into key cross-modal feature associations supported by known biological mechanisms",jpm14040421,"PubMed,arXiv",,2,311,post: PCS,disease,"Multimodal Transformer (Tri-COAT); ML Task: Subtyping Alzheimer's disease using multimodal data (imaging, genetics, clinical).",Early-stage Alzheimer's disease subtype classification using multimodal data.,"Tri-COAT framework classifies AD subtypes using imaging, genetic, and clinical data",FALSE,FALSE,TRUE
160,Large language models as a diagnostic support tool in neuropathology,"The WHO guidelines for classifying central nervous system (CNS) tumours are changing considerably with each release. The classification of CNS tumours is uniquely complex among most other solid tumours as it incorporates not just morphology, but also genetic and epigenetic features. Keeping current with these changes across medical fields can be challenging, even for clinical specialists. Large language models (LLMs) have demonstrated their ability to parse and process complex medical text, but their utility in neuro-oncology has not been systematically tested. We hypothesised that LLMs can effectively diagnose neuro-oncology cases from free-text histopathology reports according to the latest WHO guidelines. To test this hypothesis, we evaluated the performance of ChatGPT-4o, Claude-3.5-sonnet, and Llama3 across 30 challenging neuropathology cases, which each presented a complex mix of morphological and genetic information relevant to the diagnosis. Furthermore, we integrated these models with the latest WHO guidelines through Retrieval-Augmented Generation (RAG) and again assessed their diagnostic accuracy. Our data show that LLMs equipped with RAG, but not without RAG, can accurately diagnose the neuropathological tumour subtype in 90% of the tested cases. This study lays the groundwork for a new generation of computational tools that can assist neuropathologists in their daily reporting practice",https://doi.org/10.1002/2056-4538.70009,PubMed,,2,311,post: PCS,disease,"developed rag, using WHO guidlines",Retrieval-Augmented Generation (RAG) and again assessed their diagnostic accuracy,!! used guidlines of who,FALSE,FALSE,TRUE
137,Deep representation learning for clustering longitudinal survival data from electronic health records,"Precision medicine can be defined as providing the right treatment to the right patient at the right time, and it requires the ability to identify clinically relevant patient subgroups with high accuracy. The increasing availability of large-scale electronic health records (EHR) datasets has provided major opportunities for artificial intelligence and machine learning in mining such complex datasets for identifying novel disease subtypes. However, disease subtypes often exist in the context of certain disease-relevant risk events, and current efforts have been limited by analyzing clustering and event risk independently, resulting in subgroups that still display great heterogeneity in event risk and/or underlying molecular mechanisms.  To address this problem, we developed TransVarSur (Transformer Variational Survival modeling). TransVarSur integrates a Transformer-based Gaussian mixture variational autoencoder with time-to-event modeling to capture complex relationships between cluster-specific EHR trajectories and survival times. We validated TransVarSur by showing superior performance relative to baseline methods, on both synthetic and real-world benchmark datasets with known ground-truth clustering. We then applied TransVarSur to 1908 Crohns disease patients from the UK Biobank and successfully identified four clusters displaying both divergent EHR trajectories and divergent progression towards the risk event intestinal obstruction. A further analysis of the clusters revealed known clinical and genetic factors relevant in Crohns disease and progression to intestinal obstruction.  In conclusion, we demonstrated TransVarSurs ability to accurately stratify a patient population into clinically and genetically relevant, risk-associated subgroups. Hence, it can be a powerful tool in the development of precision medicine approaches",Qiu2024.01.11.24301148,medrxiv,,2,312,post: PCS,patient,Transformer-based Variational Autoencoder (TransVarSur) for Clustering EHR data with survival analysis.,Crohn's disease; clustering patient subgroups based on EHR trajectories and survival data.,"TransVarSur stratifies patients into clinically relevant subgroups, aiding precision medicine for Crohn's disease.",FALSE,FALSE,TRUE
145,Interpretation knowledge extraction for genetic testing via question-answer model,"Sequencing-based genetic testing is widely used in biomedical research, including pathogenic microorganism detection with metagenomic next-generation sequencing (mNGS). The application of sequencing results to clinical diagnosis and treatment relies on various interpretation knowledge bases. Currently, the existing knowledge bases are primarily built through manual knowledge extraction. This method requires professionals to read extensive literature and extract relevant knowledge from it, which is time-consuming and costly. Furthermore, manual extraction unavoidably introduces subjective biases. In this study, we aimed to automatically extract knowledge for interpreting mNGS results. We propose a novel approach to automatically extract pathogenic microorganism knowledge based on the question-answer (QA) model. First, we construct a MicrobeDB dataset since there is no available pathogenic microorganism QA dataset for training the model. The created dataset contains 3,161 samples from 618 published papers covering 224 pathogenic microorganisms. Then, we fine-tune the selected baseline model based on MicrobeDB. Finally, we utilize ChatGPT to enhance the diversity of training data, and employ data expansion to increase training data volume. Our method achieves an Exact Match (EM) and F1 score of 88.39% and 93.18%, respectively, on the MicrobeDB test set. We also conduct ablation studies on the proposed data augmentation method. In addition, we perform comparative experiments with the ChatPDF tool based on the ChatGPT API to demonstrate the effectiveness of the proposed method. Our method is effective and valuable for extracting pathogenic microorganism knowledge",Wang2024-hv,PubMed,,1,321,post: DRA,interpret, novel approach to automatically extract pathogenic microorganism knowledge based on the question-answer (QA) mode using chatGPT,mNGS results -> clinical diagnosis,,FALSE,TRUE,FALSE
161,Unpacking unstructured data: A pilot study on extracting insights from neuropathological reports of Parkinson's Disease patients using large language models,"The aim of this study was to make unstructured neuropathological data, located in the NeuroBioBank (NBB), follow Findability, Accessibility, Interoperability, and Reusability principles and investigate the potential of large language models (LLMs) in wrangling unstructured neuropathological reports. By making the currently inconsistent and disparate data findable, our overarching goal was to enhance research output and speed. The NBB catalog currently includes information from medical records, interview results, and neuropathological reports. These reports contain crucial information necessary for conducting an in-depth analysis of NBB data but have multiple formats that vary across different NBB biorepositories and change over time. In this study, we focused on a subset of 822 donors with Parkinson's disease (PD) from seven NBB biorepositories. We developed a data model with combined Brain Region and Pathological Findings data at its core. This approach made it easier to build an extraction pipeline and was flexible enough to convert resulting data to Common Data Elements, a standardized data collection tool used by the neuroscience community to improve consistency and facilitate data sharing across studies. This pilot study demonstrated the potential of LLMs in structuring unstructured neuropathological reports of PD patients available in the NBB. The pipeline enabled successful extraction of detailed tissue-level (microscopic) and gross anatomical (macroscopic) observations, along with staging information from pathology reports, with extraction quality comparable to manual curation results. To our knowledge, this is the first attempt to automatically standardize neuropathological information at this scale. The collected data have the potential to serve as a valuable resource for PD researchers, facilitating integration with clinical information and genetic data (such as genome-wide genotyping and whole-genome sequencing) available through the NBB, thereby enabling a more comprehensive understanding of the disease",Stroganov2023.09.12.557252,"PubMed, biorxiv",,1,321,post: DRA,interpret,Large Language Models for Structuring unstructured neuropathological data from reports.,Parkinson's disease; structuring neuropathological data for research.,"LLMs successfully standardize neuropathological reports, enabling integration with genetic and clinical data.",FALSE,TRUE,FALSE
144,CPAE: Contrastive predictive autoencoder for unsupervised pre-training in health status prediction,"Fully-supervised learning approaches have shown promising results in some health status prediction tasks using Electronic Health Records (EHRs). These traditional approaches rely on sufficient labeled data to learn from. However, in practice, acquiring large-scaled labeled medical data for various prediction tasks is often not feasible. Thus, it is of great interest to utilize contrastive pre-training to leverage the unlabeled information. In this work, we propose a novel data-efficient framework, contrastive predictive autoencoder (CPAE), to first learn without labels from the EHR data in the pre-training process, and then fine-tune on the downstream tasks. Our framework comprises of two parts: (i) a contrastive learning process, inherited from contrastive predictive coding (CPC), which aims to extract global slow-varying features, and (ii) a reconstruction process, which forces the encoder to capture local features. We also introduce the attention mechanism in one variant of our framework to balance the above two processes. Experiments on real-world EHR dataset verify the effectiveness of our proposed framework on two downstream tasks (i.e., in-hospital mortality prediction and length-of-stay prediction), compared to their supervised counterparts, the CPC model, and other baseline models. By comprising of both contrastive learning components and reconstruction components, CPAE aims to extract both global slow-varying information and local transient information. The best results on two downstream tasks are all achieved by CPAE. The variant AtCPAE is particularly superior when fine-tuned on very small training data. Further work may incorporate techniques of multi-task learning to optimize the pre-training process of CPAEs. Moreover, this work is based on the benchmark MIMIC-III dataset which only includes 17 variables. Future work may extend to a larger number of variables",zhou2024mgimultimodalcontrastivepretraining,PubMed,,1,322,post: DRA,predict,CPAE: Contrastive predictive autoencoder for unsupervised pre-training,data aggregation and health status prediction,,FALSE,TRUE,FALSE
149,Longitudinal modeling of multimorbidity trajectories using large language models,"Multimorbidity, the co-occurrence of two or more chronic conditions within an individual, is a major and escalating global health challenge, complicating treatment regimens, straining healthcare resources, and worsening patient outcomes. The complex interplay of shared genetic predispositions, biological pathways, and socioeconomic factors underpins its development, but clinical and research efforts have largely focused on managing diseases in isolation. Understanding multimorbidity trajectories--the accumulation and interaction of chronic diseases over time--is essential to improving preventive strategies and optimizing personalized care. Here, we introduce ForeSITE (Forecasting Susceptibility to Illness with Transformer Embeddings), a novel, transformer-based framework that harnesses advanced machine learning to predict multimorbidity progression. By analyzing longitudinal data from 480,000 participants in the UK Biobank, ForeSITE identifies distinct patterns in the co-occurrence and timing of diseases. Our temporal disease network provides insights into how certain diseases might share common genetic, environmental, or socioeconomic factors, offering more specific guidance for earlier detection and more effective disease management",Yang2024.10.02.24314786,medrxiv,,1,322,post: DRA,predict,"ForeSITE (Forecasting Susceptibility to Illness with Transformer Embeddings), a novel, transformer-based framework that harnesses advanced machine learning to ",predict multimorbidity progression.,,FALSE,TRUE,FALSE
142,A Deep Attention-Based Encoder for the Prediction of Type 2 Diabetes Longitudinal Outcomes from Routinely Collected Health Care Data,"Recent evidence indicates that Type 2 Diabetes Mellitus (T2DM) is a complex and highly heterogeneous disease involving various pathophysiological and genetic pathways, which presents clinicians with challenges in disease management. While deep learning models have made significant progress in helping practitioners manage T2DM treatments, several important limitations persist. In this paper we propose DARE, a model based on the transformer encoder, designed for analyzing longitudinal heterogeneous diabetes data. The model can be easily fine-tuned for various clinical prediction tasks, enabling a computational approach to assist clinicians in the management of the disease. We trained DARE using data from over 200,000 diabetic subjects from the primary healthcare SIDIAP database, which includes diagnosis and drug codes, along with various clinical and analytical measurements. After an unsupervised pre-training phase, we fine-tuned the model for predicting three specific clinical outcomes: i) occurrence of comorbidity, ii) achievement of target glycaemic control (defined as glycated hemoglobin < 7%) and iii) changes in glucose-lowering treatment. In cross-validation, the embedding vectors generated by DARE outperformed those from baseline models (comorbidities prediction task AUC = 0.88, treatment prediction task AUC = 0.91, HbA1c target prediction task AUC = 0.82). Our findings suggest that attention-based encoders improve results with respect to different deep learning and classical baseline models when used to predict different clinical relevant outcomes from T2DM longitudinal data",MANZINI2025126876,medrxiv,,2,322,post: DRA,predict," DARE, a model based on the transformer encoder, designed for analyzing longitudinal heterogeneous diabetes data","can be easily fine-tuned for various clinical prediction tasks, enabling a computational approach to assist clinicians in the management of the disease (e.g. occurrence of comorbidity, ii) achievement of target glycaemic control (defined as glycated hemoglobin < 7%) and iii) changes in glucose-lowering treatmen)",,FALSE,FALSE,TRUE
87,Comparative Analysis of Generative Pre-Trained Transformer Models in Oncogene-Driven Non-Small Cell Lung Cancer: Introducing the Generative Artificial Intelligence Performance Score,"Precision oncology in non-small cell lung cancer (NSCLC) relies on biomarker testing for clinical decision making. Despite its importance, challenges like the lack of genomic oncology training, nonstandardized biomarker reporting, and a rapidly evolving treatment landscape hinder its practice. Generative artificial intelligence (AI), such as ChatGPT, offers promise for enhancing clinical decision support. Effective performance metrics are crucial to evaluate these models' accuracy and their propensity for producing incorrect or hallucinated information. We assessed various ChatGPT versions' ability to generate accurate next-generation sequencing reports and treatment recommendations for NSCLC, using a novel Generative AI Performance Score (G-PS), which considers accuracy, relevancy, and hallucinations. We queried ChatGPT versions for first-line NSCLC treatment recommendations with an Food and Drug Administration-approved targeted therapy, using a zero-shot prompt approach for eight oncogenes. Responses were assessed against National Comprehensive Cancer Network (NCCN) guidelines for accuracy, relevance, and hallucinations, with G-PS calculating scores from -1 (all hallucinations) to 1 (fully NCCN-compliant recommendations). G-PS was designed as a composite measure with a base score for correct recommendations (weighted for preferred treatments) and a penalty for hallucinations. Analyzing 160 responses, generative pre-trained transformer (GPT)-4 outperformed GPT-3.5, showing higher base score (90% v 60%; P < .01) and fewer hallucinations (34% v 53%; P < .01). GPT-4's overall G-PS was significantly higher (0.34 v -0.15; P < .01), indicating superior performance. This study highlights the rapid improvement of generative AI in matching treatment recommendations with biomarkers in precision oncology. Although the rate of hallucinations improved in the GPT-4 model, future generative AI use in clinical care requires high levels of accuracy with minimal to no room for hallucinations. The GP-S represents a novel metric quantifying generative AI utility in health care compared with national guidelines, with potential adaptation beyond precision oncology",Hamilton2024-cw,PubMed,,2,323,post: DRA,recommend,"various ChatGPT versions' ability to generate accurate next-generation sequencing reports and treatment recommendations for NSCLC, ",,"assessed using a novel Generative AI Performance Score (G-PS), which considers accuracy, relevancy, and hallucinations -- new BENCHMARK",FALSE,FALSE,TRUE
193,Toxic Epidermal Necrolysis in a Critically Ill African American Woman: A Case Report Written With ChatGPT Assistance,"Stevens-Johnson syndrome (SJS) and toxic epidermal necrolysis (TEN) are life-threatening spectrum diseases in which a medication triggers a mucocutaneous reaction associated with severe necrosis and loss of epidermal integrity. The disease has a high mortality rate that can be assessed by dermatology scoring scales based on an affected total body surface area (TBSA). Sloughing of <10% TBSA is considered SJS, with a mortality of 10%. Sloughing of >30% TBSA is termed TEN, with an increased mortality rate of 25% to 35%. We present a case and management of TEN that involved >30% TBSA in a critically ill African American woman. Identification of the offending agent was difficult due to complicated medication exposure throughout her multi-facility care management. This case conveys the importance of close monitoring of a critically ill patient during a clinical course involving SJS-/TEN-inducing drugs. We also discuss the potential increased risks for SJS/TEN in the African American population due to genetic or epigenetic predispositions to skin conditions. This case report also contributes to increasing skin of color representation in the current literature. Additionally, we discuss the use of Chat Generative Pre-trained Transformer (ChatGPT, OpenAI LP, OpenAI Inc., San Francisco, CA, USA) and list its benefits and errors",Lantz2023-ub,PubMed,,1,331,post: CRGDS,report,,,wrote case report using gpt,FALSE,TRUE,FALSE
96,"Just-DNA-Seq, open-source personal genomics platform: longevity science for everyone","Genomic data has become increasingly accessible to the general public with the advent of companies offering whole genome sequencing at a relatively low cost. However, their reports are not verifiable due to a lack of crucial details and transparency: polygenic risk scores do not always mention all the polymorphisms involved. Simultaneously, tackling the manual investigation and interpretation of data proves challenging for individuals lacking a background in genetics. Currently, there is no open-source or commercial solution that provides comprehensive longevity reports surpassing a limited number of polymorphisms. Additionally, there are no ready-made, out-of-the-box solutions available that require minimal expertise to generate reports independently. To address these issues, we have developed the Just-DNA-Seq open-source genomic platform. Just-DNA-Seq aims to provide a user-friendly solution to genome annotation by allowing users to upload their own VCF files and receive annotations of their genetic variants and polygenic risk scores related to longevity. We also created GeneticsGenie custom GPT that can answer genetics questions based on our modules. With the Just-DNA-Seq platform, we want to provide full information regarding the genetics of long life: disease-predisposing variants, that can reduce lifespan and manifest at different age (cardiovascular, oncological, neurodegenerative diseases, etc.), pro-longevity variants and longevity drug pharmacokinetics. In this research article, we will discuss the features and capabilities of Just-DNA-Seq, and how it can benefit individuals looking to understand and improve their health. It's crucial to note that the Just-DNA-Seq platform is exclusively intended for scientific and informational purposes and is not suitable for medical applications",anton2024justdnaseqopensourcepersonalgenomics,arXiv,,2,331,post: CRGDS,report,"GeneticsGenie custom GPT for Q&A + tool Just-DNA-Seq solution for genome annotation; ML Task: Genome annotation, polygenic risk scoring.",Personal genomics and longevity-related genetic variants.,"Open-source platform allows users to analyze their genomes, focusing on longevity and health-related variants + generate summaries.",FALSE,FALSE,TRUE
143,AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals,"Generative AI has the potential to transform knowledge work, but further research is needed to understand how knowledge workers envision using and interacting with generative AI. We investigate the development of generative AI tools to support domain experts in knowledge work, examining task delegation and the design of human-AI interactions. Our research focused on designing a generative AI assistant to aid genetic professionals in analyzing whole genome sequences (WGS) and other clinical data for rare disease diagnosis. Through interviews with 17 genetics professionals, we identified current challenges in WGS analysis. We then conducted co-design sessions with six genetics professionals to determine tasks that could be supported by an AI assistant and considerations for designing interactions with the AI assistant. From our findings, we identified sensemaking as both a current challenge in WGS analysis and a process that could be supported by AI. We contribute an understanding of how domain experts envision interacting with generative AI in their knowledge work, a detailed empirical study of WGS analysis, and three design considerations for using generative AI to support domain experts in sensemaking during knowledge work.   CCS CONCEPTS: Human-centered computing, Human-computer interaction, Empirical studies in HCI   Additional Keywords and Phrases: whole genome sequencing, generative AI, large language models, knowledge work, sensemaking, co-design, rare disease   Contact Author: Angela Mastrianni (This work was done during the author's internship at Microsoft Research)   Ashley Mae Conard and Amanda K. Hall contributed equally",mastrianni2024aienhancedsensemakingexploringdesign,arXiv,,2,331,post: CRGDS,report,designing a generative AI assistant to aid genetic professionals in analyzing whole genome sequences (WGS) and other clinical data for rare disease diagnosis,Assistant to Support Genetic Professionals,"not developed, but identified challendes -- IMPORTANT, otherwise, models will be trained somehow, not for REAL needs",FALSE,FALSE,TRUE
154,Evaluating ChatGPT as an adjunct for the multidisciplinary tumor board decision-making in primary breast cancer cases,"Genomic data has become increasingly accessible to the general public with the advent of companies offering whole genome sequencing at a relatively low cost. However, their reports are not verifiable due to a lack of crucial details and transparency: polygenic risk scores do not always mention all the polymorphisms involved. Simultaneously, tackling the manual investigation and interpretation of data proves challenging for individuals lacking a background in genetics. Currently, there is no open-source or commercial solution that provides comprehensive longevity reports surpassing a limited number of polymorphisms. Additionally, there are no ready-made, out-of-the-box solutions available that require minimal expertise to generate reports independently. To address these issues, we have developed the Just-DNA-Seq open-source genomic platform. Just-DNA-Seq aims to provide a user-friendly solution to genome annotation by allowing users to upload their own VCF files and receive annotations of their genetic variants and polygenic risk scores related to longevity. We also created GeneticsGenie custom GPT that can answer genetics questions based on our modules. With the Just-DNA-Seq platform, we want to provide full information regarding the genetics of long life: disease-predisposing variants, that can reduce lifespan and manifest at different age (cardiovascular, oncological, neurodegenerative diseases, etc.), pro-longevity variants and longevity drug pharmacokinetics. In this research article, we will discuss the features and capabilities of Just-DNA-Seq, and how it can benefit individuals looking to understand and improve their health. It's crucial to note that the Just-DNA-Seq platform is exclusively intended for scientific and informational purposes and is not suitable for medical applications",Lukac2023,PubMed,,1,332,"post: CRGDS, disc",communication,"only general, not specific",planning of the therapy of patients with breast cancer,"in roder to make it better, use RAG (add also to discussion part)",FALSE,TRUE,FALSE
163,A RAG Chatbot for Precision Medicine of Multiple Myeloma,"The advent of precision medicine has revolutionized cancer treatment by integrating individual genetic, lifestyle, and environmental factors to tailor patient care (Huang et al., 2020; Ginsburg and Phillips, 2018). However, the complexity and heterogeneity of diseases like Multiple Myeloma (MM) pose significant challenges in leveraging the vast amounts of genomic data and biomedical literature available for personalized treatment planning (Rajkumar, 2014; Rollig et al., 2015). To address this, we present an innovative Retrieval-Augmented Generation (RAG) based chatbot framework that harnesses the power of Natural Language Processing (NLP) and state-of-the-art language models to curate and analyze MM-specific literature and provide personalized treatment recommendations based on patient-specific genomic data (Lewis et al., 2020).  Our framework integrates the BioMed-RoBERTa-base model for embedding generation (Gururangan et al., 2020) and the Mistral-7B language model for question answering (Anthropic, 2023), enabling effective understanding and response to complex clinical queries. The retrieval component is enhanced by Amazon OpenSearch Service, ensuring fast and accurate access to relevant information. A comprehensive data analysis pipeline, including exploratory data analysis, semantic search, clustering, and topic modeling, provides valuable insights into the MM research landscape, informing the chatbots knowledge base and uncovering potential research directions (Blei et al., 2003; Mikolov et al., 2013).  Deployed using Amazon Kendra, our RAG chatbot offers a user-friendly and scalable platform for accessing MM information, incorporating features such as user authentication, customizable web interface, and continuous improvement based on user feedback. The framework aims to democratize access to precision medicine by providing clinicians with a sophisticated tool for interpreting complex genomic data in the context of MM, streamlining clinical workflows, and facilitating the development of personalized treatment plans (Patel et al., 2015).  This paper presents the conceptualization, development, and potential impact of our RAG-based chatbot framework on the landscape of MM treatment and precision medicine. We argue that the synergistic integration of AI, NLP, and domain-specific knowledge marks a new era of healthcare, characterized by highly personalized, data-driven, and effective treatment modalities (Thong et al., 2021). Our framework not only advances the field of precision medicine in MM but also serves as a blueprint for the development of similar systems in other complex diseases, ultimately improving patient outcomes and quality of life",Quidwai2024.03.14.24304293,medrxiv,,2,332,post: CRGDS,communication,RAG Chatbot for Precision Medicine ,"conceptualization, development, and potential impact of our RAG-based chatbot framework on the landscape of MM treatment and precision medicine",MM - multiple mieloma,FALSE,FALSE,TRUE
165,Evaluating and Enhancing Japanese Large Language Models for Genetic Counseling Support: Comparative Study of Domain Adaptation and the Development of an Expert-Evaluated Dataset,"Advances in genetics have underscored a strong association between genetic factors and health outcomes, leading to an increased demand for genetic counseling services. However, a shortage of qualified genetic counselors poses a significant challenge. Large language models (LLMs) have emerged as a potential solution for augmenting support in genetic counseling tasks. Despite the potential, Japanese genetic counseling LLMs (JGCLLMs) are underexplored. To advance a JGCLLM-based dialogue system for genetic counseling, effective domain adaptation methods require investigation. This study aims to evaluate the current capabilities and identify challenges in developing a JGCLLM-based dialogue system for genetic counseling. The primary focus is to assess the effectiveness of prompt engineering, retrieval-augmented generation (RAG), and instruction tuning within the context of genetic counseling. Furthermore, we will establish an experts-evaluated dataset of responses generated by LLMs adapted to Japanese genetic counseling for the future development of JGCLLMs. Two primary datasets were used in this study: (1) a question-answer (QA) dataset for LLM adaptation and (2) a genetic counseling question dataset for evaluation. The QA dataset included 899 QA pairs covering medical and genetic counseling topics, while the evaluation dataset contained 120 curated questions across 6 genetic counseling categories. Three enhancement techniques of LLMs-instruction tuning, RAG, and prompt engineering-were applied to a lightweight Japanese LLM to enhance its ability for genetic counseling. The performance of the adapted LLM was evaluated on the 120-question dataset by 2 certified genetic counselors and 1 ophthalmologist (SK, YU, and AY). Evaluation focused on four metrics: (1) inappropriateness of information, (2) sufficiency of information, (3) severity of harm, and (4) alignment with medical consensus. The evaluation by certified genetic counselors and an ophthalmologist revealed varied outcomes across different methods. RAG showed potential, particularly in enhancing critical aspects of genetic counseling. In contrast, instruction tuning and prompt engineering produced less favorable outcomes. This evaluation process facilitated the creation an expert-evaluated dataset of responses generated by LLMs adapted with different combinations of these methods. Error analysis identified key ethical concerns, including inappropriate promotion of prenatal testing, criticism of relatives, and inaccurate probability statements. RAG demonstrated notable improvements across all evaluation metrics, suggesting potential for further enhancement through the expansion of RAG data. The expert-evaluated dataset developed in this study provides valuable insights for future optimization efforts. However, the ethical issues observed in JGCLLM responses underscore the critical need for ongoing refinement and thorough ethical evaluation before these systems can be implemented in health care settings",Fukushima2025-oi,PubMed,,2,332,"post: CRGDS, disc",communication,japanese LLM for genetic councelling,,"importance of other langiages models (in addition to racial bias, language bias)",FALSE,FALSE,TRUE
155,Evaluating GPT-4-based ChatGPT's Clinical Potential on the NEJM Quiz,"BackgroundGPT-4-based ChatGPT demonstrates significant potential in various industries; however, its potential clinical applications remain largely unexplored.  MethodsWe employed the New England Journal of Medicine (NEJM) quiz ""Image Challenge"" from October 2021 to March 2023 to assess ChatGPTs clinical capabilities. The quiz, designed for healthcare professionals, tests the ability to analyze clinical scenarios and make appropriate decisions. We evaluated ChatGPTs performance on the NEJM quiz, analyzing its accuracy rate by questioning type and specialty after excluding quizzes which were impossible to answer without images. The NEJM quiz has five multiple-choice options, but ChatGPT was first asked to answer without choices, and then given the choices to answer afterwards, in order to evaluate the accuracy in both scenarios.  ResultsChatGPT achieved an 87% accuracy without choices and a 97% accuracy with choices, after excluding 16 image-based quizzes. Upon analyzing performance by quiz type, ChatGPT excelled in the Diagnosis category, attaining 89% accuracy without choices and 98% with choices. Although other categories featured fewer cases, ChatGPTs performance remained consistent. It demonstrated strong performance across the majority of medical specialties; however, Genetics had the lowest accuracy at 67%.  ConclusionChatGPT demonstrates potential for clinical application, suggesting its usefulness in supporting healthcare professionals and enhancing AI-driven healthcare",Ueda2024,medrxiv,,2,332,post: CRGDS,communication,GPT-4-for Medical diagnosis through natural language understanding (NLP).,Clinical decision-making and diagnosis from medical text scenarios.,"GPT-4 achieves high diagnostic accuracy in clinical quizzes, but lower performance in genetics.",FALSE,FALSE,TRUE
156,"Evaluation of the Diagnostic Accuracy of GPT-4 in Five Thousand Rare Disease Cases
==========
Systematic benchmarking demonstrates large language models have not reached the diagnostic accuracy of traditional rare-disease decision support tools","Large language models (LLMs) show promise in supporting differential diagnosis, but their performance is challenging to evaluate due to the unstructured nature of their responses. To assess the current capabilities of LLMs to diagnose genetic diseases, we benchmarked these models on 5,213 case reports using the Phenopacket Schema, the Human Phenotype Ontology and Mondo disease ontology. Prompts generated from each phenopacket were sent to three generative pretrained transformer (GPT) models. The same phenopackets were used as input to a widely used diagnostic tool, Exomiser, in phenotype-only mode. The best LLM ranked the correct diagnosis first in 23.6% of cases, whereas Exomiser did so in 35.5% of cases. While the performance of LLMs for supporting differential diagnosis has been improving, it has not reached the level of commonly used traditional bioinformatics tools. Future research is needed to determine the best approach to incorporate LLMs into diagnostic pipelines",Reese2024.07.22.24310816,"PubMed,medrxiv,medrxiv",,2,332,post: CRGDS,communication,LLM for diagnostics of genetic diseases (only case reports),,,FALSE,FALSE,TRUE
146,Leveraging Large Language Models for Decision Support in Personalized Oncology,"Clinical interpretation of complex biomarkers for precision oncology currently requires manual investigations of previous studies and databases. Conversational large language models (LLMs) might be beneficial as automated tools for assisting clinical decision-making. To assess performance and define their role using 4 recent LLMs as support tools for precision oncology. This diagnostic study examined 10 fictional cases of patients with advanced cancer with genetic alterations. Each case was submitted to 4 different LLMs (ChatGPT, Galactica, Perplexity, and BioMedLM) and 1 expert physician to identify personalized treatment options in 2023. Treatment options were masked and presented to a molecular tumor board (MTB), whose members rated the likelihood of a treatment option coming from an LLM on a scale from 0 to 10 (0, extremely unlikely; 10, extremely likely) and decided whether the treatment option was clinically useful. Number of treatment options, precision, recall, F1 score of LLMs compared with human experts, recognizability, and usefulness of recommendations. For 10 fictional cancer patients (4 with lung cancer, 6 with other; median [IQR] 3.5 [3.0-4.8] molecular alterations per patient), a median (IQR) number of 4.0 (4.0-4.0) compared with 3.0 (3.0-5.0), 7.5 (4.3-9.8), 11.5 (7.8-13.0), and 13.0 (11.3-21.5) treatment options each was identified by the human expert and 4 LLMs, respectively. When considering the expert as a criterion standard, LLM-proposed treatment options reached F1 scores of 0.04, 0.17, 0.14, and 0.19 across all patients combined. Combining treatment options from different LLMs allowed a precision of 0.29 and a recall of 0.29 for an F1 score of 0.29. LLM-generated treatment options were recognized as AI-generated with a median (IQR) 7.5 (5.3-9.0) points in contrast to 2.0 (1.0-3.0) points for manually annotated cases. A crucial reason for identifying AI-generated treatment options was insufficient accompanying evidence. For each patient, at least 1 LLM generated a treatment option that was considered helpful by MTB members. Two unique useful treatment options (including 1 unique treatment strategy) were identified only by LLM. In this diagnostic study, treatment options of LLMs in precision oncology did not reach the quality and credibility of human experts; however, they generated helpful ideas that might have complemented established procedures. Considering technological progress, LLMs could play an increasingly important role in assisting with screening and selecting relevant biomedical literature to support evidence-based, personalized treatment decisions",10.1001/jamanetworkopen.2023.43689,PubMed,,2,332,post: CRGDS,communication,"4 different llms (chatgpt, galactica, perplexity, biomedlm) vs 1 expert physician",Generate treatments for patient,,FALSE,FALSE,TRUE
166,PGxQA: A Resource for Evaluating LLM Performance for Pharmacogenomic QA Tasks,"Pharmacogenetics represents one of the most promising areas of precision medicine, with several guidelines for genetics-guided treatment ready for clinical use. Despite this, implementation has been slow, with few health systems incorporating the technology into their standard of care. One major barrier to uptake is the lack of education and awareness of pharmacogenetics among clinicians and patients. The introduction of large language models (LLMs) like GPT-4 has raised the possibility of medical chatbots that deliver timely information to clinicians, patients, and researchers with a simple interface. Although state-of-the-art LLMs have shown impressive performance at advanced tasks like medical licensing exams, in practice they still often provide false information, which is particularly hazardous in a clinical context. To quantify the extent of this issue, we developed a series of automated and expert-scored tests to evaluate the performance of chatbots in answering pharmacogenetics questions from the perspective of clinicians, patients, and researchers. We applied this benchmark to state-of-the-art LLMs and found that newer models like GPT-4o greatly outperform their predecessors, but still fall short of the standards required for clinical use. Our benchmark will be a valuable public resource for subsequent developments in this space as we work towards better clinical AI for pharmacogenetics",Keat2025-lv,PubMed,,2,332,"post: CRGDS, disc",communication,evaluating LLM for A," developed a series of automated and expert-scored tests to evaluate the performance of chatbots in answering pharmacogenetics questions from the perspective of clinicians, patients, and researchers","developed BENCHMARK, not just prompted",FALSE,FALSE,TRUE
180,ChatGPT accurately performs genetic counseling for gynecologic cancers,"Artificial Intelligence (AI) systems such as ChatGPT can take medical examinations and counsel patients regarding medical diagnosis. We aim to quantify the accuracy of the ChatGPT V3.4 in answering commonly asked questions pertaining to genetic testing and counseling for gynecologic cancers. Forty questions were formulated in conjunction with gynecologic oncologists and adapted from professional society guidelines and ChatGPT version 3.5 was queried, the version that is readily available to the public. The two categories of questions were genetic counseling guidelines and questions pertaining to specific genetic disorders. The answers were scored by two attending Gynecologic Oncologists according to the following scale: 1) correct and comprehensive, 2) correct but not comprehensive, 3) some correct, some incorrect, and 4) completely incorrect. Scoring discrepancies were resolved by additional third reviewer. The proportion of responses earning each score were calculated overall and within each question category. ChatGPT provided correct and comprehensive answers to 33/40 (82.5%) questions, correct but not comprehensive answers to 6/40 (15%) questions, partially incorrect answers to 1/40 (2.5%) questions, and completely incorrect answers to 0/40 (0%) questions. The genetic counseling category of questions had the highest proportion of answers that were both correct and comprehensive with ChatGPT answering all 20/20 questions with 100% accuracy and were comprehensive in responses. ChatGPT performed equally in the specific genetic disorders category, with 88.2% (15/17) and 66.6% (2/3) correct and comprehensive answers to questions pertaining to hereditary breast and ovarian cancer and Lynch syndrome questions respectively. ChatGPT accurately answers questions about genetic syndromes, genetic testing, and counseling in majority of the studied questions. These data suggest this powerful tool can be utilized as a patient resource for genetic counseling questions, though more data input from gynecologic oncologists would be needed to educate patients on genetic syndromes",PATEL2024115,PubMed,,2,332,post: CRGDS,communication,ChatGPT-3.5,"Genetic counseling for gynecologic cancers, including hereditary breast and ovarian cancer, and Lynch syndrome.",,FALSE,FALSE,TRUE
185,Finding the sweet spot: a qualitative study exploring patients' acceptability of chatbots in genetic service delivery,"Chatbots, web-based artificial intelligence tools that simulate human conversation, are increasingly in use to support many areas of genomic medicine. However, patient preferences towards using chatbots across the range of clinical settings are unknown. We conducted a qualitative study with individuals who underwent genetic testing for themselves or their child. Participants were asked about their preferences for using a chatbot within the genetic testing journey. Thematic analysis employing interpretive description was used. We interviewed 30 participants (67% female, 50% 50 + years). Participants considered chatbots to be inefficient for very simple tasks (e.g., answering FAQs) or very complex tasks (e.g., explaining results). Chatbots were acceptable for moderately complex tasks where participants perceived a favorable return on their investment of time and energy. In addition to achieving this ""sweet spot,"" participants anticipated that their comfort with chatbots would increase if the chatbot was used as a complement to but not a replacement for usual care. Participants wanted a ""safety net"" (i.e., access to a clinician) for needs not addressed by the chatbot. This study provides timely insights into patients' comfort with and perceived limitations of chatbots for genomic medicine and can inform their implementation in practice",Luca2023-st,PubMed,,2,332,post: CRGDS,communication,,acceptability of chatbots in genetic service delivery,compare return of investments,FALSE,FALSE,TRUE
173,Large Language Models Need Holistically Thought in Medical Conversational QA,"The medical conversational question answering (CQA) system aims at providing a series of professional medical services to improve the efficiency of medical care. Despite the success of large language models (LLMs) in complex reasoning tasks in various fields, such as mathematics, logic, and commonsense QA, they still need to improve with the increased complexity and specialization of the medical field. This is because medical CQA tasks require not only strong medical reasoning, but also the ability to think broadly and deeply. In this paper, to address these challenges in medical CQA tasks that need to be considered and understood in many aspects, we propose the Holistically Thought (HoT) method, which is designed to guide the LLMs to perform the diffused and focused thinking for generating high-quality medical responses. The proposed HoT method has been evaluated through automated and manual assessments in three different medical CQA datasets containing the English and Chinese languages. The extensive experimental results show that our method can produce more correctness, professional, and considerate answers than several state-of-the-art (SOTA) methods, manifesting its effectiveness. Our code in https://github.com/WENGSYX/HoT",weng2023largelanguagemodelsneed,arXiv,,1,411,"edu, disc",qa,"Holistically Thought (HoT) method, which is designed to guide the LLMs to perform the diffused and focused thinking for generating high-quality medical responses",adn\vanced technique of QandA,just Q&A,FALSE,TRUE,FALSE
174,Performance of Publicly Available Large Language Models on Internal Medicine Board-style Questions,"Ongoing research attempts to benchmark large language models (LLM) against physicians' fund of knowledge by assessing LLM performance on medical examinations. No prior study has assessed LLM performance on internal medicine (IM) board examination questions. Limited data exists on how knowledge supplied to the models, derived from medical texts improves LLM performance. The performance of GPT-3.5, GPT-4.0, LaMDA and Llama 2, with and without additional model input augmentation, was assessed on 240 randomly selected IM board-style questions. Questions were sourced from the Medical Knowledge Self-Assessment Program released by the American College of Physicians with each question serving as part of the LLM prompt. When available, LLMs were accessed both through their application programming interface (API) and their corresponding chatbot. Mode inputs were augmented with Harrison's Principles of Internal Medicine using the method of Retrieval Augmented Generation. LLM-generated explanations to 25 correctly answered questions were presented in a blinded fashion alongside the MKSAP explanation to an IM board-certified physician tasked with selecting the human generated response. GPT-4.0, accessed either through Bing Chat or its API, scored 77.5-80.7% outperforming GPT-3.5, human respondents, LaMDA and Llama 2 in that order. GPT-4.0 outperformed human MKSAP users on every tested IM subject with its highest and lowest percentile scores in Infectious Disease (80th) and Rheumatology (99.7th), respectively. There is a 3.2-5.3% decrease in performance of both GPT-3.5 and GPT-4.0 when accessing the LLM through its API instead of its online chatbot. There is 4.5-7.5% increase in performance of both GPT-3.5 and GPT-4.0 accessed through their APIs after additional input augmentation. The blinded reviewer correctly identified the human generated MKSAP response in 72% of the 25-question sample set. GPT-4.0 performed best on IM board-style questions outperforming human respondents. Augmenting with domain-specific information improved performance rendering Retrieval Augmented Generation a possible technique for improving accuracy in medical examination LLM responses",Tarabanis2024-er,PubMed,,1,411,edu,qa,,q&a,,FALSE,TRUE,FALSE
181,ChatGPT as a bioinformatic partner,"The advanced Large Language Model ChatGPT4o, developed by OpenAI, can be used in the field of bioinformatics to analyze and understand cross-reactive allergic reactions. This study explores the use of ChatGPT4o to support research on allergens, particularly in the cross-reactivity syndrome between cat and pork. Using a hypothetical clinical case of a child with a confirmed allergy to Fel d 2 (cat albumin) and Sus s 1 (pork albumin), the model guided data collection, protein sequence analysis, and three-dimensional structure visualization. Through the use of bioinformatics tools like SDAP 2.0 and BepiPRED, the epitope regions of the allergenic proteins were predicted, confirming their accessibility to immunoglobulin E (IgE) and probability of cross-reactivity. The results show that regions with high epitope probability exhibit high surface accessibility and predominantly coil and helical structures. The construction of a phylogenetic tree further supported the evolutionary relationships among the studied allergens. ChatGPT4o has demonstrated its usefulness in guiding non-specialist researchers through complex bioinformatics processes, making advanced science accessible and improving analytical and innovation capabilities",Mondillo2024.08.20.24312291,medrxiv,,1,411,"edu, disc",qa,ChatGPT4o to support research on allergens," the model guided data collection, protein sequence analysis, and three-dimensional structure visualization","FULL PIPELINE: guiding non-specialist researchers through complex bioinformatics processes, making science accessible",FALSE,TRUE,FALSE
168,The Future of Patient Education: AI-Driven Guide for Type 2 Diabetes,"Introduction and aim The surging incidence of type 2 diabetes has become a growing concern for the healthcare sector. This chronic ailment, characterized by its complex blend of genetic and lifestyle determinants, has witnessed a notable increase in recent times, exerting substantial pressure on healthcare resources. As more individuals turn to online platforms for health guidance and embrace the utilization of Chat Generative Pre-trained Transformer (ChatGPT; San Francisco, CA: OpenAI), a text-generating AI (TGAI), to get insights into their well-being, evaluating its effectiveness and reliability becomes crucial. This research primarily aimed to evaluate the correctness of TGAI responses to type 2 diabetes (T2DM) inquiries via ChatGPT. Furthermore, this study aimed to examine the consistency of TGAI in addressing common queries on T2DM complications for patient education. Material and methods Questions on T2DM were formulated by experienced physicians and screened by research personnel before querying ChatGPT. Each question was posed thrice, and the collected answers were summarized. Responses were then sorted into three distinct categories as follows: (a) appropriate, (b) inappropriate, and (c) unreliable by two seasoned physicians. In instances of differing opinions, a third physician was consulted to achieve consensus. Results From the initial set of 110 T2DM questions, 40 were dismissed by experts for relevance, resulting in a final count of 70. An overwhelming 98.5% of the AI's answers were judged as appropriate, thus underscoring its reliability over traditional online search engines. Nonetheless, a 1.5% rate of inappropriate responses underlines the importance of ongoing AI improvements and strict adherence to medical protocols. Conclusion TGAI provides medical information of high quality and reliability. This study underscores TGAI's impressive effectiveness in delivering reliable information about T2DM, with 98.5% of responses aligning with the standard of care. These results hold promise for integrating AI platforms as supplementary tools to enhance patient education and outcomes",Hernandez2023-ay,PubMed,,1,411,edu,qa,,"evaluate the correctness of TGAI responses to type 2 diabetes (T2DM) inquiries via ChatGPT. Furthermore, this study aimed to examine the consistency of TGAI in addressing common queries on T2DM complications for patient education",,FALSE,TRUE,FALSE
170,A comparative evaluation of ChatGPT 3.5 and ChatGPT 4 in responses to selected genetics questions,"To evaluate the efficacy of ChatGPT 4 (GPT-4) in delivering genetic information about BRCA1, HFE, and MLH1, building on previous findings with ChatGPT 3.5 (GPT-3.5). To focus on assessing the utility, limitations, and ethical implications of using ChatGPT in medical settings. A structured survey was developed to assess GPT-4's clinical value. An expert panel of genetic counselors and clinical geneticists evaluated GPT-4's responses to these questions. We also performed comparative analysis with GPT-3.5, utilizing descriptive statistics and using Prism 9 for data analysis. The findings indicate improved accuracy in GPT-4 over GPT-3.5 (P < .0001). However, notable errors in accuracy remained. The relevance of responses varied in GPT-4, but was generally favorable, with a mean in the ""somewhat agree"" range. There was no difference in performance by disease category. The 7-question subset of the Bot Usability Scale (BUS-15) showed no statistically significant difference between the groups but trended lower in the GPT-4 version. The study underscores GPT-4's potential role in genetic education, showing notable progress yet facing challenges like outdated information and the necessity of ongoing refinement. Our results, while showing promise, emphasizes the importance of balancing technological innovation with ethical responsibility in healthcare information delivery",McGrath2024-zx,PubMed,,2,411,"edu, disc",qa,"GPT-3.5, GPT-4 for Genetic information delivery and education.","Genetic conditions (BRCA1, HFE, MLH1) and genetic counseling.","GPT-4 performs better than GPT-3.5 in genetic counseling but still presents notable inaccuracies, with a need for ongoing refinement.",FALSE,FALSE,TRUE
171,Evaluating ChatGPT as an Agent for Providing Genetic Education,"Genetic disorders are complex and can greatly impact an individual's health and well-being. In this study, we assess the ability of ChatGPT, a language model developed by OpenAI, to answer questions related to three specific genetic disorders: BRCA1, MLH1, and HFE. ChatGPT has shown it can supply articulate answers to a wide spectrum of questions. However, its ability to answer questions related to genetic disorders has yet to be evaluated. The aim of this study is to perform both quantitative and qualitative assessments of ChatGPT's performance in this area. The ability of ChatGPT to provide accurate and useful information to patients was assessed by genetic experts. Here we show that ChatGPT answered 64.7% of the 68 genetic questions asked and was able to respond coherently to complex questions related to the three genes/conditions. Our results reveal that ChatGPT can provide valuable information to individuals seeking information about genetic disorders, however, it still has some limitations and inaccuracies, particularly in understanding human inheritance patterns. The results of this study have implications for both genomics and medicine and can inform future developments in this area. AI platforms, like ChatGPT, have significant potential in the field of genomics. As these technologies become integrated into consumer-facing products, appropriate oversight is required to ensure accurate and safe delivery of medical information. With such oversight and training specifically for genetic information, these platforms could have the potential to augment some clinical interactions
==========
Genetic disorders are complex and can greatly impact an individuals health and well-being. In this study, we assess the ability of ChatGPT, a language model developed by OpenAI, to answer questions related to three specific genetic disorders: BRCA1, MLH1, and HFE. ChatGPT has shown it can supply articulate answers to a wide spectrum of questions. However, its ability to answer questions related to genetic disorders has yet to be evaluated. The aim of this study is to perform both quantitative and qualitative assessments of ChatGPTs performance in this area. The ability of ChatGPT to provide accurate and useful information to patients was assessed by genetic experts. Here we show that ChatGPT answered 64.7% of the 68 genetic questions asked and was able to respond coherently to complex questions related to the three genes/conditions. Our results reveal that ChatGPT can provide valuable information to individuals seeking information about genetic disorders, however, it still has some limitations and inaccuracies, particularly in understanding human inheritance patterns. The results of this study have implications for both genomics and medicine and can inform future developments in this area. AI platforms, like ChatGPT, have significant potential in the field of genomics. As these technologies become integrated into consumer-facing products, appropriate oversight is required to ensure accurate and safe delivery of medical information. With such oversight and training specifically for genetic information, these platforms could have the potential to augment some clinical interactions",Walton2023.10.25.564074,"PubMed,biorxiv",,2,411,edu,qa,"ChatGPT for Genetic education, answering questions on specific genetic disorders.","Genetic disorder information for conditions like BRCA1, MLH1, and HFE.",,FALSE,FALSE,TRUE
176,Artificial intelligence-generated patient information leaflets: a comparison of contents according to British Association of Dermatologists standards,"Patient information leaflets (PILs) can supplement a clinical consultation and provide additional information for a patient to read in their own time. A wide range of PILs are available for distribution by the British Association of Dermatologists (BAD) and undergo rigorous review ahead of publication. In the UK, 7.1 million adults are estimated to have the reading age of a 9-year-old child and 43% are unable to comprehend written health information. To determine whether artificial intelligence (AI) can produce PILs that include a similar degree of content to current BAD PILs. Using the AI tool ChatGPT, 10 PILs were generated, and their contents compared with those of existing BAD PILs using an author-generated list of commonly included themes. Omissions were noted and a repeat series of PILs generated using targeted request phrasing. The readability of AI-generated PILs was also analysed. AI-generated PILs were found to include similar factual content to BAD PILs but excluded information that was felt to be more pertinent to patient concerns such as curability and heritability. Targeted request phrasing saw AI generate PILs including this content. The readability of AI-generated PILs was beyond that of a large number of UK adults. Where a condition-specific PIL is not readily available, an AI-generated PIL can provide relevant information of lesser quality than existing BAD PILs, which may be inaccessible to some patients. Specific caution is advised regarding AI-generated medication-specific PILs",Verran2024-en,PubMed,,1,412,"edu, disc",gener,,patient information leaflets (PILs) generat,generate data,FALSE,TRUE,FALSE
172,"Generative Methods for Pediatric Genetics Education
==========
Generative Artificial Intelligence Methods for Pediatric Genetics Education
==========
Recognition of Genetic Conditions After Learning With Images Created Using Generative Artificial Intelligence","Artificial intelligence (AI) is used in an increasing number of areas, with recent interest in generative AI, such as using ChatGPT to generate programming code or DALL-E to make illustrations. We describe the use of generative AI in medical education. Specifically, we sought to determine whether generative AI could help train pediatric residents to better recognize genetic conditions. From publicly available images of individuals with genetic conditions, we used generative AI methods to create new images, which were checked for accuracy with an external classifier. We selected two conditions for study, Kabuki (KS) and Noonan (NS) syndromes, which are clinically important conditions that pediatricians may encounter. In this study, pediatric residents completed 208 surveys, where they each classified 20 images following exposure to one of 4 possible educational interventions, including with and without generative AI methods. Overall, we find that generative images perform similarly but appear to be slightly less helpful than real images. Most participants reported that images were useful, although real images were felt to be more helpful. We conclude that generative AI images may serve as an adjunctive educational tool, particularly for less familiar conditions, such as KS
=============
The lack of standardized genetics training in pediatrics residencies, along with a shortage of medical geneticists, necessitates innovative educational approaches. To compare pediatric resident recognition of Kabuki syndrome (KS) and Noonan syndrome (NS) after 1 of 4 educational interventions, including generative artificial intelligence (AI) methods. This comparative effectiveness study used generative AI to create images of children with KS and NS. From October 1, 2022, to February 28, 2023, US pediatric residents were provided images through a web-based survey to assess whether these images helped them recognize genetic conditions. Participants categorized 20 images after exposure to 1 of 4 educational interventions (text-only descriptions, real images, and 2 types of images created by generative AI). Associations between educational interventions with accuracy and self-reported confidence. Of 2515 contacted pediatric residents, 106 and 102 completed the KS and NS surveys, respectively. For KS, the sensitivity of text description was 48.5% (128 of 264), which was not significantly different from random guessing (odds ratio [OR], 0.94; 95% CI, 0.69-1.29; P = .71). Sensitivity was thus compared for real images vs random guessing (60.3% [188 of 312]; OR, 1.52; 95% CI, 1.15-2.00; P = .003) and 2 types of generative AI images vs random guessing (57.0% [212 of 372]; OR, 1.32; 95% CI, 1.04-1.69; P = .02 and 59.6% [193 of 324]; OR, 1.47; 95% CI, 1.12-1.94; P = .006) (denominators differ according to survey responses). The sensitivity of the NS text-only description was 65.3% (196 of 300). Compared with text-only, the sensitivity of the real images was 74.3% (205 of 276; OR, 1.53; 95% CI, 1.08-2.18; P = .02), and the sensitivity of the 2 types of images created by generative AI was 68.0% (204 of 300; OR, 1.13; 95% CI, 0.77-1.66; P = .54) and 71.0% (247 of 328; OR, 1.30; 95% CI, 0.92-1.83; P = .14). For specificity, no intervention was statistically different from text only. After the interventions, the number of participants who reported being unsure about important diagnostic facial features decreased from 56 (52.8%) to 5 (7.6%) for KS (P < .001) and 25 (24.5%) to 4 (4.7%) for NS (P < .001). There was a significant association between confidence level and sensitivity for real and generated images. In this study, real and generated images helped participants recognize KS and NS; real images appeared most helpful. Generated images were noninferior to real images and could serve an adjunctive role, particularly for rare conditions",Waikel2024-na,"PubMed,medrxiv",,2,412,edu,gener,"Generative AI (e.g., DALL-E) for Educational image generation for genetic disorder recognition. create images to then recognize genetic conditions -- good in education","Pediatric genetics education, focusing on conditions like Kabuki syndrome and Noonan syndrome.","Generative AI creates educational images for pediatric residents, showing potential as an adjunctive tool for teaching genetic disorder recognition.",FALSE,FALSE,TRUE
169,Rapid Creation of Knowledge-Balanced Student Groups Using ChatGPT4,"We demonstrated use of ChatGPT4 for efficient group formation in undergraduate medical education. ChatGPT4 created balanced groups considering students' backgrounds in microbiology, physiology, genetics, and immunology considerably faster than manual efforts. Manual refinements included gender balance and discipline distribution. Improvements included ChatGTP's ability to further incorporate GPA and MCAT scores",Laye2024-qg,PubMed,,1,413,edu,group,GPT-4; ML Task: Group formation in medical education.,Medical education and genetics-related group formation.,GPT-4 efficiently creates balanced student groups in medical education considering academic backgrounds.,FALSE,TRUE,FALSE
46,Gene-language models are whole genome representation learners,"The language of genetic code embodies a complex grammar and rich syntax of interacting molecular elements. Recent advances in self-supervision and feature learning suggest that statistical learning techniques can identify high-quality quantitative representations from inherent semantic structure. We present a gene-based language model that generates whole-genome vector representations from a population of 16 disease-causing bacterial species by leveraging natural contrastive characteristics between individuals. To achieve this, we developed a set-based learning objective, AB learning, that compares the annotated gene content of two population subsets for use in optimization. Using this foundational objective, we trained a Transformer model to backpropagate information into dense genome vector representations. The resulting bacterial representations, or embeddings, captured important population structure characteristics, like delineations across serotypes and host specificity preferences. Their vector quantities encoded the relevant functional information necessary to achieve state-of-the-art genomic supervised prediction accuracy in 11 out of 12 antibiotic resistance phenotypes.  TeaserDeep transformers capture and encode gene language content to derive versatile latent embeddings of microbial genomes",Naidenov2024.03.18.585642,biorxiv,,1,511,"disc, ana: AVE",areas, gene-based language model that generates whole-genome vector representations from a population of 16 disease-causing bacterial species,,"not humans, but foundation model, that can be used for multiple things",FALSE,TRUE,FALSE
48,Whole Genome Transformer for Gene Interaction Effects in Microbiome Habitat Specificity,"Leveraging the vast genetic diversity within microbiomes offers unparalleled insights into complex phenotypes, yet the task of accurately predicting and understanding such traits from genomic data remains challenging. We propose a framework taking advantage of existing large models for gene vectorization to predict habitat specificity from entire microbial genome sequences. Based on our model, we develop attribution techniques to elucidate gene interaction effects that drive microbial adaptation to diverse environments. We train and validate our approach on a large dataset of high quality microbiome genomes from different habitats. We not only demonstrate solid predictive performance, but also how sequence-level information of entire genomes allows us to identify gene associations underlying complex phenotypes. Our attribution recovers known important interaction networks and proposes new candidates for experimental follow up",li2025genometransformergeneinteraction,arXiv,,1,511,"disc, ana: AVE",areas,Whole Genome Transformer,Gene Interaction Effects in Microbiome Habitat Specificity,microbes:( -- can we use?,FALSE,TRUE,FALSE
117,Detecting microsatellite instability in colorectal cancer using Transformer-based colonoscopy image classification and retrieval,"Colorectal cancer (CRC) is a major global health concern, with microsatellite instability-high (MSI-H) being a defining characteristic of hereditary nonpolyposis colorectal cancer syndrome and affecting 15% of sporadic CRCs. Tumors with MSI-H have unique features and better prognosis compared to MSI-L and microsatellite stable (MSS) tumors. This study proposed establishing a MSI prediction model using more available and low-cost colonoscopy images instead of histopathology. The experiment utilized a database of 427 MSI-H and 1590 MSS colonoscopy images and vision Transformer (ViT) with different feature training approaches to establish the MSI prediction model. The accuracy of combining pre-trained ViT features was 84% with an area under the receiver operating characteristic curve of 0.86, which was better than that of DenseNet201 (80%, 0.80) in the experiment with support vector machine. The content-based image retrieval (CBIR) approach showed that ViT features can obtain a mean average precision of 0.81 compared to 0.79 of DenseNet201. ViT reduced the issues that occur in convolutional neural networks, including limited receptive field and gradient disappearance, and may be better at interpreting diagnostic information around tumors and surrounding tissues. By using CBIR, the presentation of similar images with the same MSI status would provide more convincing deep learning suggestions for clinical use",Lo2024-rh,PubMed,,1,511,"disc, ana: MIA",areas, Transformer-based colonoscopy image classification (ViT) and retrieval,work with tumors: Detecting microsatellite instability,,FALSE,TRUE,FALSE
130,A hybrid machine learning model for predicting gene expression from epigenetics across fungal species,"Understanding and controlling gene expression in organisms is essential for optimizing biological processes, whether in service of bioeconomic processes, human health, or environmental regulation. Epigenetic modifications play a significant role in regulating gene expression by altering chromatin structure, DNA accessibility and protein binding. While a significant amount is known about the combinatorial effects of epigenetics on gene expression, our understanding of the degree to which the orchestration of these mechanisms is conserved in gene expression regulation across species, particularly for non-model organisms, remains limited. In this study, we aim to predict gene expression levels based on epigenetic modifications in chromatin across different fungal species, to enable transferring information about well characterized species to poorly understood species. We developed a custom hybrid deep learning model, EAGLE (Evolutionary distance-Adaptable Gene expression Learned from Epigenomics), which combines convolutional layers and multi-head attention mechanisms to capture both local and global dependencies in epigenetic data. We demonstrate the cross-species performance of EAGLE across fungi, a kingdom containing both pathogens and biomanufacturing chassis and where understanding epigenetic regulation in under-characterized species would be transformative for bioeconomic, environmental, and biomedical applications. EAGLE outperformed shallow learning models and a modified transformer benchmarking model, achieving up to 80% accuracy and 89% AUROC for intra-species validation and 77% accuracy and 83% AUROC in cross-species prediction tasks. SHAP analysis revealed that EAGLE identifies important epigenetic features that drive gene expression, providing insights for experimental design and potential future epigenome engineering work. Our findings demonstrate the potential of EAGLE to generalize across fungal species, offering a versatile tool for optimizing fungal gene expression in multiple sectors. In addition, our architecture can be adapted for cross-species tasks across the tree of life where detailed molecular and genetic information can be scarce",Weinstock2024.12.12.628183,biorxiv,,1,511,disc,areas,"custom hybrid deep learning model, EAGLE (Evolutionary distance-Adaptable Gene expression Learned from Epigenomics), which combines convolutional layers and multi-head attention mechanisms to capture both local and global dependencies in epigenetic data",Gene expression,,FALSE,TRUE,FALSE
110,A transformer-based multi-task deep learning model for simultaneous infiltrated brain area identification and segmentation of gliomas,"The anatomical infiltrated brain area and the boundaries of gliomas have a significant impact on clinical decision making and available treatment options. Identifying glioma-infiltrated brain areas and delineating the tumor manually is a laborious and time-intensive process. Previous deep learning-based studies have mainly been focused on automatic tumor segmentation or predicting genetic/histological features. However, few studies have specifically addressed the identification of infiltrated brain areas. To bridge this gap, we aim to develop a model that can simultaneously identify infiltrated brain areas and perform accurate segmentation of gliomas. We have developed a transformer-based multi-task deep learning model that can perform two tasks simultaneously: identifying infiltrated brain areas segmentation of gliomas. The multi-task model leverages shaped location and boundary information to enhance the performance of both tasks. Our retrospective study involved 354 glioma patients (grades II-IV) with single or multiple brain area infiltrations, which were divided into training (N = 270), validation (N = 30), and independent test (N = 54) sets. We evaluated the predictive performance using the area under the receiver operating characteristic curve (AUC) and Dice scores. Our multi-task model achieved impressive results in the independent test set, with an AUC of 94.95% (95% CI, 91.78-97.58), a sensitivity of 87.67%, a specificity of 87.31%, and accuracy of 87.41%. Specifically, for grade II-IV glioma, the model achieved AUCs of 95.25% (95% CI, 91.09-98.23, 84.38% sensitivity, 89.04% specificity, 87.62% accuracy), 98.26% (95% CI, 95.22-100, 93.75% sensitivity, 98.15% specificity, 97.14% accuracy), and 93.83% (95%CI, 86.57-99.12, 92.00% sensitivity, 85.71% specificity, 87.37% accuracy) respectively for the identification of infiltrated brain areas. Moreover, our model achieved a mean Dice score of 87.60% for the whole tumor segmentation. Experimental results show that our multi-task model achieved superior performance and outperformed the state-of-the-art methods. The impressive performance demonstrates the potential of our work as an innovative solution for identifying tumor-infiltrated brain areas and suggests that it can be a practical tool for supporting clinical decision making",Li2023-zk,PubMed,,1,511,disc,areas,transformer-based multi-task deep learning model that can perform two tasks simultaneously: identifying infiltrated brain areas segmentation of gliomas.,location+boundary,,FALSE,TRUE,FALSE
131,Digital profiling of gene expression from histology images with linearized attention,"Cancer is a heterogeneous disease requiring costly genetic profiling for better understanding and management. Recent advances in deep learning have enabled cost-effective predictions of genetic alterations from whole slide images (WSIs). While transformers have driven significant progress in non-medical domains, their application to WSIs lags behind due to high model complexity and limited dataset sizes. Here, we introduce SEQUOIA, a linearized transformer model that predicts cancer transcriptomic profiles from WSIs. SEQUOIA is developed using 7584 tumor samples across 16 cancer types, with its generalization capacity validated on two independent cohorts comprising 1368 tumors. Accurately predicted genes are associated with key cancer processes, including inflammatory response, cell cycles and metabolism. Further, we demonstrate the value of SEQUOIA in stratifying the risk of breast cancer recurrence and in resolving spatial gene expression at loco-regional levels. SEQUOIA hence deciphers clinically relevant information from WSIs, opening avenues for personalized cancer management",Pizurica2024,PubMed,,1,511,disc,areas,linearized transformer model,gene expression from histology images,,FALSE,TRUE,FALSE
119,Enhanced brain tumor diagnosis using combined deep learning models and weight selection technique,"Brain tumor classification is a critical task in medical imaging, as accurate diagnosis directly influences treatment planning and patient outcomes. Traditional methods often fall short in achieving the required precision due to the complex and heterogeneous nature of brain tumors. In this study, we propose an innovative approach to brain tumor multi-classification by leveraging an ensemble learning method that combines advanced deep learning models with an optimal weighting strategy. Our methodology integrates Vision Transformers (ViT) and EfficientNet-V2 models, both renowned for their powerful feature extraction capabilities in medical imaging. This model enhances the feature extraction step by capturing both global and local features, thanks to the combination of different deep learning models with the ViT model. These models are then combined using a weighted ensemble approach, where each model's prediction is assigned a weight. To optimize these weights, we employ a genetic algorithm, which iteratively selects the best weight combinations to maximize classification accuracy. We trained and validated our ensemble model using a well-curated dataset comprising labeled brain MRI images. The model's performance was benchmarked against standalone ViT and EfficientNet-V2 models, as well as other traditional classifiers. The ensemble approach achieved a notable improvement in classification accuracy, precision, recall, and F1-score compared to individual models. Specifically, our model attained an accuracy rate of 95%, significantly outperforming existing methods. This study underscores the potential of combining advanced deep learning models with a genetic algorithm-optimized weighting strategy to tackle complex medical classification tasks. The enhanced diagnostic precision offered by our ensemble model can lead to better-informed clinical decisions, ultimately improving patient outcomes. Furthermore, our approach can be generalized to other medical imaging classification problems, paving the way for broader applications of AI in healthcare. This advancement in brain tumor classification contributes valuable insights to the field of medical AI, supporting the ongoing efforts to integrate advanced computational tools in clinical practice",10.3389/fninf.2024.1444650,PubMed,,1,511,disc,areas,ViT and EfficientNet-V2 -- cv on mri,brain tumor multicclassificatuon,,FALSE,TRUE,FALSE
132,Enhancing personalized gene expression prediction from DNA sequences using genomic foundation models,"Artificial intelligence (AI)/deep learning (DL) models that predict molecular phenotypes like gene expression directly from DNA sequences have recently emerged. While these models have proven effective at capturing the variation across genes, their ability to explain inter-individual differences has been limited. We hypothesize that the performance gap can be narrowed through the use of pre-trained embeddings from the Nucleotide Transformer, a large foundation model trained on 3,000+ genomes. We train a transformer model using the pre-trained embeddings and compare its predictive performance to Enformer, the current state-of-the-art model, using genotype and expression data from 290 individuals. Our model significantly outperforms Enformer in terms of correlation across individuals, and narrows the performance gap with an elastic net regression approach that uses just the genetic variants as predictors. Although simple regression models have their advantages in personalized prediction tasks, DL approaches based on foundation models pre-trained on diverse genomes have unique strengths in flexibility and interpretability. With further methodological and computational improvements with more training data, these models may eventually predict molecular phenotypes from DNA sequences with an accuracy surpassing that of regression-based approaches. Our work demonstrates the potential for large pre-trained AI/DL models to advance functional genomics",RAMPRASAD2024100347,PubMed,,1,511,disc,areas,use embeddings of Transforer model on genotype and expression data,predict molecular phenotypes like gene expression directly from DNA sequences,linked with CVI,FALSE,TRUE,FALSE
133,Evaluating Generative AI's Ability to Identify Cancer Subtypes in Publicly Available Structured Genetic Datasets,"Genetic data play a crucial role in diagnosing and treating various diseases, reflecting a growing imperative to integrate these data into clinical care. However, significant barriers such as the structure of electronic health records (EHRs), insurance costs for genetic testing, and the interpretability of genetic results impede this integration. This paper explores solutions to these challenges by combining recent technological advances with informatics and data science, focusing on the diagnostic potential of artificial intelligence (AI) in cancer research. AI has historically been applied in medical research with limited success, but recent developments have led to the emergence of large language models (LLMs). These transformer-based generative AI models, trained on vast datasets, offer significant potential for genetic and genomic analyses. However, their effectiveness is constrained by their training on predominantly human-written text rather than comprehensive, structured genetic datasets. This study reevaluates the capabilities of LLMs, specifically GPT models, in performing supervised prediction tasks using structured gene expression data. By comparing GPT models with traditional machine learning approaches, we assess their effectiveness in predicting cancer subtypes, demonstrating the potential of AI models to analyze real-world genetic data for generating real-world evidence",jpm14101022,PubMed,,1,511,disc,areas,GPT models on structured gene expression data, Identify Cancer Subtypes in Publicly Available Structured Genetic Datasets,,FALSE,TRUE,FALSE
11,"Genetic factors associated with reasons for clinical trial stoppage
==========
Why Clinical Trials Stop: The Role of Genetics","Many drug discovery projects are started but few progress fully through clinical trials to approval. Previous work has shown that human genetics support for the therapeutic hypothesis increases the chance of trial progression. Here, we applied natural language processing to classify the free-text reasons for 28,561 clinical trials that stopped before their endpoints were met. We then evaluated these classes in light of the underlying evidence for the therapeutic hypothesis and target properties. We found that trials are more likely to stop because of a lack of efficacy in the absence of strong genetic evidence from human populations or genetically modified animal models. Furthermore, certain trials are more likely to stop for safety reasons if the drug target gene is highly constrained in human populations and if the gene is broadly expressed across tissues. These results support the growing use of human genetics to evaluate targets for drug discovery programs
==========
Many drug discovery projects are started, but few progress fully through clinical trials to approval. Previous work has shown that human genetics support for the therapeutic hypothesis increases the chance of trial progression. Here, we applied natural language processing to classify the freetext reasons for 28,842 clinical trials that stopped before their endpoints were met. We then evaluated these classes in the light of the underlying evidence for the therapeutic hypothesis and target properties. We show that trials are more likely to stop due to lack of efficacy in the absence of strong genetic evidence from human populations or genetically-modified animal models. Furthermore, trials are more likely to stop for safety reasons if the drug target gene is highly constrained in human populations and if the gene is not selectively expressed. These results support the growing use of human genetics to evaluate targets for drug discovery programmes",Razuvayevskaya2024,"PubMed, medrxiv",,1,511,disc,areas,NLP (fine-tuned a BERT) for free-text classification for Classifying trial stoppages due to genetic factors.,Drug discovery and clinical trials; genetic evidence and trial progression.,"Highlights genetic evidence's role in increasing clinical trial success, particularly for efficacy and safety.",FALSE,TRUE,FALSE
134,MMGCN: Multi-modal multi-view graph convolutional networks for cancer prognosis prediction,"Accurate prognosis prediction for cancer patients plays a significant role in the formulation of treatment strategies, considerably impacting personalized medicine. Recent advancements in this field indicate that integrating information from various modalities, such as genetic and clinical data, and developing multi-modal deep learning models can enhance prediction accuracy. However, most existing multi-modal deep learning methods either overlook patient similarities that benefit prognosis prediction or fail to effectively capture diverse information due to measuring patient similarities from a single perspective. To address these issues, a novel framework called multi-modal multi-view graph convolutional networks (MMGCN) is proposed for cancer prognosis prediction. Initially, we utilize the similarity network fusion (SNF) algorithm to merge patient similarity networks (PSNs), individually constructed using gene expression, copy number alteration, and clinical data, into a fused PSN for integrating multi-modal information. To capture diverse perspectives of patient similarities, we treat the fused PSN as a multi-view graph by considering each single-edge-type subgraph as a view graph, and propose multi-view graph convolutional networks (GCNs) with a view-level attention mechanism. Moreover, an edge homophily prediction module is designed to alleviate the adverse effects of heterophilic edges on the representation power of GCNs. Finally, comprehensive representations of patient nodes are obtained to predict cancer prognosis. Experimental results demonstrate that MMGCN outperforms state-of-the-art baselines on four public datasets, including METABRIC, TCGA-BRCA, TCGA-LGG, and TCGA-LUSC, with the area under the receiver operating characteristic curve achieving 0.827 ± 0.005, 0.805 ± 0.014, 0.925 ± 0.007, and 0.746 ± 0.013, respectively. Our study reveals the effectiveness of the proposed MMGCN, which deeply explores patient similarities related to different modalities from a broad perspective, in enhancing the performance of multi-modal cancer prognosis prediction. The source code is publicly available at https://github.com/ping-y/MMGCN",YANG2024108400,PubMed,,1,511,disc,areas,multi-modal multi-view graph convolutional networks (MMGCN) is proposed for cancer prognosis prediction,use gene expression+clinical data to predict cancer,,FALSE,TRUE,FALSE
135,Modeling and predicting single-cell multi-gene perturbation responses with scLAMBDA,"Understanding cellular responses to genetic perturbations is essential for understanding gene regulation and phenotype formation. While high-throughput single-cell RNA-sequencing has facilitated detailed profiling of heterogeneous transcriptional responses to perturbations at the single-cell level, there remains a pressing need for computational models that can decode the mechanisms driving these responses and accurately predict outcomes to prioritize target genes for experimental design. Here, we present scLAMBDA, a deep generative learning framework designed to model and predict single-cell transcriptional responses to genetic perturbations, including single-gene and combinatorial multi-gene perturbations. By leveraging gene embeddings derived from large language models, scLAMBDA effectively integrates prior biological knowledge and disentangles basal cell states from perturbation-specific salient representations. Through comprehensive evaluations on multiple single-cell CRISPR Perturb-seq datasets, scLAMBDA consistently outperformed state-of-the-art methods in predicting perturbation outcomes, achieving higher prediction accuracy. Notably, scLAMBDA demonstrated robust generalization to unseen target genes and perturbations, and its predictions captured both average expression changes and the heterogeneity of single-cell responses. Furthermore, its predictions enable diverse downstream analyses, including the identification of differentially expressed genes and the exploration of genetic interactions, demonstrating its utility and versatility",Wang2024.12.04.626878,biorxiv,,1,511,disc,areas,"scLAMBDA, a deep generative learning framework designed to model and predict single-cell transcriptional responses to genetic perturbations",,,FALSE,TRUE,FALSE
77,ProtGO: A Transformer based Fusion Model for accurately predicting Gene Ontology (GO) Terms from full scale Protein Sequences,"Recent developments in next generation sequencing technology have led to the creation of extensive, open-source protein databases consisting of hundreds of millions of sequences. To render these sequences applicable in biomedical applications, they must be meticulously annotated by wet lab testing or extracting them from existing literature. Over the last few years, researchers have developed numerous automatic annotation systems, particularly deep learning models based on machine learning and artificial intelligence, to address this issue. In this work, we propose a transformer-based fusion model capable of predicting Gene Ontology (GO) terms from full-scale protein sequences, achieving state-of-the-art accuracy compared to other contemporary machine learning annotation systems. The approach performs particularly well on clustered split datasets, which comprise training and testing samples originating from distinct distributions that are structurally diverse. This demonstrates that the model is able to understand both short and long term dependencies within the enzyme's structure and can precisely identify the motifs associated with the various GO terms. Furthermore, the technique is lightweight and less computationally expensive compared to the benchmark methods, while at the same time not unaffected by sequence length, rendering it appropriate for diverse applications with varying sequence lengths",tamir2024protgotransformerbasedfusion,arXiv,,1,511,disc,areas,ProtGO: A Transformer based Fusion Model,predicting Gene Ontology (GO) Terms from full scale Protein Sequences,,FALSE,TRUE,FALSE
129,Weakly Supervised Classification for Nasopharyngeal Carcinoma with Transformer in Whole Slide Images,"Pathological examination of nasopharyngeal carcinoma (NPC) is an indispensable factor for diagnosis, guiding clinical treatment and judging prognosis. Traditional and fully supervised NPC diagnosis algorithms require manual delineation of regions of interest on the gigapixel of whole slide images (WSIs), which however is laborious and often biased. In this paper, we propose a weakly supervised framework based on Tokens-to-Token Vision Transformer (WS-T2T-ViT) for accurate NPC classification with only a slide-level label. The label of tile images is inherited from their slide-level label. Specifically, WS-T2T-ViT is composed of the multi-resolution pyramid, T2T-ViT and multi-scale attention module. The multi-resolution pyramid is designed for imitating the coarse-to-fine process of manual pathological analysis to learn features from different magnification levels. The T2T module captures the local and global features to overcome the lack of global information. The multi-scale attention module improves classification performance by weighting the contributions of different granularity levels. Extensive experiments are performed on the 802-patient NPC and CAMELYON16 dataset. WS-T2T-ViT achieves an area under the receiver operating characteristic curve (AUC) of 0.989 for NPC classification on the NPC dataset. The experiment results of CAMELYON16 dataset demonstrate the robustness and generalizability of WS-T2T-ViT in WSI-level classification",Hu2024-qo,PubMed,,1,511,disc,areas,Vision Transformer (T2T-ViT); for Image classification of nasopharyngeal carcinoma.,Cancer diagnosis using whole slide images (WSIs) for clinical decision-making.,Proposes a weakly supervised transformer framework for accurate cancer classification using WSIs.,FALSE,TRUE,FALSE
55,CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments,"The introduction of genome engineering technology has transformed biomedical research, making it possible to make precise changes to genetic information. However, creating an efficient gene-editing system requires a deep understanding of CRISPR technology, and the complex experimental systems under investigation. While Large Language Models (LLMs) have shown promise in various tasks, they often lack specific knowledge and struggle to accurately solve biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent augmented with domain knowledge and external tools to automate and enhance the design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages the reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes. We showcase the potential of CRISPR-GPT for assisting non-expert researchers with gene-editing experiments from scratch and validate the agent's effectiveness in a real-world use case. Furthermore, we explore the ethical and regulatory considerations associated with automated gene-editing design, highlighting the need for responsible and transparent use of these tools. Our work aims to bridge the gap between beginner biological researchers and CRISPR genome engineering techniques, and demonstrate the potential of LLM agents in facilitating complex biological discovery tasks
==========
The introduction of genome engineering technology has transformed biomedical research, making it possible to make precise changes to genetic information. However, creating an efficient gene-editing system requires a deep understanding of CRISPR technology, and the complex experimental systems under investigation. While Large Language Models (LLMs) have shown promise in various tasks, they often lack specific knowledge and struggle to accurately solve biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent augmented with domain knowledge and external tools to automate and enhance the design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages the reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes. We showcase the potential of CRISPR-GPT for assisting non-expert researchers with gene-editing experiments from scratch and validate the agent's effectiveness in a real-world use case. Furthermore, we explore the ethical and regulatory considerations associated with automated gene-editing design, highlighting the need for responsible and transparent use of these tools. Our work aims to bridge the gap between biological researchers across various fields with CRISPR genome engineering technology and demonstrate the potential of LLM agents in facilitating complex biological discovery tasks
==========
The introduction of genome engineering technology has transformed biomedical research, making it possible to make precise changes to genetic information. However, creating an efficient gene-editing system requires a deep understanding of CRISPR technology, and the complex experimental systems under investigation. While Large Language Models (LLMs) have shown promise in various tasks, they often lack specific knowledge and struggle to accurately solve biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent augmented with domain knowledge and external tools to automate and enhance the design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages the reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes. We showcase the potential of CRISPR-GPT for assisting non-expert researchers with gene-editing experiments from scratch and validate the agents effectiveness in a real-world use case. Furthermore, we explore the ethical and regulatory considerations associated with automated gene-editing design, highlighting the need for responsible and transparent use of these tools. Our work aims to bridge the gap between biological researchers across various fields with CRISPR genome engineering technology and demonstrate the potential of LLM agents in facilitating complex biological discovery tasks",huang2024crisprgptllmagentautomated,"arXiv,PubMed,biorxiv",,2,511,disc,areas,CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments,"reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes","not really genetic, but nice to discuss ",FALSE,FALSE,TRUE
184,Empowering personalized pharmacogenomics with generative AI solutions,"This study evaluates an AI assistant developed using OpenAI's GPT-4 for interpreting pharmacogenomic (PGx) testing results, aiming to improve decision-making and knowledge sharing in clinical genetics and to enhance patient care with equitable access. The AI assistant employs retrieval-augmented generation (RAG), which combines retrieval and generative techniques, by harnessing a knowledge base (KB) that comprises data from the Clinical Pharmacogenetics Implementation Consortium (CPIC). It uses context-aware GPT-4 to generate tailored responses to user queries from this KB, further refined through prompt engineering and guardrails. Evaluated against a specialized PGx question catalog, the AI assistant showed high efficacy in addressing user queries. Compared with OpenAI's ChatGPT 3.5, it demonstrated better performance, especially in provider-specific queries requiring specialized data and citations. Key areas for improvement include enhancing accuracy, relevancy, and representative language in responses. The integration of context-aware GPT-4 with RAG significantly enhanced the AI assistant's utility. RAG's ability to incorporate domain-specific CPIC data, including recent literature, proved beneficial. Challenges persist, such as the need for specialized genetic/PGx models to improve accuracy and relevancy and addressing ethical, regulatory, and safety concerns. This study underscores generative AI's potential for transforming healthcare provider support and patient accessibility to complex pharmacogenomic information. While careful implementation of large language models like GPT-4 is necessary, it is clear that they can substantially improve understanding of pharmacogenomic data. With further development, these tools could augment healthcare expertise, provider productivity, and the delivery of equitable, patient-centered healthcare services",Murugan2024-lo,PubMed,,2,511,"disc, post: DRA, post: CRGDS",areas,GPT-4 with Retrieval-Augmented Generation (RAG) for Pharmacogenomics data interpretation and question answering.,Interpretation of pharmacogenomic (PGx) testing results and provider-specific queries.,"GPT-4 with RAG enhances pharmacogenomic interpretation, improving healthcare provider support.",FALSE,FALSE,TRUE
82,Transformers significantly improve splice site prediction,"Mutations that affect RNA splicing significantly impact human diversity and disease. Here we present a method using transformers, a type of machine learning model, to detect splicing from raw 45,000-nucleotide sequences. We generate embeddings with residual neural networks and apply hard attention to select splice site candidates, enabling efficient training on long sequences. Our method surpasses the leading tool, SpliceAI, in detecting splice sites in GENCODE and ENSEMBL annotations. Using extensive RNA sequencing data from an Icelandic cohort of 17,848 individuals and the Genotype-Tissue Expression (GTEx) project, our method demonstrates superior performance in detecting splice junctions compared to SpliceAI-10k (PR-AUC = 0.834 vs. PR-AUC = 0.820) and is more effective at identifying disease-related splice variants in ClinVar (PR-AUC = 0.997 vs. PR-AUC = 0.996). These advancements hold promise for improving genetic research and clinical diagnostics, potentially leading to better understanding and treatment of splicing-related diseases",Jonsson2024,PubMed,,2,511,disc,areas,transformers,splice site prediction,,FALSE,FALSE,TRUE
124,MCNMF-Unet: a mixture Conv-MLP network with multi-scale features fusion Unet for medical image segmentation,"Recently, the medical image segmentation scheme combining Vision Transformer (ViT) and multilayer perceptron (MLP) has been widely used. However, one of its disadvantages is that the feature fusion ability of different levels is weak and lacks flexible localization information. To reduce the semantic gap between the encoding and decoding stages, we propose a mixture conv-MLP network with multi-scale features fusion Unet (MCNMF-Unet) for medical image segmentation. MCNMF-Unet is a U-shaped network based on convolution and MLP, which not only inherits the advantages of convolutional in extracting underlying features and visual structures, but also utilizes MLP to fuse local and global information of each layer of the network. MCNMF-Unet performs multi-layer fusion and multi-scale feature map skip connections in each network stage so that all the feature information can be fully utilized and the gradient disappearance problem can be alleviated. Additionally, MCNMF-Unet incorporates a multi-axis and multi-windows MLP module. This module is fully end-to-end and eliminates the need to consider the negative impact of image cropping. It not only fuses information from multiple dimensions and receptive fields but also reduces the number of parameters and computational complexity. We evaluated the proposed model on BUSI, ISIC2018 and CVC-ClinicDB datasets. The experimental results show that the performance of our proposed model is superior to most existing networks, with an IoU of 84.04% and a F1-score of 91.18%",Yuan2024-wp,PubMed,,1,512,disc,data,mixture conv-MLP network with multi-scale features fusion Unet (MCNMF-Unet) for medical image segmentation,image segmentation,,FALSE,TRUE,FALSE
125,NexToU: Efficient Topology-Aware U-Net for Medical Image Segmentation,"Convolutional neural networks (CNN) and Transformer variants have emerged as the leading medical image segmentation backbones. Nonetheless, due to their limitations in either preserving global image context or efficiently processing irregular shapes in visual objects, these backbones struggle to effectively integrate information from diverse anatomical regions and reduce inter-individual variability, particularly for the vasculature. Motivated by the successful breakthroughs of graph neural networks (GNN) in capturing topological properties and non-Euclidean relationships across various fields, we propose NexToU, a novel hybrid architecture for medical image segmentation. NexToU comprises improved Pool GNN and Swin GNN modules from Vision GNN (ViG) for learning both global and local topological representations while minimizing computational costs. To address the containment and exclusion relationships among various anatomical structures, we reformulate the topological interaction (TI) module based on the nature of binary trees, rapidly encoding the topological constraints into NexToU. Extensive experiments conducted on three datasets (including distinct imaging dimensions, disease types, and imaging modalities) demonstrate that our method consistently outperforms other state-of-the-art (SOTA) architectures. All the code is publicly available at https://github.com/PengchengShi1220/NexToU",shi2023nextouefficienttopologyawareunet,arXiv,,1,512,disc,data,"NexToU model, Pool GNN + Swin GNN from Vision GNN",Medical Image segmentation,,FALSE,TRUE,FALSE
128,TSCA-Net: Transformer based spatial-channel attention segmentation network for medical images,"Deep learning architectures based on convolutional neural network (CNN) and Transformer have achieved great success in medical image segmentation. Models based on the encoder-decoder framework like U-Net have been successfully employed in many realistic scenarios. However, due to the low contrast between object and background, various shapes and scales of objects, and complex background in medical images, it is difficult to locate targets and obtain better segmentation performance by extracting effective information from images. In this paper, an encoder-decoder architecture based on spatial and channel attention modules built by Transformer is proposed for medical image segmentation. Concretely, spatial and channel attention modules based on Transformer are utilized to extract spatial and channel global complementary information at different layers in U-shape network, which is beneficial to learn the detail features in different scales. To fuse better spatial and channel information from Transformer features, a spatial and channel feature fusion block is designed for the decoder. The proposed network inherits the advantages of both CNN and Transformer with the local feature representation and long-range dependency for medical images. Qualitative and quantitative experiments demonstrate that the proposed method outperforms against eight state-of-the-art segmentation methods on five publicly medical image datasets including different modalities, such as 80.23% and 93.56% Dice value, 67.13% and 88.94% Intersection over Union (IoU) value on the Multi-organ Nucleus Segmentation (MoNuSeg) and Combined Healthy Abdominal Organ Segmentation with Computed Tomography scans (CHAOS-CT) datasets",FU2024107938,PubMed,,1,512,disc,data,TSCA-Net: Transformer based spatial-channel attention segmentation network,segmentation of medical images,,FALSE,TRUE,FALSE
113,Automatic facial axes standardization of 3D fetal ultrasound images,"Craniofacial anomalies indicate early developmental disturbances and are usually linked to many genetic syndromes. Early diagnosis is critical, yet ultrasound (US) examinations often fail to identify these features. This study presents an AI-driven tool to assist clinicians in standardizing fetal facial axes/planes in 3D US, reducing sonographer workload and facilitating the facial evaluation. Our network, structured into three blocks-feature extractor, rotation and translation regression, and spatial transformer-processes three orthogonal 2D slices to estimate the necessary transformations for standardizing the facial planes in the 3D US. These transformations are applied to the original 3D US using a differentiable module (the spatial transformer block), yielding a standardized 3D US and the corresponding 2D facial standard planes. The dataset used consists of 1180 fetal facial 3D US images acquired between weeks 20 and 35 of gestation. Results show that our network considerably reduces inter-observer rotation variability in the test set, with a mean geodesic angle difference of 14.12$^{\circ}$ $\pm$ 18.27$^{\circ}$ and an Euclidean angle error of 7.45$^{\circ}$ $\pm$ 14.88$^{\circ}$. These findings demonstrate the network's ability to effectively standardize facial axes, crucial for consistent fetal facial assessments. In conclusion, the proposed network demonstrates potential for improving the consistency and accuracy of fetal facial assessments in clinical settings, facilitating early evaluation of craniofacial anomalies",alomar2024automaticfacialaxesstandardization,arXiv,,1,512,disc,data,spatial transformer,no raletion to med,theory: facial standartization -- then can be used in medicine,FALSE,TRUE,FALSE
192,Towards Democratization of Subspeciality Medical Expertise,"The scarcity of subspecialist medical expertise, particularly in rare, complex and life-threatening diseases, poses a significant challenge for healthcare delivery. This issue is particularly acute in cardiology where timely, accurate management determines outcomes. We explored the potential of AMIE (Articulate Medical Intelligence Explorer), a large language model (LLM)-based experimental AI system optimized for diagnostic dialogue, to potentially augment and support clinical decision-making in this challenging context. We curated a real-world dataset of 204 complex cases from a subspecialist cardiology practice, including results for electrocardiograms, echocardiograms, cardiac MRI, genetic tests, and cardiopulmonary stress tests. We developed a ten-domain evaluation rubric used by subspecialists to evaluate the quality of diagnosis and clinical management plans produced by general cardiologists or AMIE, the latter enhanced with web-search and self-critique capabilities. AMIE was rated superior to general cardiologists for 5 of the 10 domains (with preference ranging from 9% to 20%), and equivalent for the rest. Access to AMIE's response improved cardiologists' overall response quality in 63.7% of cases while lowering quality in just 3.4%. Cardiologists' responses with access to AMIE were superior to cardiologist responses without access to AMIE for all 10 domains. Qualitative examinations suggest AMIE and general cardiologist could complement each other, with AMIE thorough and sensitive, while general cardiologist concise and specific. Overall, our results suggest that specialized medical LLMs have the potential to augment general cardiologists' capabilities by bridging gaps in subspecialty expertise, though further research and validation are essential for wide clinical utility",osullivan2024democratizationsubspecialitymedicalexpertise,arXiv,,1,512,disc,data,"POTENTIAL explored the potential of AMIE (Articulate Medical Intelligence Explorer), a large language model (LLM)-based experimental AI system optimized for diagnostic dialogue, to potentially augment and support clinical decision-making in this challenging context.",curated a real-world dataset of 204 complex cases from a subspecialist cardiology practice,DATASET,FALSE,TRUE,FALSE
178,CARDBiomedBench: A Benchmark for Evaluating Large Language Model Performance in Biomedical Research,"Biomedical research requires sophisticated understanding and reasoning across multiple specializations. While large language models (LLMs) show promise in scientific applications, their capability to safely and accurately support complex biomedical research remains uncertain. We present CARDBiomedBench , a novel question-and-answer benchmark for evaluating LLMs in biomedical research. For our pilot implementation, we focus on neurodegenerative diseases (NDDs), a domain requiring integration of genetic, molecular, and clinical knowledge. The benchmark combines expert-annotated question-answer (Q/A) pairs with semi-automated data augmentation, drawing from authoritative public resources including drug development data, genome-wide association studies (GWAS), and Summary-data based Mendelian Randomization (SMR) analyses. We evaluated seven private and open-source LLMs across ten biological categories and nine reasoning skills, using novel metrics to assess both response quality and safety. Our benchmark comprises over 68,000 Q/A pairs, enabling robust evaluation of LLM performance. Current state-of-the-art models show significant limitations: models like Claude-3.5-Sonnet demonstrates excessive caution (Response Quality Rate: 25% [95% CI: 25% ± 1], Safety Rate: 76% ± 1), while others like ChatGPT-4o exhibits both poor accuracy and unsafe behavior (Response Quality Rate: 37% ± 1, Safety Rate: 31% ± 1). These findings reveal fundamental gaps in LLMs' ability to handle complex biomedical information. CARDBiomedBench establishes a rigorous standard for assessing LLM capabilities in biomedical research. Our pilot evaluation in the NDD domain reveals critical limitations in current models' ability to safely and accurately process complex scientific information. Future iterations will expand to other biomedical domains, supporting the development of more reliable AI systems for accelerating scientific discovery
==========
BackgroundsBiomedical research requires sophisticated understanding and reasoning across multiple specializations. While large language models (LLMs) show promise in scientific applications, their capability to safely and accurately support complex biomedical research remains uncertain.  MethodsWe present CARDBiomedBench, a novel question-and-answer benchmark for evaluating LLMs in biomedical research. For our pilot implementation, we focus on neurodegenerative diseases (NDDs), a domain requiring integration of genetic, molecular, and clinical knowledge. The benchmark combines expert-annotated question-answer (Q/A) pairs with semi-automated data augmentation, drawing from authoritative public resources including drug development data, genome-wide association studies (GWAS), and Summary-data based Mendelian Randomization (SMR) analyses. We evaluated seven private and open-source LLMs across ten biological categories and nine reasoning skills, using novel metrics to assess both response quality and safety.  ResultsOur benchmark comprises over 68,000 Q/A pairs, enabling robust evaluation of LLM performance. Current state-of-the-art models show significant limitations: models like Claude-3.5-Sonnet demonstrates excessive caution (Response Quality Rate: 25% [95% CI: 25% {+/-} 1], Safety Rate: 76% {+/-} 1), while others like ChatGPT-4o exhibits both poor accuracy and unsafe behavior (Response Quality Rate: 37% {+/-} 1, Safety Rate: 31% {+/-} 1). These findings reveal fundamental gaps in LLMs ability to handle complex biomedical information.  ConclusionCARDBiomedBench establishes a rigorous standard for assessing LLM capabilities in biomedical research. Our pilot evaluation in the NDD domain reveals critical limitations in current models ability to safely and accurately process complex scientific information. Future iterations will expand to other biomedical domains, supporting the development of more reliable AI systems for accelerating scientific discovery",Bianchi2025.01.15.633272,"PubMed,biorxiv",,2,512,disc,data,,,this is biomed benchmark!!!!!,FALSE,FALSE,TRUE
190,One-Versus-Others Attention: Scalable Multimodal Integration for Biomedical Data,"Multimodal learning models have become increasingly important as they surpass single-modality approaches on diverse tasks ranging from question-answering to autonomous driving. Despite the importance of multimodal learning, existing efforts focus on NLP applications, where the number of modalities is typically less than four (audio, video, text, images). However, data inputs in other domains, such as the medical field, may include X-rays, PET scans, MRIs, genetic screening, clinical notes, and more, creating a need for both efficient and accurate information fusion. Many state-of-the-art models rely on pairwise cross-modal attention, which does not scale well for applications with more than three modalities. For $n$ modalities, computing attention will result in $n \choose 2$ operations, potentially requiring considerable amounts of computational resources. To address this, we propose a new domain-neutral attention mechanism, One-Versus-Others (OvO) attention, that scales linearly with the number of modalities and requires only $n$ attention operations, thus offering a significant reduction in computational complexity compared to existing cross-modal attention algorithms. Using three diverse real-world datasets as well as an additional simulation experiment, we show that our method improves performance compared to popular fusion techniques while decreasing computation costs
==========
Multimodal models have become increasingly important as they surpass single-modality approaches on diverse tasks ranging from question-answering to disease diagnosis. Despite the importance of multimodal learning, existing efforts focus on vision-language applications, where the number of modalities rarely exceeds four (images, text, audio, video). However, data in healthcare domain, may include many more modalities like X-rays, PET scans, MRIs, genetic screening, genomic data, and clinical notes, creating a need for both efficient and accurate data integration. Many state-of-the-art multimodal models rely on cross-attention or self-attention for effective data integration, which do not scale well for applications with more than two modalities. The complexity per layer of computing attention in either paradigm is, at best, quadratic with respect to the number of modalities, posing a computational bottleneck that impedes broad adoption. To address this, we propose a new attention mechanism, One-Versus-Others (OvO) attention, that scales linearly with the number of modalities, thus offering a significant reduction in computational complexity compared to existing multimodal attention methods. Using three clinical datasets with multiple diverse modalities, we show that our method decreases computation costs while maintaining or increasing performance compared to popular integration techniques. Across all clinical datasets, OvO reduced the number of required floating point operations (FLOPs) by at least 91.98%, demonstrating its significant impact on efficiency and enabling multi-modal predictions in healthcare",golovanevsky2024oneversusothersattentionscalablemultimodal,"arXiv,PubMed",,2,512,disc,data,"One-Versus-Others (OvO) attention, that scales linearly with the number of modalities, thus offering a significant reduction in computational complexity compared to existing multimodal attention methods",Using three clinical datasets with multiple diverse modalities,"THEORETICAL, but GOOD - look at efficiency: OvO reduced the number of required floating point operations (FLOPs) by at least 91.98%, demonstrating its significant impact on efficiency and enabling multi-modal predictions in healthcare",FALSE,FALSE,TRUE
189,MedLexSp - a medical lexicon for Spanish medical natural language processing,"Medical lexicons enable the natural language processing (NLP) of health texts. Lexicons gather terms and concepts from thesauri and ontologies, and linguistic data for part-of-speech (PoS) tagging, lemmatization or natural language generation. To date, there is no such type of resource for Spanish. This article describes an unified medical lexicon for Medical Natural Language Processing in Spanish. MedLexSp includes terms and inflected word forms with PoS information and Unified Medical Language System[Formula: see text] (UMLS) semantic types, groups and Concept Unique Identifiers (CUIs). To create it, we used NLP techniques and domain corpora (e.g. MedlinePlus). We also collected terms from the Dictionary of Medical Terms from the Spanish Royal Academy of Medicine, the Medical Subject Headings (MeSH), the Systematized Nomenclature of Medicine - Clinical Terms (SNOMED-CT), the Medical Dictionary for Regulatory Activities Terminology (MedDRA), the International Classification of Diseases vs. 10, the Anatomical Therapeutic Chemical Classification, the National Cancer Institute (NCI) Dictionary, the Online Mendelian Inheritance in Man (OMIM) and OrphaData. Terms related to COVID-19 were assembled by applying a similarity-based approach with word embeddings trained on a large corpus. MedLexSp includes 100 887 lemmas, 302 543 inflected forms (conjugated verbs, and number/gender variants), and 42 958 UMLS CUIs. We report two use cases of MedLexSp. First, applying the lexicon to pre-annotate a corpus of 1200 texts related to clinical trials. Second, PoS tagging and lemmatizing texts about clinical cases. MedLexSp improved the scores for PoS tagging and lemmatization compared to the default Spacy and Stanza python libraries. The lexicon is distributed in a delimiter-separated value file; an XML file with the Lexical Markup Framework; a lemmatizer module for the Spacy and Stanza libraries; and complementary Lexical Record (LR) files. The embeddings and code to extract COVID-19 terms, and the Spacy and Stanza lemmatizers enriched with medical terms are provided in a public repository",Campillos-Llanos2023,PubMed,,1,513,disc,biases,"NLP techniques (lexicon-based, word embeddings); ML Task: Medical text processing (POS tagging, lemmatization) for Spanish texts.",Spanish medical text processing for clinical trials and case reports.,"importance of other languages models (in addition to racial bias, language bias)",FALSE,TRUE,FALSE
319,"What Goes In, Must Come Out: Generative Artificial Intelligence Does Not Present Algorithmic Bias Across Race and Gender in Medical Residency Specialties","Objective Artificial Intelligence (AI) has made significant inroads into various domains, including medicine, raising concerns about algorithmic bias. This study investigates the presence of biases in generative AI programs, with a specific focus on gender and racial representations across 19 medical residency specialties. Methodology This comparative study utilized DALL-E2 to generate faces representing 19 distinct residency training specialties, as identified by the Association of American Medical Colleges (AAMC), which were then compared to the AAMC's residency specialty breakdown with respect to race and gender. Results Our findings reveal an alignment between OpenAI's DALL-E2's predictions and the current demographic landscape of medical residents, suggesting an absence of algorithmic bias in this AI model. Conclusion This revelation gives rise to important ethical considerations. While AI excels at pattern recognition, it inherits and mirrors the biases present in its training data. To combat AI bias, addressing real-world disparities is imperative. Initiatives to promote inclusivity and diversity within medicine are commendable and contribute to reshaping medical education. This study underscores the need for ongoing efforts to dismantle barriers and foster inclusivity in historically male-dominated medical fields, particularly for underrepresented populations. Ultimately, our findings underscore the crucial role of real-world data quality in mitigating AI bias. As AI continues to shape healthcare and education, the pursuit of equitable, unbiased AI applications should remain at the forefront of these transformative endeavors",Lin2024-yg,PubMed,,1,513,disc,biases,,,,FALSE,TRUE,FALSE
177,Assessing Large Language Model Performance Related to Aging in Genetic Conditions,"Unlike some health conditions that have been extensively delineated throughout the lifespan, many genetic conditions are largely described in pediatric populations, with a focus on early manifestations like congenital anomalies and developmental delay. An apparent gap exists in understanding clinical features and optimal management as patients age. Generative artificial intelligence is transforming biomedical disciplines including through the introduction of large language models (LLMs). Motivated by these advances, we explored how LLMs handle age with respect to 282 genetic conditions selected based on prevalence. We divided these conditions into five categories: Disorders limited to childhood; Disorders limited to adulthood; Disorders with changes in presentation across ages; Disorders with changes in management across ages; Disorders with no changes across ages. We evaluated Llama-2-70b-chat (70b) and GPT-3.5 (GPT) capabilities at generating accurate medical vignettes for these conditions based on Correctness, Completeness, and Conciseness as graded by 3 clinicians. Using accurately generated vignettes as in-context prompts, we further generated and evaluated patient-geneticist dialogues and assessed LLM performance in answering specific questions regarding age-based management plans for a subset of conditions. Results revealed impressive performances of 70b with in-context prompting and GPT in generating vignettes. We overall did not observe age-based biases, though our experiments identified statistically significant differences in some areas related to LLM output. Despite impressive capabilities, LLMs still have limitations in clinical applications",Othman2025.01.19.25320798,medrxiv,,2,513,disc,biases,"evaluated Llama-2-70b-chat (70b) and GPT-3.5 (GPT) capabilities at generating accurate medical vignettes for these conditions based on Correctness, Completeness, and Conciseness as graded by 3 clinicians","how LLMs handle age with respect to 282 genetic conditions selected based on prevalence - no significant biases, but in some output identified",age biases (in addition to race),FALSE,FALSE,TRUE
164,Association of reviewer experience with discriminating human-written versus ChatGPT-written abstracts,"To determine if reviewer experience impacts the ability to discriminate between human-written and ChatGPT-written abstracts. Thirty reviewers (10 seniors, 10 juniors, and 10 residents) were asked to differentiate between 10 ChatGPT-written and 10 human-written (fabricated) abstracts. For the study, 10 gynecologic oncology abstracts were fabricated by the authors. For each human-written abstract we generated a ChatGPT matching abstract by using the same title and the fabricated results of each of the human generated abstracts. A web-based questionnaire was used to gather demographic data and to record the reviewers' evaluation of the 20 abstracts. Comparative statistics and multivariable regression were used to identify factors associated with a higher correct identification rate. The 30 reviewers discriminated 20 abstracts, giving a total of 600 abstract evaluations. The reviewers were able to correctly identify 300/600 (50%) of the abstracts: 139/300 (46.3%) of the ChatGPT-generated abstracts and 161/300 (53.7%) of the human-written abstracts (p=0.07). Human-written abstracts had a higher rate of correct identification (median (IQR) 56.7% (49.2-64.1%) vs 45.0% (43.2-48.3%), p=0.023). Senior reviewers had a higher correct identification rate (60%) than junior reviewers and residents (45% each; p=0.043 and p=0.002, respectively). In a linear regression model including the experience level of the reviewers, familiarity with artificial intelligence (AI) and the country in which the majority of medical training was achieved (English speaking vs non-English speaking), the experience of the reviewer (β=10.2 (95% CI 1.8 to 18.7)) and familiarity with AI (β=7.78 (95% CI 0.6 to 15.0)) were independently associated with the correct identification rate (p=0.019 and p=0.035, respectively). In a correlation analysis the number of publications by the reviewer was positively correlated with the correct identification rate (r28)=0.61, p<0.001. A total of 46.3% of abstracts written by ChatGPT were detected by reviewers. The correct identification rate increased with reviewer and publication experience",LEVIN2024669,PubMed,,2,513,disc,biases,discriminating human-written versus ChatGPT-written abstracts, human-written abstract we generated a ChatGPT matching abstract by using the same title and the fabricated results of each of the human generated abstracts,,FALSE,FALSE,TRUE
194,Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation,"Large language models like GPT-3.5-turbo and GPT-4 hold promise for healthcare professionals, but they may inadvertently inherit biases during their training, potentially affecting their utility in medical applications. Despite few attempts in the past, the precise impact and extent of these biases remain uncertain. Through both qualitative and quantitative analyses, we find that these models tend to project higher costs and longer hospitalizations for White populations and exhibit optimistic views in challenging medical scenarios with much higher survival rates. These biases, which mirror real-world healthcare disparities, are evident in the generation of patient backgrounds, the association of specific diseases with certain races, and disparities in treatment recommendations, etc. Our findings underscore the critical need for future research to address and mitigate biases in language models, especially in critical healthcare applications, to ensure fair and accurate outcomes for all patients",Yang2024-zv,"arXiv,PubMed",,2,513,"disc, post: CRGDS",biases,gpt 3.5 and 4,Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation,in addition to age bias,FALSE,FALSE,TRUE
86,BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments,"Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent, using Claude 3.5 Sonnet, achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy",roohani2025biodiscoveryagentaiagentdesigning,arXiv,,1,514,disc,techniques,Agent for Designing Genetic Perturbation Experiments,"searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions",,FALSE,TRUE,FALSE
183,ChatGPT- versus human-generated answers to frequently asked questions about diabetes: a Turing test-inspired survey among employees of a Danish diabetes center,"BackgroundLarge language models have received enormous attention recently with some studies demonstrating their potential clinical value, despite not being trained specifically for this domain. We aimed to investigate whether ChatGPT, a language model optimized for dialogue, can answer frequently asked questions about diabetes.  MethodsWe conducted a closed e-survey among employees of a large Danish diabetes center. The study design was inspired by the Turing test and non-inferiority trials. Our survey included ten questions with two answers each. One of these was written by a human expert, while the other was generated by ChatGPT. Participants had the task to identify the ChatGPT-generated answer. Data was analyzed at the question-level using logistic regression with robust variance estimation with clustering at participant level. In secondary analyses, we investigated the effect of participant characteristics on the outcome. A 55% non-inferiority margin was pre-defined based on precision simulations and had been published as part of the study protocol before data collection began.  FindingsAmong 311 invited individuals, 183 participated in the survey (59% response rate). 64% had heard of ChatGPT before, and 19% had tried it. Overall, participants could identify ChatGPT-generated answers 59.5% (95% CI: 57.0, 62.0) of the time. Among participant characteristics, previous ChatGPT use had the strongest association with the outcome (odds ratio: 1.52 (1.16, 2.00), p=0.003). Previous users answered 67.4% (61.7, 72.7) of the questions correctly, versus non-users 57.6% (54.9, 60.3).  InterpretationParticipants could distinguish between ChatGPT-generated and human-written answers somewhat better than flipping a fair coin. However, our results suggest a stronger predictive value of linguistic features rather than the actual content. Rigorously planned studies are needed to elucidate the risks and benefits of integrating such technologies in routine clinical practice.  Research in contextO_ST_ABSEvidence before this studyC_ST_ABSChatGPT (OpenAI, San Francisco, CA) was released on 30th of November, 2022. A PubMed search for  ChatGPT conducted on 5th of February, 2023, returned 21 results. All of these were either editorials, commentaries or investigated educational perspectives of the technology. We also searched medRxiv, which returned seven preprints on the topic. Two studies investigated ChatGPT  s performance on the United States Medical Licensing Exam and reported that it passed some components of the exam. Other studies investigated ChatGPT  s ability to answer questions in specific medical specialties, including ophthalmology, genetics, musculoskeletal disorders, with encouraging results, but often expressing the need for further specialization. We identified one study where participants had to distinguish between chatbot- and human-generated answers to patient-healthcare provider interactions extracted from electronic health records. Chatbot-generated responses were identified 65% of the time, suggesting that they were weakly distinguishable from human-generated answers.  Added value of this studyOur study is among the first ones to assess the capabilities of ChatGPT from the patients perspective instead of focusing on retrieval of scientific knowledge. We did so in a rigorously designed study inspired by the Turing test and non-inferiority trials. Among all participants, 64% had heard of ChatGPT before, and 19% had tried it. These proportions were even higher among men (87% and 48%). Overall, participants could identify ChatGPT-generated answers (versus human) 60% of the time. We found that individuals who had previously used ChatGPT could distinguish ChatGPT-generated answers from human answers more often, while having contact with patients was not as strong a discriminator. This may suggest a stronger predictive value of linguistic features rather than the actual content.  Implications of all available evidenceAfter ChatGPT, a general-purpose large language model optimized for dialogue, demonstrated its capabilities to the general public, an enormous interest arose in how large language models can support medical research and clinical tasks. Despite not being specifically trained for this, ChatGPT not only has clinical knowledge, but also encodes information about disease management and practical aspects relevant to patients everyday lives. Large language models optimized for healthcare use are warranted, but rigorously planned studies are needed to elucidate the risks and benefits of integrating such technologies in patient care",Hulman2023-zp,medrxiv,,1,514,disc,techniques,ChatGPT; ML Task: Answering frequently asked questions (FAQs) on diabetes.,Diabetes management; comparison of ChatGPT and human-generated responses.,"ChatGPT answers were identified 60% of the time, with prior users better at distinguishing responses, highlighting the importance of linguistic features over content.",FALSE,TRUE,FALSE
245,Facilitating family communication of familial hypercholesterolemia genetic risk: Assessing engagement with innovative chatbot technology from the IMPACT-FH study,"To assess use of two web-based conversational agents, the Family Sharing Chatbot (FSC) and One Month Chatbot (OMC), by individuals with familial hypercholesterolemia (FH). FSC and OMC were sent using an opt-out methodology to a cohort of individuals receiving a FH genetic result. Data from 7/1/2021 through 5/12/2022 was obtained from the electronic health record and the chatbots' HIPAA-secure web portal. Of 175 subjects, 21 (12%) opted out of the chatbots. Older individuals were more likely to opt out. Most (91/154, 59%) preferred receiving chatbots via the patient EHR portal. Seventy-five individuals (49%) clicked the FSC link, 62 (40%) interacted, and 36 (23%) shared a chatbot about their FH result with at least one relative. Ninety-two of the subjects received OMC, 22 (23%) clicked the link and 20 (21%) interacted. Individuals who shared were majority female and younger on average than the overall cohort. Reminders tended to increase engagement. Results demonstrate characteristics relevant to chatbot engagement. Individuals may be more inclined to receive chatbots if integrated within the patient EHR portal. Frequent reminders can potentially improve chatbot utilization. FSC and OMC employ innovative digital health technology that can facilitate family communication about hereditary conditions",,PubMed,,1,514,disc,techniques,,,,FALSE,TRUE,FALSE
179,Chatbot for the Return of Positive Genetic Screening Results for Hereditary Cancer Syndromes: a Prompt Engineering Study,"The growing demand for genomic testing and limited access to experts necessitate innovative service models. While chatbots have shown promise in supporting genomic services like pre-test counseling, their use in returning positive genetic results, especially using the more recent large language models (LLMs) remains unexplored. This study reports the prompt engineering process and intrinsic evaluation of the LLM component of a chatbot designed to support returning positive population-wide genomic screening results. We used a three-step prompt engineering process, including Retrieval-Augmented Generation (RAG) and few-shot techniques to develop an open-response chatbot. This was then evaluated using two hypothetical scenarios, with experts rating its performance using a 5-point Likert scale across eight criteria: tone, clarity, program accuracy, domain accuracy, robustness, efficiency, boundaries, and usability. The chatbot achieved an overall score of 3.88 out of 5 across all criteria and scenarios. The highest ratings were in Tone (4.25), Usability (4.25), and Boundary management (4.0), followed by Efficiency (3.88), Clarity and Robustness (3.81), and Domain Accuracy (3.63). The lowest-rated criterion was Program Accuracy, which scored 3.25. The LLM handled open-ended queries and maintained boundaries, while the lower Program Accuracy rating indicates areas for improvement. Future work will focus on refining prompts, expanding evaluations, and exploring optimal hybrid chatbot designs that integrate LLM components with rule-based chatbot components to enhance genomic service delivery",Coen2024-ug,PubMed,,2,514,"disc, post: CRGDS",techniques,"Retrieval-Augmented Generation (RAG), Large Language Models (LLMs) + prompt engineering for genetic result interpretation.",Genomic screening for hereditary cancer syndromes; delivering positive test results via chatbots.," The chatbot shows promise in delivering genetic screening results, scoring high on tone, usability, and boundaries but needs improvement in program accuracy.",FALSE,FALSE,TRUE
182,ChatGPT for phenotypes extraction: one model to rule them all?,"Information Extraction (IE) is a core task in Natural Language Processing (NLP) where the objective is to identify factual knowledge in textual documents (often unstructured), and feed downstream use cases with the resulting output. In genomic medicine for instance, being able to extract the most precise list of phenotypes associated to a patient allows to improve genetic disease diagnostic, which represents a vital step in the modern deep phenotyping approach. As most of the phenotypic information lies in clinical reports, the challenge is to build an IE pipeline to automatically recognize phenotype concepts from free-text notes. A new machine learning paradigm around large language models (LLM) has given rise of an increasing number of academic works on this topic lately, where sophisticated combinations of different technics have been employed to improve the phenotypes extraction accuracy. Even more recently released, the ChatGPT<sup>1</sup> application nevertheless raises the question of the relevance of these approches compared to this new generic one based on an instruction-oriented LLM. In this paper, we propose a rigorous evaluation of ChatGPT and the current state-of-the-art solutions on this specific task, and discuss the possible impacts and the technical evolutions to consider in the medical domain.Clinical relevance- Deep phenotyping on electronic health records has proven its ability to improve genetic diagnosis by clinical exomes [10]. Thus, comparing state-of-the-art solutions in order to derive insights and improving research paths is essential",Labbe2023-lj,PubMed,,2,514,"disc, pre: RS",techniques,,"propose a rigorous evaluation of ChatGPT and the current state-of-the-art solutions on this specific task, and discuss the possible impacts and the technical evolutions to consider in the medical domai",propose a benchmark,FALSE,FALSE,TRUE
186,Genomic Foundationless Models: Pretraining Does Not Promise Performance,"AO_SCPLOWBSTRACTC_SCPLOWThe success of Large Language Models has inspired the development of Genomic Foundation Models (GFMs) through similar pretraining techniques. However, the relationship between pretraining performance and effectiveness in downstream genomic tasks remains unclear. Additionally, the high computational cost of pre-training raises questions about its cost-efficiency. To assess the usefulness of pre-training in genomics, we evaluated seven different GFMs across various bench-marks, comparing them to their counterparts with randomly initialized weights. Surprisingly, we found that randomly initialized models can match or even surpass the performance of pretrained GFMs in finetuning and feature extraction tasks. We also discovered that pretrained GFMs fail to capture clinically relevant genetic mutations, which are crucial for understanding genetic disorders and phenotypic traits. Our results indicate that most of the current pretrained GFMs lack a ""foundational"" understanding of genomics and provide minimal utility, even for basic tasks such as sequence classification. These findings collectively highlight the need for critically rethinking the pretraining approaches for genomics. Our code is available at https://github.com/m42-health/gfm-random-eval",Vishniakov2024.12.18.628606,biorxiv,,2,514,disc,techniques,Genomic Foundation Models (GFMs),,Highlight importance of correct training (ref allen-zhu),FALSE,FALSE,TRUE
187,High-Throughput Phenotyping of Clinical Text Using Large Language Models,"High-throughput phenotyping automates the mapping of patient signs to standardized ontology concepts and is essential for precision medicine. This study evaluates the automation of phenotyping of clinical summaries from the Online Mendelian Inheritance in Man (OMIM) database using large language models. Due to their rich phenotype data, these summaries can be surrogates for physician notes. We conduct a performance comparison of GPT-4 and GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in identifying, categorizing, and normalizing signs, achieving concordance with manual annotators comparable to inter-rater agreement. Despite some limitations in sign normalization, the extensive pre-training of GPT-4 results in high performance and generalizability across several phenotyping tasks while obviating the need for manually annotated training data. Large language models are expected to be the dominant method for automating high-throughput phenotyping of clinical text",hier2024highthroughputphenotypingclinicaltext,arXiv,,2,514,"disc, pre: KNLR",techniques,GPT-4 and GPT-3.5 for High-throughput clinical text phenotyping using NLP.,Automating phenotype extraction from clinical text (OMIM database).,GPT-4 surpasses GPT-3.5 for automating phenotype identification in clinical summaries.,FALSE,FALSE,TRUE
188,Large language models identify causal genes in complex trait GWAS,"Identifying underlying causal genes at significant loci from genome-wide association studies (GWAS) remains a challenging task. Literature evidence for disease-gene co-occurrence, whether through automated approaches or human expert annotation, is one way of nominating causal genes at GWAS loci. However, current automated approaches are limited in accuracy and generalizability, and expert annotation is not scalable to hundreds of thousands of significant findings. Here, we demonstrate that large language models (LLMs) can accurately identify genes likely to be causal at loci from GWAS. By evaluating the performance of GPT-3.5 and GPT-4 on datasets of GWAS loci with high-confidence causal gene annotations, we show that these models outperform state-of-the-art methods in identifying putative causal genes. These findings highlight the potential of LLMs to augment existing approaches to causal gene discovery",Shringarpure2024.05.30.24308179,medrxiv,,2,514,"disc, ana: CVI",techniques,"GPT-3.5, GPT-4 for Identifying causal genes in GWAS datasets.",Genomic data analysis for complex trait and disease gene identification.,"LLMs outperform current methods in identifying causal genes in GWAS, augmenting traditional approaches.",FALSE,FALSE,TRUE
191,OpenAI o1-Preview vs. ChatGPT in Healthcare: A New Frontier in Medical AI Reasoning,"This editorial explores the recent advancements in generative artificial intelligence with the newly-released OpenAI o1-Preview, comparing its capabilities to the traditional ChatGPT (GPT-4) model, particularly in the context of healthcare. While ChatGPT has shown many applications for general medical advice and patient interactions, OpenAI o1-Preview introduces new features with advanced reasoning skills using a chain of thought processes that could enable users to tackle more complex medical queries such as genetic disease discovery, multi-system or complex disease care, and medical research support. The article explores some of the new model's potential and other aspects that may affect its usage, like slower response times due to its extensive reasoning approach yet highlights its potential for reducing hallucinations and offering more accurate outputs for complex medical problems. Ethical challenges, data diversity, access equity, and transparency are also discussed, identifying key areas for future research, including optimizing the use of both models in tandem for healthcare applications. The editorial concludes by advocating for collaborative exploration of all large language models (LLMs), including the novel OpenAI o1-Preview, to fully utilize their transformative potential in medicine and healthcare delivery. This model, with its advanced reasoning capabilities, presents an opportunity to empower healthcare professionals, policymakers, and computer scientists to work together in transforming patient care, accelerating medical research, and enhancing healthcare outcomes. By optimizing the use of several LLM models in tandem, healthcare systems may enhance efficiency and precision, as well as mitigate previous LLM challenges, such as ethical concerns, access disparities, and technical limitations, steering to a new era of artificial intelligence (AI)-driven healthcare",Temsah2024-ux,PubMed,,2,514,disc,techniques,o1 vs others,just review of them in terms of AI reasoning in healthcare,??,FALSE,FALSE,TRUE
50,A transformer-based genomic prediction method fused with knowledge-guided module,"Genomic prediction (GP) uses single nucleotide polymorphisms (SNPs) to establish associations between markers and phenotypes. Selection of early individuals by genomic estimated breeding value shortens the generation interval and speeds up the breeding process. Recently, methods based on deep learning (DL) have gained great attention in the field of GP. In this study, we explore the application of Transformer-based structures to GP and develop a novel deep-learning model named GPformer. GPformer obtains a global view by gleaning beneficial information from all relevant SNPs regardless of the physical distance between SNPs. Comprehensive experimental results on five different crop datasets show that GPformer outperforms ridge regression-based linear unbiased prediction (RR-BLUP), support vector regression (SVR), light gradient boosting machine (LightGBM) and deep neural network genomic prediction (DNNGP) in terms of mean absolute error, Pearson's correlation coefficient and the proposed metric consistent index. Furthermore, we introduce a knowledge-guided module (KGM) to extract genome-wide association studies-based information, which is fused into GPformer as prior knowledge. KGM is very flexible and can be plugged into any DL network. Ablation studies of KGM on three datasets illustrate the efficiency of KGM adequately. Moreover, GPformer is robust and stable to hyperparameters and can generalize to each phenotype of every dataset, which is suitable for practical application scenarios",,PubMed,,1,,,,GPformer.,"Genomic Prediction -- from snps to phenotypes, BUT it's agriculture",,FALSE,TRUE,FALSE
112,Artificial Intelligence ECG Analysis in Patients with Short QT Syndrome to Predict Life-Threatening Arrhythmic Events,"Short QT syndrome (SQTS) is an inherited cardiac ion-channel disease related to an increased risk of sudden cardiac death (SCD) in young and otherwise healthy individuals. SCD is often the first clinical presentation in patients with SQTS. However, arrhythmia risk stratification is presently unsatisfactory in asymptomatic patients. In this context, artificial intelligence-based electrocardiogram (ECG) analysis has never been applied to refine risk stratification in patients with SQTS. The purpose of this study was to analyze ECGs from SQTS patients with the aid of different AI algorithms to evaluate their ability to discriminate between subjects with and without documented life-threatening arrhythmic events. The study group included 104 SQTS patients, 37 of whom had a documented major arrhythmic event at presentation and/or during follow-up. Thirteen ECG features were measured independently by three expert cardiologists; then, the dataset was randomly divided into three subsets (training, validation, and testing). Five shallow neural networks were trained, validated, and tested to predict subject-specific class (non-event/event) using different subsets of ECG features. Additionally, several deep learning and machine learning algorithms, such as Vision Transformer, Swin Transformer, MobileNetV3, EfficientNetV2, ConvNextTiny, Capsule Networks, and logistic regression were trained, validated, and tested directly on the scanned ECG images, without any manual feature extraction. Furthermore, a shallow neural network, a 1-D transformer classifier, and a 1-D CNN were trained, validated, and tested on ECG signals extracted from the aforementioned scanned images. Classification metrics were evaluated by means of sensitivity, specificity, positive and negative predictive values, accuracy, and area under the curve. Results prove that artificial intelligence can help clinicians in better stratifying risk of arrhythmia in patients with SQTS. In particular, shallow neural networks' processing features showed the best performance in identifying patients that will not suffer from a potentially lethal event. This could pave the way for refined ECG-based risk stratification in this group of patients, potentially helping in saving the lives of young and otherwise healthy individuals",,PubMed,,1,,,,"ViS, SWIN, and other sv methods",ECG analysis from short QT syndrome patients,cv in another topic: ecg,FALSE,TRUE,FALSE
20,Can Electronic care planning using AI Summarization Yield equal Documentation Quality? (EASY eDocQ),"ImportanceData, information and knowledge in health care has expanded exponentially over the last 50 years, leading to significant challenges with information overload and complex, fragmented care plans. Generative AI has the potential to facilitate summarization and integration of knowledge and wisdom to through rapid integration of data and information to enable efficient care planning.  ObjectiveOur objective was to understand the value of AI generated summarization through short synopses at the care transition from hospital to first outpatient visit.  DesignUsing a de-identified data set of recently hospitalized patients with multiple chronic illnesses, we used the data-information-knowledge-wisdom framework to train clinicians and an open-source generative AI Large Language Model system to produce summarized patient assessments after hospitalizations. Both sets of synopses were judged blinded in random order by clinician judges.  ParticipantsDe-identified patients had multiple chronic conditions and a recent hospitalization. Raters were physicians at various levels of training.  Main outcomeAccuracy, succinctness, synthesis and usefulness of synopses using a standardized scale with scores > 80% indicating success.  ResultsAI and clinicians summarized 80 patients with 10% overlap. In blinded trials, AI synopses were rated as useful 75% of the time versus 76% for human generated ones. AI had lower succinctness ratings for the Data synopsis task (55-67%) versus human (84-86%). For accuracy and synthesis, AI had near equal or better scores in other domains (AI: 72%-79%, humans: 68%-84%), with best scores from AI in Wisdom. Interrater agreement was moderate, indicating different preferences for synopsis content, and did not vary between AI and human-created synopses.  DiscussionAI-created synopses that were nearly equivalent to human-created ones; they were slightly longer and did not always synthesize individual data elements compared to humans. Given their rapid introduction into clinical care, our framework and protocol for evaluation of these tools provides strong benchmarking capabilities for developers and implementers.  Key PointsO_ST_ABSQuestionC_ST_ABSCan a Generative AI Large Language Model be trained to generate accurate and useful patient synopses through chart summarization for use in outpatient settings after hospital discharge?  FindingsUsing a Data-Information-Knowledge-Wisdom framework, clinicians and an open-source AI system were trained to summarize charts; these synopses were rated blindly using a standardized index. Synopses from the AI were rated as useful 75% of the time versus 76% for human generated ones, AI synopses scored highest in Wisdom for accuracy and synthesis. Interrater agreement was moderate but did not vary between AI and human.  MeaningThis study provides a concrete, replicable protocol for benchmarking LLM summarization outputs and demonstrates general equivalence to human-created synopses for outpatient use after care transitions",,medrxiv,,1,,,, used the data-information-knowledge-wisdom framework to train clinicians and an open-source generative AI Large Language Model system to produce summarized patient assessments after hospitalizations,summarizing patients assessment,,FALSE,TRUE,FALSE
60,"Enhancing recognition and interpretation of functional phenotypic sequences through fine-tuning pre-trained genomic models
==========
Enhancing Recognition and Interpretation of Functional Phenotypic Sequences through Fine-Tuning Pre-Trained Genomic Models","Decoding human genomic sequences requires comprehensive analysis of DNA sequence functionality. Through computational and experimental approaches, researchers have studied the genotype-phenotype relationship and generate important datasets that help unravel complicated genetic blueprints. Thus, the recently developed artificial intelligence methods can be used to interpret the functions of those DNA sequences. This study explores the use of deep learning, particularly pre-trained genomic models like DNA_bert_6 and human_gpt2-v1, in interpreting and representing human genome sequences. Initially, we meticulously constructed multiple datasets linking genotypes and phenotypes to fine-tune those models for precise DNA sequence classification. Additionally, we evaluate the influence of sequence length on classification results and analyze the impact of feature extraction in the hidden layers of our model using the HERV dataset. To enhance our understanding of phenotype-specific patterns recognized by the model, we perform enrichment, pathogenicity and conservation analyzes of specific motifs in the human endogenous retrovirus (HERV) sequence with high average local representation weight (ALRW) scores. We have constructed multiple genotype-phenotype datasets displaying commendable classification performance in comparison with random genomic sequences, particularly in the HERV dataset, which achieved binary and multi-classification accuracies and F1 values exceeding 0.935 and 0.888, respectively. Notably, the fine-tuning of the HERV dataset not only improved our ability to identify and distinguish diverse information types within DNA sequences but also successfully identified specific motifs associated with neurological disorders and cancers in regions with high ALRW scores. Subsequent analysis of these motifs shed light on the adaptive responses of species to environmental pressures and their co-evolution with pathogens. These findings highlight the potential of pre-trained genomic models in learning DNA sequence representations, particularly when utilizing the HERV dataset, and provide valuable insights for future research endeavors. This study represents an innovative strategy that combines pre-trained genomic model representations with classical methods for analyzing the functionality of genome sequences, thereby promoting cross-fertilization between genomics and artificial intelligence
==========
Decoding high-quality human genomic sequences requires comprehensive analysis of DNA sequence functionality. Through computational and experimental approaches, researchers study the genotype-phenotype relationship and generate important datasets that help unravel complicated genetic blueprints. This study explores the use of deep learning, particularly pre-trained models like DNA_bert_6 and human_gpt2-v1, in interpreting and representing human genome sequences. We meticulously construct multiple datasets linking genotypes and phenotypes to fine-tune pre-trained models for precise DNA sequence classification. Furthermore, we specifically focused on the human endogenous retrovirus (HERV) dataset with commendable classification performance (both binary and multi-classification accuracy and F1 values above 0.935 and 0.888, respectively). We evaluate the influence of sequence length on classification results and analyze the impact of feature extraction in the models hidden layers using the HERV dataset. To further understand the phenotype-specific patterns learned by the model, we perform enrichment, pathogenicity and conservation analyzes of specific motifs in the HERV sequence with high average local representation weight (LRAW) scores. Overall, the generated datasets further provide numerous additional genotype-phenotype datasets for evaluating the performance of genomic models. The findings highlight the potential of large models in learning DNA sequence representations, particularly when utilizing the HERV dataset, and provide valuable insights for future research. This work represents an innovative strategy that combines pre-trained model representations with classical omics methods for analyzing the functionality of genome sequences, fostering cross-fertilization between genomics and advanced AI. The source code and data are available at https://github.com/GeorgeBGM/Genome_Fine-Tuning",,"PubMed,biorxiv",,1,,,,fine tuning existing dna_bert_6 and human_gpt2-v1, Recognition and Interpretation of Functional Phenotypic Sequences,uses viruses,FALSE,TRUE,FALSE
39,"Evaluating Computer Vision, Large Language, and Genome-Wide Association Models in a Limited Sized Patient Cohort for Pre-Operative Risk Stratification in Adult Spinal Deformity Surgery","Background: Adult spinal deformities (ASD) are varied spinal abnormalities, often necessitating surgical intervention when associated with pain, worsening deformity, or worsening function. Predicting post-operative complications and revision surgery is critical for surgical planning and patient counseling. Due to the relatively small number of cases of ASD surgery, machine learning applications have been limited to traditional models (e.g., logistic regression or standard neural networks) and coarse clinical variables. We present the novel application of advanced models (CNN, LLM, GWAS) using complex data types (radiographs, clinical notes, genomics) for ASD outcome prediction. Methods: We developed a CNN trained on 209 ASD patients (1549 radiographs) from the Stanford Research Repository, a CNN pre-trained on VinDr-SpineXR (10,468 spine radiographs), and an LLM using free-text clinical notes from the same 209 patients, trained via Gatortron. Additionally, we conducted a GWAS using the UK Biobank, contrasting 540 surgical ASD patients with 7355 non-surgical ASD patients. Results: The LLM notably outperformed the CNN in predicting pulmonary complications (F1: 0.545 vs. 0.2881), neurological complications (F1: 0.250 vs. 0.224), and sepsis (F1: 0.382 vs. 0.132). The pre-trained CNN showed improved sepsis prediction (AUC: 0.638 vs. 0.534) but reduced performance for neurological complication prediction (AUC: 0.545 vs. 0.619). The LLM demonstrated high specificity (0.946) and positive predictive value (0.467) for neurological complications. The GWAS identified 21 significant (p < 10<sup>-5</sup>) SNPs associated with ASD surgery risk (OR: mean: 3.17, SD: 1.92, median: 2.78), with the highest odds ratio (8.06) for the LDB2 gene, which is implicated in ectoderm differentiation. Conclusions: This study exemplifies the innovative application of cutting-edge models to forecast outcomes in ASD, underscoring the utility of complex data in outcome prediction for neurosurgical conditions. It demonstrates the promise of genetic models when identifying surgical risks and supports the integration of complex machine learning tools for informed surgical decision-making in ASD",,PubMed,,1,,,,"Multimodality: advanced models (CNN, LLM, GWAS) using complex data types (radiographs, clinical notes, genomics) for ASD outcome prediction","Pre-operative risk prediction in adult spinal deformity surgery using genomics, radiographs, and clinical notes.","use separately, not multimodality",FALSE,TRUE,FALSE
28,"Evaluation of GPT and BERT-based models on identifying proteinprotein interactions in biomedical text
==========
Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text","Detecting protein-protein interactions (PPIs) is crucial for understanding genetic mechanisms, disease pathogenesis, and drug design. However, with the fast-paced growth of biomedical literature, there is a growing need for automated and accurate extraction of PPIs to facilitate scientific knowledge discovery. Pre-trained language models, such as generative pre-trained transformers (GPT) and bidirectional encoder representations from transformers (BERT), have shown promising results in natural language processing (NLP) tasks. We evaluated the performance of PPI identification of multiple GPT and BERT models using three manually curated gold-standard corpora: Learning Language in Logic (LLL) with 164 PPIs in 77 sentences, Human Protein Reference Database with 163 PPIs in 145 sentences, and Interaction Extraction Performance Assessment with 335 PPIs in 486 sentences. BERT-based models achieved the best overall performance, with BioBERT achieving the highest recall (91.95%) and F1-score (86.84%) and PubMedBERT achieving the highest precision (85.25%). Interestingly, despite not being explicitly trained for biomedical texts, GPT-4 achieved commendable performance, comparable to the top-performing BERT models. It achieved a precision of 88.37%, a recall of 85.14%, and an F1-score of 86.49% on the LLL dataset. These results suggest that GPT models can effectively detect PPIs from text data, offering promising avenues for application in biomedical literature mining. Further research could explore how these models might be fine-tuned for even more specialized tasks within the biomedical domain",,"PubMed, arXiv",,1,,,," GPT and BERT (biobert, pbmedbert)-based models ",,!! importance of corrrect encoder/decoder use,FALSE,TRUE,FALSE
29,Fine-tuned large language models for answering questions about full-text biomedical research studies,"BackgroundFew studies have explored the degree to which fine-tuning a large-language model (LLM) can improve its ability to answer a specific set of questions about a research study.  MethodsWe created an instruction set comprising 250 marked-down studies of HIV drug resistance, 16 questions per study, answers to each question, and explanations for each answer. The questions were broadly relevant to studies of pathogenic human viruses including whether a study reported viral genetic sequences and the demographics and antiviral treatments of the persons from whom sequences were obtained. We fine-tuned GPT-4o-mini (GPT-4o), Llama3.1-8B-Instruct (Llama3.1-8B), and Llama3.1-70B-Instruct (Llama3.1-70B) using a quantized low rank adapter (QLoRA). We assessed the accuracy, precision, and recall of each base and fine-tuned model in answering the same questions on a test set comprising 120 different studies. Paired t-tests and Wilcoxon signed-rank tests were used to compare base models to one another, fine-tuned models to their respective base model, and the fine-tuned models to one another.  ResultsPrior to fine-tuning, GPT-4o displayed significantly greater performance than both Llama3.1-70B and Llama3.1-8B due to its greater precision compared with Llama3.1-70B and greater precision and recall compared with Llama3.1-8B; there was no difference in performance between Llama3.1-70B and Llama3.1-8B. After fine-tuning, both GPT-4o and Llama3.1-70B, but not Llama3.1-8B, displayed significantly improved performance compared with their base models. The improved performance of GPT-4o resulted from a mean 6% increased precision and 9% increased recall; the improved performance of Llama3.1-70B resulted from a 15% increased precision. After fine-tuning, Llama3.1-70B significantly outperformed Llama3.1-8B but did not perform as well as the fine-tuned GPT-4o model which displayed superior recall.  ConclusionFine-tuning GPT-4o and Llama3.1-70B, but not the smaller Llama3.1-8B, led to marked improvement in answering specific questions about research papers. The process we describe will be useful to researchers studying other medical domains.  AUTHOR SUMMARYAddressing key biomedical questions often requires systematically reviewing data from numerous studies--a process that demands time and expertise. Large language models (LLMs) have shown potential in screening papers and summarizing their content. However, few research groups have fine-tuned these models to enhance their performance in specialized biomedical domains. In this study, we fine-tuned three LLMs to answer questions about studies on the subject of HIV drug resistance including one proprietary LLM (GPT-4o-mini) and two open-source LLMs (Llama3.1-Instruct-70B and Llama 3.1-Instruct-8B). To fine-tune the models, we used an instruction set comprising 250 studies of HIV drug resistance and selected 16 questions covering whether studies included viral genetic sequences, patient demographics, and antiviral treatments. We then tested the models on 120 independent research studies. Our results showed that fine-tuning GPT-4o-mini and Llama3.1-Instruct-70B significantly improved their ability to answer domain-specific questions, while the smaller Llama3.1-Instruct-8B model was not improved. The process we described offers a roadmap for researchers in other fields and represents a step in our attempt towards developing an LLM capable of answering questions about research studies across a range of pathogenic human viruses",,medrxiv,,1,,,,Q and A -- potential in screening papers!!!,not purely genetics,,FALSE,TRUE,FALSE
159,Is Artificial Intelligence (AI) currently able to provide evidence-based scientific responses on methods that can improve the outcomes of embryo transfers? No,"The rapid development of Artificial Intelligence (AI) has raised questions about its potential uses in different sectors of everyday life. Specifically in medicine, the question arose whether chatbots could be used as tools for clinical decision-making or patients' and physicians' education. To answer this question in the context of fertility, we conducted a test to determine whether current AI platforms can provide evidence-based responses regarding methods that can improve the outcomes of embryo transfers. We asked nine popular chatbots to write a 300-word scientific essay, outlining scientific methods that improve embryo transfer outcomes. We then gathered the responses and extracted the methods suggested by each chatbot. Out of a total of 43 recommendations, which could be grouped into 19 similar categories, only 3/19 (15.8%) were evidence-based practices, those being ""ultrasound-guided embryo transfer"" in 7/9 (77.8%) chatbots, ""single embryo transfer"" in 4/9 (44.4%) and ""use of a soft catheter"" in 2/9 (22.2%), whereas some controversial responses like ""preimplantation genetic testing"" appeared frequently (6/9 chatbots; 66.7%), along with other debatable recommendations like ""endometrial receptivity assay"", ""assisted hatching"" and ""time-lapse incubator"". Our results suggest that AI is not yet in a position to give evidence-based recommendations in the field of fertility, particularly concerning embryo transfer, since the vast majority of responses consisted of scientifically unsupported recommendations. As such, both patients and physicians should be wary of guiding care based on chatbot recommendations in infertility. Chatbot results might improve with time especially if trained from validated medical databases; however, this will have to be scientifically checked",,PubMed,,1,,,,,provide evidence-based scientific responses,,FALSE,TRUE,FALSE
150,PGSbuilder: An end-to-end platform for human genome association analysis and polygenic risk score predictions,"Understanding the genetic basis of human complex diseases is increasingly important in the development of precision medicine. Over the last decade, genome-wide association studies (GWAS) have become a key technique for detecting associations between common diseases and single nucleotide polymorphisms (SNPs) present in a cohort of individuals. Alternatively, the polygenic risk score (PRS), which often applies results from GWAS summary statistics, is calculated for the estimation of genetic propensity to a trait at the individual level. Despite many GWAS and PRS tools being available to analyze a large volume of genotype data, most clinicians and medical researchers are often not familiar with the bioinformatics tools and lack access to a high-performance computing cluster resource. To fill this gap, we provide a publicly available web server, PGSbuilder, for the GWAS and PRS analysis of human genomes with variant annotations. The user-friendly and intuitive PGSbuilder web server is developed to facilitate the discovery of the genetic variants associated with complex traits and diseases for medical professionals with limited computational skills. For GWAS analysis, PGSbuilder provides the most renowned analysis tool PLINK 2.0 package. For PRS, PGSbuilder provides six different PRS methods including Clumping and Thresholding, Lassosum, LDPred2, GenEpi, PRS-CS, and PRSice2. Furthermore, PGSbuilder provides an intuitive user interface to examine the annotated functional effects of variants from known biomedical databases and relevant literature using advanced natural language processing approaches. In conclusion, PGSbuilder offers a reliable platform to aid researchers in advancing the public perception of genomic risk and precision medicine for human disease genetics. PGSbuilder is freely accessible at http://pgsb.tw23.org",,biorxiv,,1,,,,Generate summaries (???) after doing GWAS -> automatic tool for: Genome-wide association studies and polygenic risk score predictions.,Genomic risk analysis for human complex diseases (SNP and variant data).,"PGSbuilder is a user-friendly web platform enabling GWAS and PRS analyses for non-experts, facilitating precision medicine and genomic risk assessment.",FALSE,TRUE,FALSE
151,SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic Reasoning,"Syllogistic reasoning is crucial for Natural Language Inference (NLI). This capability is particularly significant in specialized domains such as biomedicine, where it can support automatic evidence interpretation and scientific discovery. This paper presents SylloBio-NLI, a novel framework that leverages external ontologies to systematically instantiate diverse syllogistic arguments for biomedical NLI. We employ SylloBio-NLI to evaluate Large Language Models (LLMs) on identifying valid conclusions and extracting supporting evidence across 28 syllogistic schemes instantiated with human genome pathways. Extensive experiments reveal that biomedical syllogistic reasoning is particularly challenging for zero-shot LLMs, which achieve an average accuracy between 70% on generalized modus ponens and 23% on disjunctive syllogism. At the same time, we found that few-shot prompting can boost the performance of different LLMs, including Gemma (+14%) and LLama-3 (+43%). However, a deeper analysis shows that both techniques exhibit high sensitivity to superficial lexical variations, highlighting a dependency between reliability, models' architecture, and pre-training regime. Overall, our results indicate that, while in-context examples have the potential to elicit syllogistic reasoning in LLMs, existing models are still far from achieving the robustness and consistency required for safe biomedical NLI applications",,arXiv,,1,,,,,SylloBio-NLI to evaluate Large Language Models (LLMs) on identifying valid conclusions and extracting supporting evidence across 28 syllogistic schemes instantiated with human genome pathways,"syllogistic reasoning - formal reasoning, here - in biomed",FALSE,TRUE,FALSE
167,"Tabula Sapiens reveals transcription factor expression, senescence effects, and sex-specific features in cell types from 28 human organs and tissues","The Tabula Sapiens is a reference human cell atlas containing single cell transcriptomic data from more than two dozen organs and tissues. Here we report Tabula Sapiens 2.0 which includes data from nine new donors, doubles the number of cells in Tabula Sapiens, and adds four new tissues. This new data includes four donors with multiple organs contributed, thus providing a unique data set in which genetic background, age, and epigenetic effects are controlled for. We analyzed the combined Tabula Sapiens data for expression of transcription factors, thereby providing putative cell type specificity for nearly every human transcription factor and as well as new insights into their regulatory roles. We analyzed the molecular phenotypes of senescent cells across the entire data set, providing new insight into both the universal attributes of senescence as well as those aspects of human senescence that are specific to particular organs and cell-types. Similarly, we analyzed sex-specific gene expression across all of the identified cell types and discovered which cell types and genes have the most distinct sex based gene expression profiles. Finally, to enable accessible analysis of the voluminous medical records of Tabula Sapiens donors, we created a web application powered by a large language model that allows users to ask general questions about the health history of the donors",,biorxiv,,1,,,,, a web application powered by a large language model that allows users to ask general questions about the health history of the donors,,FALSE,TRUE,FALSE
195,[LORENZO'S OIL AND ADRENOLEUKODYSTROPHY EXAMINING AN ARTIFICIAL INTELLIGENCE TOOL INTENDED FOR CONDUCTING LITERATURE SEARCHES AND ANALYSES],"Adrenoleukodystrophy is a genetic metabolic disorder characterized by a heterogeneous phenotype. Its severe form, known as cerebral adrenoleukodystrophy, involves unpredictable cerebral damage and progressive central nervous system deterioration. This rare condition became famous because of a Hollywood movie in which the Italian parents of a child with the condition supposedly discovered a medication for treating the condition. But real life does not emulate movies and hematopoietic stem cell transplantation remains the standard of care for patients diagnosed at an early disease stage. This article describes a patient with cerebral adrenoleukodystrophy diagnosed at an advanced disease stage. The literature search aimed to identify therapies to prevent further deterioration suggested autologous hematopoietic stem cell-based gene therapy and metabolic therapies. Consensus is a Chat GPT-based AI tool trained on millions of scientific publications, intended for conducting evidence-based literature searches and analyses. The case presented was used to conduct a parallel literature review using Consensus. While the generated output contained no hallucinations (a problem often seen with other large language models), the quality of the selected articles and their interpretation in the context of the specific case fell short of that achieved by experienced researchers or physicians",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
196,A deep network embedded with rough fuzzy discretization for OCT fundus image segmentation,"The noise and redundant information are the main reasons for the performance bottleneck of medical image segmentation algorithms based on the deep learning. To this end, we propose a deep network embedded with rough fuzzy discretization (RFDDN) for OCT fundus image segmentation. Firstly, we establish the information decision table of OCT fundus image segmentation, and regard each category of segmentation region as a fuzzy set. Then, we use the fuzzy c-means clustering to get the membership degrees of pixels to each segmentation region. According to membership functions and the equivalence relation generated by the brightness attribute, we design the individual fitness function based on the rough fuzzy set, and use a genetic algorithm to search for the best breakpoints to discretize the features of OCT fundus images. Finally, we take the feature discretization based on the rough fuzzy set as the pre-module of the deep neural network, and introduce the deep supervised attention mechanism to obtain the important multi-scale information. We compare RFDDN with U-Net, ReLayNet, CE-Net, MultiResUNet, and ISCLNet on the two groups of 3D retinal OCT data. RFDDN is superior to the other five methods on all evaluation indicators. The results obtained by ISCLNet are the second only inferior to those obtained by RFDDN. DSC, sensitivity, and specificity of RFDDN are evenly 3.3%, 2.6%, and 7.1% higher than those of ISCLNet, respectively. HD95 and ASD of RFDDN are evenly 6.6% and 19.7% lower than those of ISCLNet, respectively. The experimental results show that our method can effectively eliminate the noise and redundant information in Oct fundus images, and greatly improve the accuracy of OCT fundus image segmentation while taking into account the interpretability and computational efficiency",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
197,"A foundational large language model for edible plant genomes
==========
A Foundational Large Language Model for Edible Plant Genomes","Significant progress has been made in the field of plant genomics, as demonstrated by the increased use of high-throughput methodologies that enable the characterization of multiple genome-wide molecular phenotypes. These findings have provided valuable insights into plant traits and their underlying genetic mechanisms, particularly in model plant species. Nonetheless, effectively leveraging them to make accurate predictions represents a critical step in crop genomic improvement. We present AgroNT, a foundational large language model trained on genomes from 48 plant species with a predominant focus on crop species. We show that AgroNT can obtain state-of-the-art predictions for regulatory annotations, promoter/terminator strength, tissue-specific gene expression, and prioritize functional variants. We conduct a large-scale in silico saturation mutagenesis analysis on cassava to evaluate the regulatory impact of over 10 million mutations and provide their predicted effects as a resource for variant characterization. Finally, we propose the use of the diverse datasets compiled here as the Plants Genomic Benchmark (PGB), providing a comprehensive benchmark for deep learning-based methods in plant genomic research. The pre-trained AgroNT model is publicly available on HuggingFace at https://huggingface.co/InstaDeepAI/agro-nucleotide-transformer-1b  for future research purposes
==========
Significant progress has been made in the field of plant genomics, as demonstrated by the increased use of high-throughput methodologies that enable the characterization of multiple genome-wide molecular phenotypes. These findings have provided valuable insights into plant traits and their underlying genetic mechanisms, particularly in model plant species. Nonetheless, effectively leveraging them to make accurate predictions represents a critical step in crop genomic improvement. We present AO_SCPLOWGROC_SCPLOWNT, a foundational large language model trained on genomes from 48 plant species with a predominant focus on crop species. We show that AO_SCPLOWGROC_SCPLOWNT can obtain state-of-the-art predictions for regulatory annotations, promoter/terminator strength, tissue-specific gene expression, and prioritize functional variants. We conduct a large-scale in silico saturation mutagenesis analysis on cassava to evaluate the regulatory impact of over 10 million mutations and provide their predicted effects as a resource for variant characterization. Finally, we propose the use of the diverse datasets compiled here as the Plants Genomic Benchmark (PGB), providing a comprehensive bench-mark for deep learning-based methods in plant genomic research. The pre-trained AO_SCPLOWGROC_SCPLOWNT model is publicly available on HuggingFace at https://huggingface.co/InstaDeepAI/agro-nucleotide-transformer-1b for future research purposes",,"PubMed,biorxiv",,1,,,,"Large language model (AgroNT); ML Task: Genomic prediction (e.g., gene expression, variant prioritization).",Genomic prediction for plant species using DNA sequence data (NGS).,"AgroNT predicts regulatory annotations and functional variants for plant genomes, aiding crop improvement.",FALSE,TRUE,FALSE
198,"A graphSAGE discovers synergistic combinations of Gefitinib, paclitaxel, and Icotinib for Lung adenocarcinoma management by targeting human genes and proteins: the RAIN protocol","BackgroundAdenocarcinoma of the lung is the most common type of lung cancer, and it is characterized by distinct cellular and molecular features. It occurs when abnormal lung cells multiply out of control and form a tumor in the outer region of the lungs. Adenocarcinoma of the lung is a serious and life-threatening condition that requires effective and timely management to improve the survival and quality of life of the patients. One of the challenges in this cancer treatment is finding the optimal combination of drugs that can target the genes or proteins that are involved in the disease process.  MethodIn this article, we propose a novel method to recommend combinations of trending drugs to target its associated proteins/genes, using a Graph Neural Network (GNN) under the RAIN protocol. The RAIN protocol is a three-step framework that consists of: 1) Applying graph neural networks to recommend drug combinations by passing messages between trending drugs for managing disease and genes that act as potential targets for disease; 2) Retrieving relevant articles with clinical trials that include those proposed drugs in previous step using Natural Language Processing (NLP). The search queries include ""Adenocarcinoma of the lung"", ""Gefitinib"", ""Paclitaxel"", ""Icotinib"" that searched context based in databases using NLP; 3) Analyzing the network meta-analysis to measure the comparative efficacy of the drug combinations.  ResultWe applied our method to a dataset of nodes and edges that represent the network, where each node is a drug or a gene, and each edge is a p-value between them. We found that the graph neural network recommends combining Gefitinib, Paclitaxel, and Icotinib as the most effective drug combination to target this cancer associated proteins/genes. We reviewed the clinical trials and expert opinions on these medications and found that they support our claim. The network meta-analysis also confirmed the effectiveness of these drugs on associated genes.  ConclusionOur method is a novel and promising approach to recommend trending drugs combination to target cancer associated proteins/genes, using graph neural networks under the RAIN protocol. It can help clinicians and researchers to find the best treatment options for patients, and also provide insights into the underlying mechanisms of the disease.  HighlightsO_LIProposing the combination of medicinal compounds together for the treatment of lung adenocarcinoma C_LIO_LIachieved a p-value of 0.002858 between lung adenocarcinoma and targeted proteins/genes C_LIO_LI3-Leveraging GraphSAGE for Suggesting an Optimal Drug Combinations. C_LI    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=105 SRC=""FIGDIR/small/24304384v1_ufig1.gif"" ALT=""Figure 1""> View larger version (39K): org.highwire.dtl.DTLVardef@af030borg.highwire.dtl.DTLVardef@1f0e960org.highwire.dtl.DTLVardef@169d70aorg.highwire.dtl.DTLVardef@1a4eade_HPS_FORMAT_FIGEXP  M_FIG C_FIG",,medrxiv,,1,,,,,,,FALSE,TRUE,FALSE
199,A landmark federal interagency collaboration to promote data science in health care: Million Veteran Program-Computational Health Analytics for Medical Precision to Improve Outcomes Now,"In 2016, the Department of Veterans Affairs (VA) and the Department of Energy (DOE) established an Interagency Agreement (IAA), the Million Veteran Program-Computational Health Analytics for Medical Precision to Improve Outcomes Now (MVP-CHAMPION) research collaboration. Oversight fell under the VA Office of Research Development (VA ORD) and DOE headquarters. An Executive Committee and 2 senior scientific liaisons work with VA and DOE leadership to optimize efforts in the service of shared scientific goals. The program supported centralized data management and genomic analysis including creation of a scalable approach to cataloging phenotypes. Cross-cutting methods including natural language processing, image processing, and reusable code were developed. The 79.6 million dollar collaboration has supported centralized data management and genomic analysis including a scalable approach to cataloging phenotypes and launched over 10 collaborative scientific projects in health conditions highly prevalent in veterans. A ground-breaking analysis on the Summit and Andes supercomputers at the Oak Ridge National Laboratory (ORNL) of the genetic underpinnings of over 2000 health conditions across 44 million genetic variants which resulted in the identification of 38 270 independent genetic variants associating with one or more health traits. Of these, over 2000 identified associations were unique to non-European ancestry. Cross-cutting methods have advanced state-of-the-art artificial intelligence (AI) including large language natural language processing and a system biology study focused on opioid addiction awarded the 2018 Gordon Bell Prize for outstanding achievement in high-performance computing. The collaboration has completed work in prostate cancer, suicide prevention, and cardiovascular disease, and cross-cutting data science. Predictive models developed in these projects are being tested for application in clinical management. Eight new projects were launched in 2023, taking advantage of the momentum generated by the previous collaboration. A major challenge has been limitations in the scope of appropriated funds at DOE which cannot currently be used for health research. Extensive multidisciplinary interactions take time to establish and are essential to continued progress. New funding models for maintaining high-performance computing infrastructure at the ORNL and for supporting continued collaboration by joint VA-DOE research teams are needed",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
200,A multi-task deep learning model based on comprehensive feature integration and self-attention mechanism for predicting response to anti-PD1/PD-L1,"Immune checkpoint inhibitor (ICI) has been widely used in the treatment of advanced cancers, but predicting their efficacy remains challenging. Traditional biomarkers are numerous but exhibit heterogeneity within populations. For comprehensively utilizing the ICI-related biomarkers, we aim to conduct multidimensional feature selection and deep learning model construction. We used statistical and machine learning methods to map features of different levels to next-generation sequencing gene expression. We integrated genes from different sources into the feature input of a deep learning model, by means of self-attention mechanism. We performed feature selection at the single-cell sequencing level, PD-L1 (CD274) analysis level, tumor mutational burden (TMB)/mismatch repair (MMR) level, and somatic copy number alteration (SCNA) level, obtaining 96 feature genes. Based on the pan-cancer dataset, we trained a multi-task deep learning model. We tested the model in the bladder urothelial carcinoma testing set 1 (AUC = 0.62, n = 298), bladder urothelial carcinoma testing set 2 (AUC = 0.66, n = 89), non-small cell lung cancer testing set (AUC = 0.85, n = 27), and skin cutaneous melanoma testing set (AUC = 0.71, n = 27). Our study demonstrates the potential of the deep learning model for integrating multidimensional features in predicting the outcome of ICI. Our study also provides a potential methodological case for medical scenarios requiring the integration of multiple levels of features",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
201,A new AI-assisted data standard accelerates interoperability in biomedical research,"In this paper, we leveraged Large Language Models(LLMs) to accelerate data wrangling and automate labor-intensive aspects of data discovery and harmonization. This work promotes interoperability standards and enhances data discovery, facilitating AI-readiness in biomedical science with the generation of Common Data Elements (CDEs) as key to harmonizing multiple datasets. Thirty-one studies, various ontologies, and medical coding systems served as source material to create CDEs from which available metadata and context was sent as an API request to 4th-generation OpenAI GPT models to populate each metadata field. A human-in-the-loop (HITL) approach was used to assess quality and accuracy of the generated CDEs. To regulate CDE generation, we employed ElasticSearch and HITL to avoid duplicate CDEs and instead, added them as potential aliases for existing CDEs. The generated CDEs are foundational to assess the interoperability potential of datasets by determining how many data set column headers can be correctly mapped to CDEs as well as quantifying compliance with permissible values and data types. Subject matter experts reviewed generated CDEs and determined that 94.0% of generated metadata fields did not require manual revisions. Data tables from the Alzheimers Disease Neuroimaging Initiative (ADNI) and the Global Parkinsons Genetic Program (GP2) were used as test cases for interoperability assessments. Column headers from all test cases were successfully mapped to generated CDEs at a rate of 32.4% via elastic search.The interoperability score, a metric for dataset compatibility to CDEs and other connected datasets, based on relevant criteria such as data field completeness and compliance with common harmonization standards averaged 53.8 out of 100 for test cases. With this project, we aim to automate the most tedious aspects of data harmonization, enhancing efficiency and scalability in biomedical research while decreasing activation energy for federated research
==========
In this paper, we leveraged Large Language Models(LLMs) to accelerate data wrangling and automate labor-intensive aspects of data discovery and harmonization. This work promotes interoperability standards and enhances data discovery, facilitating AI-readiness in biomedical science with the generation of Common Data Elements (CDEs) as key to harmonizing multiple datasets. Thirty-one studies, various ontologies, and medical coding systems served as source material to create CDEs from which available metadata and context was sent as an API request to 4th-generation OpenAI GPT models to populate each metadata field. A human-in-the-loop (HITL) approach was used to assess quality and accuracy of the generated CDEs. To regulate CDE generation, we employed ElasticSearch and HITL to avoid duplicate CDEs and instead, added them as potential aliases for existing CDEs. The generated CDEs are foundational to assess the interoperability potential of datasets by determining how many data set column headers can be correctly mapped to CDEs as well as quantifying compliance with permissible values and data types. Subject matter experts reviewed generated CDEs and determined that 94.0% of generated metadata fields did not require manual revisions. Data tables from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and the Global Parkinson's Genetic Program (GP2) were used as test cases for interoperability assessments. Column headers from all test cases were successfully mapped to generated CDEs at a rate of 32.4% via elastic search.The interoperability score, a metric for dataset compatibility to CDEs and other connected datasets, based on relevant criteria such as data field completeness and compliance with common harmonization standards averaged 53.8 out of 100 for test cases. With this project, we aim to automate the most tedious aspects of data harmonization, enhancing efficiency and scalability in biomedical research while decreasing activation energy for federated research",,"PubMed,medrxiv",,1,,,,,,,FALSE,TRUE,FALSE
202,"A robust transformer-based pipeline of 3D cell alignment, denoise and instance segmentation on electron microscopy sequence images","Germline cells are critical for transmitting genetic information to subsequent generations in biological organisms. While their differentiation from somatic cells during embryonic development is well-documented in most animals, the regulatory mechanisms initiating plant germline cells are not well understood. To thoroughly investigate the complex morphological transformations of their ultrastructure over developmental time, nanoscale 3D reconstruction of entire plant tissues is necessary, achievable exclusively through electron microscopy imaging. This paper presents a full-process framework designed for reconstructing large-volume plant tissue from serial electron microscopy images. The framework ensures end-to-end direct output of reconstruction results, including topological networks and morphological analysis. The proposed 3D cell alignment, denoise, and instance segmentation pipeline (3DCADS) leverages deep learning to provide a cell instance segmentation workflow for electron microscopy image series, ensuring accurate and robust 3D cell reconstructions with high computational efficiency. The pipeline involves five stages: the registration of electron microscopy serial images; image enhancement and denoising; semantic segmentation using a Transformer-based neural network; instance segmentation through a supervoxel-based clustering algorithm; and an automated analysis and statistical assessment of the reconstruction results, with the mapping of topological connections. The 3DCADS model's precision was validated on a plant tissue ground-truth dataset, outperforming traditional baseline models and deep learning baselines in overall accuracy. The framework was applied to the reconstruction of early meiosis stages in the anthers of Arabidopsis thaliana, resulting in a topological connectivity network and analysis of morphological parameters and characteristics of cell distribution. The experiment underscores the 3DCADS model's potential for biological tissue identification and its significance in quantitative analysis of plant cell development, crucial for examining samples across different genetic phenotypes and mutations in plant development. Additionally, the paper discusses the regulatory mechanisms of Arabidopsis thaliana's germline cells and the development of stamen cells before meiosis, offering new insights into the transition from somatic to germline cell fate in plants",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
203,A self-supervised framework for learning whole slide representations,"Whole slide imaging is fundamental to biomedical microscopy and computational pathology. Previously, learning representations for gigapixel-sized whole slide images (WSIs) has relied on multiple instance learning with weak labels, which do not annotate the diverse morphologic features and spatial heterogeneity of WSIs. A high-quality self-supervised learning method for WSIs would provide transferable visual representations for downstream computational pathology tasks, without the need for dense annotations. We present Slide Pre-trained Transformers (SPT) for gigapixel-scale self-supervision of WSIs. Treating WSI patches as tokens, SPT combines data transformation strategies from language and vision modeling into a general and unified framework to generate views of WSIs for self-supervised pretraining. SPT leverages the inherent regional heterogeneity, histologic feature variability, and information redundancy within WSIs to learn high-quality whole slide representations. We benchmark SPT visual representations on five diagnostic tasks across three biomedical microscopy datasets. SPT significantly outperforms baselines for histopathologic diagnosis, cancer subtyping, and genetic mutation prediction. Finally, we demonstrate that SPT consistently improves whole slide representations when using off-the-shelf, in-domain, and foundational patch encoders for whole slide multiple instance learning",,arXiv,,1,,,,,,,FALSE,TRUE,FALSE
204,A Suite of Foundation Models Captures the Contextual Interplay Between Codons,"In the canonical genetic code, many amino acids are assigned more than one codon. Work by us and others has shown that the choice of these synonymous codon is not random, and carries regulatory and functional consequences. Existing protein foundation models ignore this context-dependent role of coding sequence in shaping the protein landscape of the cell. To address this gap, we introduce cdsFM, a suite of codon-resolution large language models, including both EnCodon and DeCodon models, with up to 1B parameters. Pre-trained on 60 million protein-coding sequences from more than 5,000 species, our models effectively learn the relationship between codons and amino acids, recapitualing the overall structure of the genetic code. In addition to outperforming state-of-the-art genomic foundation models in a variety of zero-shot and few-shot learning tasks, the larger pre-trained models were superior in predicting the choice of synonymous codons. To systematically assess the impact of synonymous codon choices on protein expression and our models ability to capture these effects, we generated a large dataset measuring overall and surface expression levels of three proteins as a function of changes in their synonymous codons. We showed that our EnCodon models could be readily fine-tuned to predict the contextual consequences of synonymous codon choices. Armed with this knowledge, we applied EnCodon to existing clinical datasets of synonymous variants, and we identified a large number of synonymous codons that are likely pathogenic, several of which we experimentally confirmed in a cellbased model. Together, our findings establish the cdsFM suite as a powerful tool for decoding the complex functional grammar underlying the choice of synonymous codons",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
205,A Theoretical Exploration of Artificial Intelligence's Impact on Feto-Maternal Health from Conception to Delivery,"The implementation of Artificial Intelligence (AI) in healthcare is enhancing diagnostic accuracy in clinical setups. The use of AI in healthcare is steadily increasing with advancing technology, extending beyond disease diagnosis to encompass roles in feto-maternal health. AI harnesses Machine Learning (ML), Natural Language Processing (NLP), Artificial Neural Networks (ANN), and computer vision to analyze data and draw conclusions. Considering maternal health, ML analyzes vast datasets to predict maternal and fetal health outcomes, while NLP interprets medical texts and patient records to assist in diagnosis and treatment decisions. ANN models identify patterns in complex feto-maternal medical data, aiding in risk assessment and intervention planning whereas, computer vision enables the analysis of medical images for early detection of feto-maternal complications. AI facilitates early pregnancy detection, genetic screening, and continuous monitoring of maternal health parameters, providing real-time alerts for deviations, while also playing a crucial role in the early detection of fetal abnormalities through enhanced ultrasound imaging, contributing to informed decision-making. This review investigates into the application of AI, particularly through predictive models, in addressing the monitoring of feto-maternal health. Additionally, it examines potential future directions and challenges associated with these applications",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
206,A transformer-based unified multimodal framework for Alzheimer's disease assessment,"In Alzheimer's disease (AD) assessment, traditional deep learning approaches have often employed separate methodologies to handle the diverse modalities of input data. Recognizing the critical need for a cohesive and interconnected analytical framework, we propose the AD-Transformer, a novel transformer-based unified deep learning model. This innovative framework seamlessly integrates structural magnetic resonance imaging (sMRI), clinical, and genetic data from the extensive Alzheimer's Disease Neuroimaging Initiative (ADNI) database, encompassing 1651 subjects. By employing a Patch-CNN block, the AD-Transformer efficiently transforms image data into image tokens, while a linear projection layer adeptly converts non-image data into corresponding tokens. As the core, a transformer block learns comprehensive representations of the input data, capturing the intricate interplay between modalities. The AD-Transformer sets a new benchmark in AD diagnosis and Mild Cognitive Impairment (MCI) conversion prediction, achieving remarkable average area under curve (AUC) values of 0.993 and 0.845, respectively, surpassing those of traditional image-only models and non-unified multimodal models. Our experimental results confirmed the potential of the AD-Transformer as a potent tool in AD diagnosis and MCI conversion prediction. By providing a unified framework that jointly learns holistic representations of both image and non-image data, the AD-Transformer paves the way for more effective and precise clinical assessments, offering a clinically adaptable strategy for leveraging diverse data modalities in the battle against AD",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
207,AI-Guided Cancer Therapy for Patients with Coexisting Migraines,"Background: Cancer remains a leading cause of death worldwide. Progress in its effective treatment has been hampered by challenges in personalized therapy, particularly in patients with comorbid conditions. The integration of artificial intelligence (AI) into patient profiling offers a promising approach to enhancing individualized anticancer therapy. Objective: This narrative review explores the role of AI in refining anticancer therapy through personalized profiling, with a specific focus on cancer patients with comorbid migraine. Methods: A comprehensive literature search was conducted across multiple databases, including PubMed, Scopus, and Google Scholar. Studies were selected based on their relevance to AI applications in oncology and migraine management, with a focus on personalized medicine and predictive modeling. Key themes were synthesized to provide an overview of recent developments, challenges, and emerging directions. Results: AI technologies, such as machine learning (ML), deep learning (DL), and natural language processing (NLP), have become instrumental in the discovery of genetic and molecular biomarkers of cancer and migraine. These technologies also enable predictive analytics for assessing the impact of migraine on cancer therapy in comorbid cases, predicting outcomes and provide clinical decision support systems (CDSS) for real-time treatment adjustments. Conclusions: AI holds significant potential to improve the precision and effectiveness of the management and therapy of cancer patients with comorbid migraine. Nevertheless, challenges remain over data integration, clinical validation, and ethical consideration, which must be addressed to appreciate the full potential for the approach outlined herein",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
208,AI-Powered Test Question Generation in Medical Education: The DailyMed Approach,"IntroductionLarge language models (LLMs) presents opportunities to improve the efficiency and quality of tools in medical education, such as the generation of multiple-choice questions (MCQs). However, ensuring that these questions are clinically relevant, accurate, and easily accesible and reusable remains challenging. Here, we developed DailyMed, an online automated pipeline using LLMs to generate high-quality medical MCQs.  MethodsOur DailyMed pipeline involves several key steps: 1) topic generation, 2) question creation, 3) validation using Semantic Scholar, 4) difficulty grading, 5) iterative improvement of simpler questions, and 6) final human review. The Chain-of-Thought (CoT) prompting technique was applied to enhance LLM reasoning. Three state-of the art LLMs--OpenBioLLM-70B, GPT-4o, and Claude 3.5 Sonnet--were evaluated within the area of clinical genetics, and the generated questions were rated by clinical experts for validity, clarity, originality, relevance, and difficulty.  ResultsGPT-4o produced the highest-rated questions, excelling in validity, originality, clarity, and relevance. Although OpenBioLLM was more cost-efficient, it consistently scored lower in all categories. GPT-4o also achieved the greatest topic diversity (89.8%), followed by Claude Sonnet (86.9%) and OpenBioLLM (80.0%). In terms of cost and performance, GPT-4o was the most efficient model, with an average cost of $0.51 per quiz and a runtime of 16 seconds per question.  ConclusionsOur pipeline provides a scalable, effective and online-accessible solution for generating diverse, clinically relevant MCQs. GPT-4o demonstrated the highest overall performance, making it the preferred model for this task, while OpenBioLLM offers a cost-effective alternative",,medrxiv,,1,,,,,,,FALSE,TRUE,FALSE
209,An AI-Driven Framework for Discovery of BACE1 Inhibitors for Alzheimer's Disease,"Alzheimers Disease (AD) is a progressive neurodegenerative disorder that affects over 51 million individuals globally. The {beta}-secretase (BACE1) enzyme is responsible for the production of amyloid beta (A{beta}) plaques in the brain. The accumulation of A{beta} plaques leads to neuronal death and the impairment of cognitive abilities, both of which are fundamental symptoms of AD. Thus, BACE1 has emerged as a promising therapeutic target for AD. Previous BACE1 inhibitors have faced various issues related to molecular size and blood-brain barrier permeability, preventing any of them from maturing into FDA-approved AD drugs. In this work, a generative AI framework is developed as the first AI application to the de novo generation of BACE1 inhibitors. Through a simple, robust, and accurate molecular representation, a Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), and a Genetic Algorithm (GA), the framework generates and optimizes over 1,000,000 candidate inhibitors that improve upon the bioactive and pharmacological properties of current BACE1 inhibitors. Then, the molecular docking simulation models the candidate inhibitors and identifies 14 candidate drugs that exhibit stronger binding interactions to the BACE1 active site than previous candidate BACE1 drugs from clinical trials. Overall, the framework successfully discovers BACE1 inhibitors and candidate AD drugs, accelerating the developmental process for a novel AD treatment",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
210,An Improved Nested U-Net Network for Fluorescence In Situ Hybridization Cell Image Segmentation,"Fluorescence in situ hybridization (FISH) is a powerful cytogenetic method used to precisely detect and localize nucleic acid sequences. This technique is proving to be an invaluable tool in medical diagnostics and has made significant contributions to biology and the life sciences. However, the number of cells is large and the nucleic acid sequences are disorganized in the FISH images taken using the microscope. Processing and analyzing images is a time-consuming and laborious task for researchers, as it can easily tire the human eyes and lead to errors in judgment. In recent years, deep learning has made significant progress in the field of medical imaging, especially the successful application of introducing the attention mechanism. The attention mechanism, as a key component of deep learning, improves the understanding and interpretation of medical images by giving different weights to different regions of the image, enabling the model to focus more on important features. To address the challenges in FISH image analysis, we combined medical imaging with deep learning to develop the SEAM-Unet++ automated cell contour segmentation algorithm with integrated attention mechanism. The significant advantage of this algorithm is that it improves the accuracy of cell contours in FISH images. Experiments have demonstrated that by introducing the attention mechanism, our method is able to segment cells that are adherent to each other more efficiently",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
211,Analysis of large-language model versus human performance for genetics questions,"Large-language models like ChatGPT have recently received a great deal of attention. To assess ChatGPT in the field of genetics, we compared its performance to human respondents in answering genetics questions (involving 13,636 responses) that had been posted on social media platforms starting in 2021. Overall, ChatGPT did not perform significantly differently than human respondents, but did significantly better on memorization-type questions versus critical thinking questions, frequently provided different answers when asked questions multiple times, and provided plausible explanations for both correct and incorrect answers
==========
Large-language models like ChatGPT have recently received a great deal of attention. One area of interest pertains to how these models could be used in biomedical contexts, including related to human genetics. To assess one facet of this, we compared the performance of ChatGPT versus human respondents (13,642 human responses) in answering 85 multiple-choice questions about aspects of human genetics. Overall, ChatGPT did not perform significantly differently (p = 0.8327) than human respondents; ChatGPT was 68.2% accurate, compared to 66.6% accuracy for human respondents. Both ChatGPT and humans performed better on memorization-type questions versus critical thinking questions (p < 0.0001). When asked the same question multiple times, ChatGPT frequently provided different answers (16% of initial responses), including for both initially correct and incorrect answers, and gave plausible explanations for both correct and incorrect answers. ChatGPT's performance was impressive, but currently demonstrates significant shortcomings for clinical or other high-stakes use. Addressing these limitations will be important to guide adoption in real-life situations",,"PubMed,medrxiv",,1,,,,,,,FALSE,TRUE,FALSE
212,Anesthetic Management of a Patient With Juvenile Hyaline Fibromatosis: A Case Report Written With the Assistance of the Large Language Model ChatGPT,"This case report was written with the assistance of the large language model known as ChatGPT, a form of generative artificial intelligence that can write grammatically correct and semantically meaningful prose on a multitude of topics. Here, it has assisted us in presenting a case of anesthetic management for a case of Juvenile Hyaline Fibromatosis (JHF), an extremely rare genetic disorder that is part of a spectrum of diseases presently characterized as Hyaline Fibromatosis Syndrome (HFS), which also includes a more severe variant presenting in infancy. HFS is caused by autosomal recessive mutations in the ANTXR2 (anthrax toxin receptor cell adhesion molecule 2) gene, which binds collagen IV and laminin, suggesting that it may be involved in extracellular matrix adhesion. Defects in this molecule lead to abnormal deposition of hyaline material in perivascular areas, presenting as cutaneous lesions, joint contractures, and in some cases internal organ dysfunction. Anesthetic management of patients with JHF may present difficulties with patient positioning and airway management. Most reports of anesthetic management concern children with severe disease and adult reports are uncommon. We present a case of JHF in a 39-year-old woman managed for resection of a lower extremity cutaneous lesion. The anesthetic management of this relatively minor case was uneventful, but the process of drafting this report with the assistance of the new software tool ChatGPT was informative of both its strengths and limitations",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
213,Application of machine learning based genome sequence analysis in pathogen identification,"Infectious diseases caused by pathogenic microorganisms pose a serious threat to human health. Despite advances in molecular biology, genetics, computation, and medicinal chemistry, infectious diseases remain a significant public health concern. Addressing the challenges posed by pathogen outbreaks, pandemics, and antimicrobial resistance requires concerted interdisciplinary efforts. With the development of computer technology and the continuous exploration of artificial intelligence(AI)applications in the biomedical field, the automatic morphological recognition and image processing of microbial images under microscopes have advanced rapidly. The research team of Institute of Microbiology, Chinese Academy of Sciences has developed a single cell microbial identification technology combining Raman spectroscopy and artificial intelligence. Through laser Raman acquisition system and convolutional neural network analysis, the average accuracy rate of 95.64% has been achieved, and the identification can be completed in only 5 min. These technologies have shown substantial advantages in the visible morphological detection of pathogenic microorganisms, expanding anti-infective drug discovery, enhancing our understanding of infection biology, and accelerating the development of diagnostics. In this review, we discuss the application of AI-based machine learning in image analysis, genome sequencing data analysis, and natural language processing (NLP) for pathogen identification, highlighting the significant role of artificial intelligence in pathogen diagnosis. AI can improve the accuracy and efficiency of diagnosis, promote early detection and personalized treatment, and enhance public health safety",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
214,Applications of artificial intelligence in clinical laboratory genomics,"The transition from analog to digital technologies in clinical laboratory genomics is ushering in an era of ""big data"" in ways that will exceed human capacity to rapidly and reproducibly analyze those data using conventional approaches. Accurately evaluating complex molecular data to facilitate timely diagnosis and management of genomic disorders will require supportive artificial intelligence methods. These are already being introduced into clinical laboratory genomics to identify variants in DNA sequencing data, predict the effects of DNA variants on protein structure and function to inform clinical interpretation of pathogenicity, link phenotype ontologies to genetic variants identified through exome or genome sequencing to help clinicians reach diagnostic answers faster, correlate genomic data with tumor staging and treatment approaches, utilize natural language processing to identify critical published medical literature during analysis of genomic data, and use interactive chatbots to identify individuals who qualify for genetic testing or to provide pre-test and post-test education. With careful and ethical development and validation of artificial intelligence for clinical laboratory genomics, these advances are expected to significantly enhance the abilities of geneticists to translate complex data into clearly synthesized information for clinicians to use in managing the care of their patients at scale",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
215,Applications of Artificial Intelligence to Diagnosis of Neurodegenerative Diseases,"Artificial Intelligence (AI) is an umbrella term that represents a new technology for simulating and expanding human intelligence by using machines and computer systems. It consists of methods such as machine learning (ML), deep learning (DL), and natural language processing (NLP). In the era of big data, AI has emerged as an essential tool for improving the detection of neurodegenerative diseases, such as Alzheimer's diseases (AD), Parkinson's diseases, amyotrophic lateral sclerosis, etc. AI with its ability to extract critical information from the mass of data has enabled scientists to deal with various types of large-volume data, including genetic data, imaging data, and clinical data, rapidly generated in the course of neurodegenerative disease research. This review provides a comprehensive overview of the literature on current AI applications in the diagnosis of neurodegenerative diseases. Firstly, bioinformatics and AI approaches to identify potential biomarkers for neurodegenerative diseases such as AD are reviewed. Secondly, the use of ML and DL methods to analyze Magnetic Resonance Imaging (MRI) data for a better understanding of disease progression and predicting patient outcomes is discussed. Finally, the use of AI methods including NLP for Electronic Health Record (EHR) data analysis to extract meaningful information and identify patterns that may contribute to early diagnosis and treatment planning are reviewed. The potential benefits of AI-based approaches in improving patient outcomes and the challenges associated with their implementations are also discussed. Overall, this paper highlights the promise of AI in transforming the diagnosis and management of neurodegenerative diseases",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
216,Artificial Intelligence and Multiple Sclerosis,"In this paper, we analyse the different advances in artificial intelligence (AI) approaches in multiple sclerosis (MS). AI applications in MS range across investigation of disease pathogenesis, diagnosis, treatment, and prognosis. A subset of AI, Machine learning (ML) models analyse various data sources, including magnetic resonance imaging (MRI), genetic, and clinical data, to distinguish MS from other conditions, predict disease progression, and personalize treatment strategies. Additionally, AI models have been extensively applied to lesion segmentation, identification of biomarkers, and prediction of outcomes, disease monitoring, and management. Despite the big promises of AI solutions, model interpretability and transparency remain critical for gaining clinician and patient trust in these methods. The future of AI in MS holds potential for open data initiatives that could feed ML models and increasing generalizability, the implementation of federated learning solutions for training the models addressing data sharing issues, and generative AI approaches to address challenges in model interpretability, and transparency. In conclusion, AI presents an opportunity to advance our understanding and management of MS. AI promises to aid clinicians in MS diagnosis and prognosis improving patient outcomes and quality of life, however ensuring the interpretability and transparency of AI-generated results is going to be key for facilitating the integration of AI into clinical practice",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
217,Artificial Intelligence-Generated Scientific Literature: A Critical Appraisal,"Review articles play a critical role in informing medical decisions and identifying avenues for future research. With the introduction of artificial intelligence (AI), there has been a growing interest in the potential of this technology to transform the synthesis of medical literature. Open AI's Generative Pre-trained Transformer (GPT-4) (Open AI Inc, San Francisco, CA) tool provides access to advanced AI that is able to quickly produce medical literature following only simple prompts. The accuracy of the generated articles requires review, especially in subspecialty fields like Allergy/Immunology. To critically appraise AI-synthesized allergy-focused minireviews. We tasked the GPT-4 Chatbot with generating 2 1,000-word reviews on the topics of hereditary angioedema and eosinophilic esophagitis. Authors critically appraised these articles using the Joanna Briggs Institute (JBI) tool for text and opinion and additionally evaluated domains of interest such as language, reference quality, and accuracy of the content. The language of the AI-generated minireviews was carefully articulated and logically focused on the topic of interest; however, reviewers of the AI-generated articles indicated that the AI-generated content lacked depth, did not appear to be the result of an analytical process, missed critical information, and contained inaccurate information. Despite being provided instruction to utilize scientific references, the AI chatbot relied mainly on freely available resources, and the AI chatbot fabricated references. The AI holds the potential to change the landscape of synthesizing medical literature; however, apparent inaccurate and fabricated information calls for rigorous evaluation and validation of AI tools in generating medical literature, especially on subjects associated with limited resources",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
218,Assessment of ChatGPT's performance on neurology written board examination questions,"ChatGPT has shown promise in healthcare. To assess the utility of this novel tool in healthcare education, we evaluated ChatGPT's performance in answering neurology board exam questions. Neurology board-style examination questions were accessed from BoardVitals, a commercial neurology question bank. ChatGPT was provided a full question prompt and multiple answer choices. First attempts and additional attempts up to three tries were given to ChatGPT to select the correct answer. A total of 560 questions (14 blocks of 40 questions) were used, although any image-based questions were disregarded due to ChatGPT's inability to process visual input. The artificial intelligence (AI) answers were then compared with human user data provided by the question bank to gauge its performance. Out of 509 eligible questions over 14 question blocks, ChatGPT correctly answered 335 questions (65.8%) on the first attempt/iteration and 383 (75.3%) over three attempts/iterations, scoring at approximately the 26th and 50th percentiles, respectively. The highest performing subjects were pain (100%), epilepsy & seizures (85%) and genetic (82%) while the lowest performing subjects were imaging/diagnostic studies (27%), critical care (41%) and cranial nerves (48%). This study found that ChatGPT performed similarly to its human counterparts. The accuracy of the AI increased with multiple attempts and performance fell within the expected range of neurology resident learners. This study demonstrates ChatGPT's potential in processing specialised medical information. Future studies would better define the scope to which AI would be able to integrate into medical decision making",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
219,Attitudes Toward Use of an APOL1 Genetic Testing Chatbot in Living Kidney Donor Evaluation: A Focus Group Study,"Living kidney donor (LKD) candidates of African ancestry are increasingly asked to undergo Apolipoprotein L1 (APOL1) genetic testing during the donor evaluation process to better understand their risk of kidney disease. LKD candidates' attitudes about using a clinical chatbot on APOL1 remain unknown. This study builds on prior work to culturally adapt the Gia (Genetic Information Assistant) chatbot on APOL1 by assessing donor, recipient, and community member attitudes about the Gia chatbot for enhancing the integration of APOL1 testing into the LKD clinical evaluation workflow. This study involved focus groups and a post-focus group survey in two US cities about the APOL1 Gia chatbot. Qualitative data were analyzed via thematic analysis, and descriptive statistics were used for demographic data. We conducted 10 focus groups including 54 participants (25 LKDs, 23 community members, and 6 living donor kidney transplant recipients of African ancestry). Five themes emerged: (1) participants supported LKD candidates using the Gia chatbot before the nephrologist clinic visit, (2) participants were interested in undergoing APOL1 testing after using Gia, (3) APOL1 testing costs may influence LKD candidates' willingness to get tested, (4) patients of African ancestry may hold varying preferences for using chatbots in the healthcare setting, and (5) individual-level barriers may limit the use of Gia in the healthcare setting. Individuals of African ancestry were highly receptive to integrating the APOL1 chatbot into LKD candidate clinical evaluation, which bodes well for integrating chatbots into the APOL1 clinical genetic testing process",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
220,Automated Derivation of Diagnostic Criteria for Lung Cancer using Natural Language Processing on Electronic Health Records: A pilot study,"BackgroundThe digitisation of healthcare records has generated vast amounts of unstructured data, presenting opportunities for improvements in disease diagnosis when clinical coding falls short, such as in the recording of patient symptoms. This study presents an approach using natural language processing to extract clinical concepts from free-text which are used to automatically form diagnostic criteria for lung cancer from unstructured secondary-care data.  MethodsPatients aged 40 and above who underwent a chest x-ray (CXR) between 2016-2022 were included. ICD-10 and unstructured data were pulled from their electronic health records (EHRs) over the preceding 12 months to the CXR. The unstructured data were processed using named entity recognition to extract symptoms, which were mapped to SNOMED-CT codes. Subsumption of features up the SNOMED-CT hierarchy was used to mitigate against sparse features and a frequency-based criteria, combined with univariate logarithmic probabilities, was applied to select candidate features to take forward to the model development phase. A genetic algorithm was employed to identify the most discriminating features to form the diagnostic criteria.  Results75002 patients were included, with 1012 lung cancer diagnoses made within 12 months of the CXR. The best-performing model achieved an AUROC of 0.72. Results showed that an existing  disorder of the lung, such as pneumonia, and a  cough increased the probability of a lung cancer diagnosis.  Anomalies of great vessel,  disorder of the retroperitoneal compartment and  context-dependent findings, such as pain, statistically reduced the risk of lung cancer, making other diagnoses more likely. The performance of the developed model was compared to the existing cancer risk scores, demonstrating superior performance.  ConclusionsThe proposed methods demonstrated success in leveraging unstructured secondary-care data to derive diagnostic criteria for lung cancer, outperforming existing risk tools. These advancements show potential for enhancing patient care and results. However, it is essential to tackle specific limitations by integrating primary care data to ensure a more thorough and unbiased development of diagnostic criteria. Moreover, the study highlights the importance of contextualising SNOMED-CT concepts into meaningful terminology that resonates with clinicians, facilitating a clearer and more tangible understanding of the criteria applied",,"medrxiv, pubmed",,1,,,,,,,FALSE,TRUE,FALSE
222,Beyond neuropsychological tests: AI speech analysis in PKU,"Phenylketonuria (PKU) is a rare inherited metabolic disorder characterized by toxic phenylalanine (Phe) concentrations in blood and brain. State-of-the-art analyses of speech detected a dimension of verbal discourse providing insights that extend beyond those captured by existing paradigms to measure performance associated with biochemical markers in PKU. The Cookie Theft Picture Task provided a standardized stimulus for eliciting spontaneous speech from 42 adults with PKU and 41 adults without PKU. Subtests measuring language and memory from the Wechsler Adult Intelligence Scale-Fourth Edition showed no differences between the groups and no correlations with biomarkers in PKU. In contrast, AI analyses of responses to the Cookie Theft Task revealed significant differences between the PKU and non-PKU groups on 23 linguistic features. Using multidimensional scaling (MDS), these features were aggregated into a single quantifiable Dimension 1 that significantly correlated with biomarkers. When extreme examples of Dimension 1 were presented to chatGPT, the differences noted reflected attention to detail, clarity in word choice, expression cohesion, contextual awareness and emotion recognition. We subsequently defined Dimension 1 as Proficiency in Verbal Discourse. This novel measure elucidated discourse styles possibly associated with suboptimal achievement and learning disabilities, often reported in PKU. In summary, AI captured a characteristic associated with metabolic status undetectable through traditional neuropsychological measures. Future studies will expand upon this novel paradigm, leveraging speech AI to quantify meaningful aspects of everyday functioning and possibly provide information for management decisions. Once validated, this measure holds promise for extension to other rare diseases and incorporation into clinical trials",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
223,ChatGPT-A promising generative AI tool and its implications for cancer care,"Since its launch, ChatGPT has taken the internet by storm and has the potential to be used broadly in the health care system, particularly in a setting such as medical oncology. ChatGPT is well suited to review and extract key content from records of patients with cancer, interpret next-generation sequencing reports, and offer a list of potential clinical trial options",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
224,Classification of clinically actionable genetic mutations in cancer patients,"Personalized medicine in cancer treatment aims to treat each individual's cancer tumor uniquely based on the genetic sequence of the cancer patient and is a much more effective approach compared to traditional methods which involve treating each type of cancer in the same, generic manner. However, personalized treatment requires the classification of cancer-related genes once profiled, which is a highly labor-intensive and time-consuming task for pathologists making the adoption of personalized medicine a slow progress worldwide. In this paper, we propose an intelligent multi-class classifier system that uses a combination of Natural Language Processing (NLP) techniques and Machine Learning algorithms to automatically classify clinically actionable genetic mutations using evidence from text-based medical literature. The training data set for the classifier was obtained from the Memorial Sloan Kettering Cancer Center and the Random Forest algorithm was applied with TF-IDF for feature extraction and truncated SVD for dimensionality reduction. The results show that the proposed model outperforms the previous research in terms of accuracy and precision scores, giving an accuracy score of approximately 82%. The system has the potential to revolutionize cancer treatment and lead to significant improvements in cancer therapy",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
225,"Clinical signatures of genetic epilepsies precede diagnosis in electronic medical records of 32,000 individuals","An early genetic diagnosis can guide the time-sensitive treatment of individuals with genetic epilepsies. However, most genetic diagnoses occur long after disease onset. We aimed to identify early clinical features suggestive of genetic diagnoses in individuals with epilepsy through large-scale analysis of full-text electronic medical records. We extracted 89 million time-stamped standardized clinical annotations using Natural Language Processing from 4,572,783 clinical notes from 32,112 individuals with childhood epilepsy, including 1925 individuals with known or presumed genetic epilepsies. We applied these features to train random forest models to predict SCN1A-related disorders and any genetic diagnosis. We identified 47,774 age-dependent associations of clinical features with genetic etiologies a median of 3.6 years before molecular diagnosis. Across all 710 genetic etiologies identified in our cohort, neurodevelopmental differences between 6 to 9 months increased the likelihood of a later molecular diagnosis 5-fold (P < .0001, 95% CI = 3.55-7.42). A later diagnosis of SCN1A-related disorders (area under the curve [AUC] = 0.91) or an overall positive genetic diagnosis (AUC = 0.82) could be reliably predicted using random forest models. Clinical features predictive of genetic epilepsies precede molecular diagnoses by up to several years in conditions with known precision treatments. An earlier diagnosis facilitated by automated electronic medical records analysis has the potential for earlier targeted therapeutic strategies in the genetic epilepsies",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
226,Computer-assisted patient identification tool in inborn errors of metabolism - potential for rare disease patient registry and big data analysis,"Patient registries are crucial for rare disease management. However, manual registry construction is labor-intensive and often not user-friendly. Our goal is to establish Hong Kong's first computer-assisted patient identification tool for rare diseases, starting with inborn errors of metabolism (IEM). Patient data from 2010 to 2019 was retrieved from electronic databases. Through big data analytics, patient data were filtered based on specific IEM-related biochemical and genetic tests. Clinical notes were analyzed using a rule-based natural language processing technique called regular expression. The algorithm classified each extracted paragraph as ""IEM-related"" or ""not IEM-related."" Pathologists reviewed the paragraphs for curation, and the algorithm's performance was evaluated. Out of 46,419 patients with IEM-related tests, the algorithm identified 100 as ""IEM-related."" After pathologists' validation, 96 cases were confirmed as true IEM, with 1 uncertain case and 3 false positives. A secondary ascertainment yielded a sensitivity of 92.3% compared to our previously published IEM cohort. Our artificial intelligence approach provides a novel method to identify IEM patients, facilitating the creation of a centralized, computer-assisted rare disease patient registry at the local and national levels. This data can potentially be accessed by multiple stakeholders for collaborative research and to enhance healthcare management for rare diseases",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
227,Contrastive learning-based histopathological features infer molecular subtypes and clinical outcomes of breast cancer from unannotated whole slide images,"The artificial intelligence-powered computational pathology has led to significant improvements in the speed and precision of tumor diagnosis, while also exhibiting substantial potential to infer genetic mutations and gene expression levels. However, current studies remain limited in predicting molecular subtypes and clinical outcomes in breast cancer. In this paper, we proposed a weakly supervised contrastive learning framework to address this challenge. Our framework first performed contrastive learning pretraining on a large number of unlabeled patches tiled from whole slide images (WSIs) to extract patch-level features. The gated attention mechanism was leveraged to aggregate patch-level features to produce slide feature that was then applied to various downstream tasks. To confirm the effectiveness of the proposed method, three public cohorts and one external independent cohort of breast cancer have been used to conducted evaluation experiments. The predictive powers of our model to infer gene expression, molecular subtypes, recurrence events and drug responses were validated across cohorts. In addition, the learned patch-level attention scores enabled us to generate heatmaps that were highly consistent with pathologist annotations and spatial transcriptomic data. These findings demonstrated that our model effectively established the high-order genotype-phenotype associations, thereby potentially extend the application of digital pathology in clinical practice",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
228,Conventional therapy induces tumor immunoediting and modulates the immune contexture in colorectal cancer,"BackgroundCancer immunotherapies for patients with colorectal cancer (CRC) continue to lag behind other solid cancer types with the exception of 4% of patients with microsatellite-instable tumors. Thus, there is an urgent need to broaden the clinical benefit of checkpoint blockers to CRC by combining conventional therapies to sensitise tumors to immunotherapy. However, the impact of conventional drugs on immunoediting, potentially promoting the positive selection of less immunogenic variants, and on the tumor immune contexture in CRC, remain elusive.  MethodsWe performed comprehensive multimodal profiling using longitudinal samples from metastatic CRC patients undergoing neoadjuvant therapy with mFOLFOX6 and Bevacizumab. Exome-sequencing, RNA-sequencing and multiplexed immunofluorescence imaging was carried out on tumor samples obtained before and after therapy and the data was analysed using established methods. The results of the analysis were extrapolated to publicly available datasets (TCGA and CPTAC). In order to identify a surrogate marker, an explainable artificial intelligence method was developed using a transformer-based analytical pipeline for the identification of features in Hematoxylin and Eosin (H&E) images associated with specific biological processes, followed by manual evaluation of highly informative tiles by a pathologist.  ResultsMutational profiles were highly modified and the level of genetic intertumoral heterogeneity between patients varied following treatment. Evolutionary analysis indicated eradication of some clones and dominant clonal prevalence of others, supporting the notion of pharmacologically-induced cancer immunoeditin. Post treatment samples showed upregulation of HLA class II genes, activation of differentiation and stemness pathways, and changes in the consensus molecular subtypes. The tumor immune contexture was characterised by increased densities of CD8+ and CD4+ T cells, but reduced T cell-tumor cell interactions (and increased T cell exhaustion. The AI-guided analyses of the H&E images pinpointed extracellular mucin deposits associated with stemness genes, suggesting a surrogate marker for routine pathological evaluation.  ConclusionsConventional therapy induces immunoediting and modulates the immune contexture in metastatic CRC patients",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
229,Current status of artificial intelligence methods for skin cancer survival analysis: a scoping review,"Skin cancer mortality rates continue to rise, and survival analysis is increasingly needed to understand who is at risk and what interventions improve outcomes. However, current statistical methods are limited by inability to synthesize multiple data types, such as patient genetics, clinical history, demographics, and pathology and reveal significant multimodal relationships through predictive algorithms. Advances in computing power and data science enabled the rise of artificial intelligence (AI), which synthesizes vast amounts of data and applies algorithms that enable personalized diagnostic approaches. Here, we analyze AI methods used in skin cancer survival analysis, focusing on supervised learning, unsupervised learning, deep learning, and natural language processing. We illustrate strengths and weaknesses of these approaches with examples. Our PubMed search yielded 14 publications meeting inclusion criteria for this scoping review. Most publications focused on melanoma, particularly histopathologic interpretation with deep learning. Such concentration on a single type of skin cancer amid increasing focus on deep learning highlight growing areas for innovation; however, it also demonstrates opportunity for additional analysis that addresses other types of cutaneous malignancies and expands the scope of prognostication to combine both genetic, histopathologic, and clinical data. Moreover, researchers may leverage multiple AI methods for enhanced benefit in analyses. Expanding AI to this arena may enable improved survival analysis, targeted treatments, and outcomes",,PubMed,,1,,,,"Supervised learning, unsupervised learning, deep learning, and NLP; ML Task: Survival analysis for skin cancer.","Skin cancer survival prediction using multimodal data (genetics, clinical, pathology).","AI methods, especially deep learning, are applied to skin cancer prognosis, focusing on multimodal data integration.",FALSE,TRUE,FALSE
230,Deep learning analyses of splicing variants identify the link of PCP4 with amyotrophic lateral sclerosis,"Amyotrophic lateral sclerosis (ALS) is a severe motor neuron disease, with most sporadic cases lacking clear genetic causes. Abnormal pre-mRNA splicing is a fundamental mechanism in neurodegenerative diseases. For example, TAR DNA-binding protein 43 (TDP-43) loss-of-function (LOF) causes widespread RNA mis-splicing events in ALS. Additionally, splicing mutations are major contributors to neurological disorders. However, the role of intronic variants driving RNA mis-splicing in ALS remains poorly understood. To address this, we developed Spliformer to predict RNA splicing. Spliformer is a transformer-based deep learning model trained and tested on splicing events from the GENCODE database, as well as RNA-seq data from blood and central nervous system tissues. We benchmarked Spliformer against SpliceAI and Pangolin using testing datasets and paired whole-genome sequencing (WGS) with RNA-seq data. We further developed the Spliformer-motif model to identify splicing regulatory motifs. We analyzed Clinvar dataset to identify the link of splicing variants with disease pathogenicity. Additionally, we analyzed WGS data of ALS patients and controls to identify common intronic splicing variants linked to ALS risk or disease phenotypes. We also profiled rare intronic splicing variants in ALS patients to identify known or novel ALS-associated genes. Minigene assays were employed to validate candidate splicing variants. Finally, we measured spine density in neurons with a specific gene knockdown or those expressing a TDP-43 disease-causing mutant. Spliformer accurately predicts the possibilities of a nucleotide within a pre-mRNA sequence being a splice donor, acceptor, or neither. Spliformer outperformed SpliceAI and Pangolin in both speed and accuracy in tested splicing events and/or paired WGS/RNA-seq data. Spliformer-motif successfully identified canonical and novel splicing regulatory motifs. In Clinvar dataset, splicing variants are highly related to disease pathogenicity. Genome-wide analyses of common intronic splicing variants nominated one variant linked to ALS progression. Deep learning analyses of WGS data from 1,370 ALS patients revealed rare splicing variants in reported ALS genes (such as PTPRN2 and CFAP410, validated through minigene assays and RNA-seq), and TDP-43 LOF related RNA mis-splicing genes (such as PTPRD). Further genetic analysis and minigene assays nominated PCP4 and TMEM63A as ALS-associated genes. Functional assays demonstrated that PCP4 is critical for maintaining spine density and can rescue spine loss in neurons expressing a disease-causing TDP-43 mutant. In summary, we developed Spliformer and Spliformer-motif that accurately predict and interpret pre-mRNA splicing. Our findings highlight an intronic genetic mechanism driving RNA mis-splicing in ALS and nominate PCP4 as an ALS-associated gene",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
231,"Deep Learning on 777K Bulk Transcriptomes Unveils Human-Mouse Cross-Species Gene Disparities
==========
Genes in Humans and Mice: Insights from Deep learning of 777K Bulk Transcriptomes","Mice are widely used as animal models in biomedical research, favored for their small size, ease of breeding, and anatomical and physiological similarities to humans1,2. However, discrepancies between mouse gene experimental results and the actual behavior of human genes are not uncommon, despite their shared DNA sequence similarity3-8. This suggests that DNA sequence similarity does not always reliably predict functional similarity. On the other hand, RNA-level gene expression could offer additional information about gene function9,10. In this study, we undertook characterization and inter-species comparison of human and mouse genes by applying innovative deep learning methodologies to a large dataset of 410K human and 366K mouse bulk RNA-seq samples. This was achieved by using gene representations from our Transformer-based GeneRAIN model11,12. These gene representations aggregate information from large gene expression datasets, and provide insights beyond DNA sequence similarity. We identified 2,407 human-mouse homologous genes with high DNA similarity but distinct RNA characteristics, and showed that these genes are more likely to have differing disease/phenotype associations between the two species. Additionally, we found 3,070 homologous genes with low similarity at both the DNA and RNA levels, suggesting the highest risk of discrepancies in study results between the two species. We propose that this approach will support future decision making around whether the mouse will be an appropriate model for studying specific human genes, and whether the results of specific mouse gene studies are likely to be recapitulated in humans. Our methodological innovations offer valuable lessons for future deep learning applications in cross-species omics data. The interspecies gene relationship findings from our study also contribute valuable insights into the gene biology and evolution of the two species",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
232,DeepGenMon: A Novel Framework for Monkeypox Classification Integrating Lightweight Attention-Based Deep Learning and a Genetic Algorithm,"Background: The rapid global spread of the monkeypox virus has led to serious issues for public health professionals. According to related studies, monkeypox and other types of skin conditions can spread through direct contact with infected animals, humans, or contaminated items. This disease can cause fever, headaches, muscle aches, and enlarged lymph nodes, followed by a rash that develops into lesions. To facilitate the early detection of monkeypox, researchers have proposed several AI-based techniques for accurately classifying and identifying the condition. However, there is still room for improvement to accurately detect and classify monkeypox cases. Furthermore, the currently proposed pre-trained deep learning models can consume extensive resources to achieve accurate detection and classification of monkeypox. Hence, these models often need significant computational power and memory. Methods: This paper proposes a novel lightweight framework called DeepGenMonto accurately classify various types of skin diseases, such as chickenpox, melasma, monkeypox, and others. This suggested framework leverages an attention-based convolutional neural network (CNN) and a genetic algorithm (GA) to enhance detection accuracy while optimizing the hyperparameters of the proposed model. It first applies the attention mechanism to highlight and assign weights to specific regions of an image that are relevant to the model's decision-making process. Next, the CNN is employed to process the visual input and extract hierarchical features for classifying the input data into multiple classes. Finally, the CNN's hyperparameters are adjusted using a genetic algorithm to enhance the model's robustness and classification accuracy. Compared to the state-of-the-art (SOTA) models, DeepGenMon features a lightweight design that requires significantly lower computational resources and is easier to train with few parameters. Its effective integration of a CNN and an attention mechanism with a GA further enhances its performance, making it particularly well suited for low-resource environments. DeepGenMon is evaluated on two public datasets. The first dataset comprises 847 images of diverse skin diseases, while the second dataset contains 659 images classified into several categories. Results: The proposed model demonstrates superior performance compared to SOTA models across key evaluation metrics. On dataset 1, it achieves a precision of 0.985, recall of 0.984, F-score of 0.985, and accuracy of 0.985. Similarly, on dataset 2, the model attains a precision of 0.981, recall of 0.982, F-score of 0.982, and accuracy of 0.982. Moreover, the findings demonstrate the model's ability to achieve an inference time of 2.9764 s on dataset 1 and 2.1753 s on dataset 2. Conclusions: These results also show DeepGenMon's effectiveness in accurately classifying different skin conditions, highlighting its potential as a reliable and low-resource tool in clinical settings",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
233,Deriving comprehensive literature trends on multi-omics analysis studies in autism spectrum disorder using literature mining pipeline,"Autism spectrum disorder (ASD) is characterized by highly heterogenous abnormalities in functional brain connectivity affecting social behavior. There is a significant progress in understanding the molecular and genetic basis of ASD in the last decade using multi-omics approach. Mining this large volume of biomedical literature for insights requires considerable amount of manual intervention for curation. Machine learning and artificial intelligence fields are advancing toward simplifying data mining from unstructured text data. Here, we demonstrate our literature mining pipeline to accelerate data to insights. Using topic modeling and generative AI techniques, we present a pipeline that can classify scientific literature into thematic clusters and can help in a wide array of applications such as knowledgebase creation, conversational virtual assistant, and summarization. Employing our pipeline, we explored the ASD literature, specifically around multi-omics studies to understand the molecular interplay underlying autism brain",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
234,Detecting and Evaluating Medical Hallucinations in Large Vision Language Models,"Large Vision Language Models (LVLMs) are increasingly integral to healthcare applications, including medical visual question answering and imaging report generation. While these models inherit the robust capabilities of foundational Large Language Models (LLMs), they also inherit susceptibility to hallucinations-a significant concern in high-stakes medical contexts where the margin for error is minimal. However, currently, there are no dedicated methods or benchmarks for hallucination detection and evaluation in the medical field. To bridge this gap, we introduce Med-HallMark, the first benchmark specifically designed for hallucination detection and evaluation within the medical multimodal domain. This benchmark provides multi-tasking hallucination support, multifaceted hallucination data, and hierarchical hallucination categorization. Furthermore, we propose the MediHall Score, a new medical evaluative metric designed to assess LVLMs' hallucinations through a hierarchical scoring system that considers the severity and type of hallucination, thereby enabling a granular assessment of potential clinical impacts. We also present MediHallDetector, a novel Medical LVLM engineered for precise hallucination detection, which employs multitask training for hallucination detection. Through extensive experimental evaluations, we establish baselines for popular LVLMs using our benchmark. The findings indicate that MediHall Score provides a more nuanced understanding of hallucination impacts compared to traditional metrics and demonstrate the enhanced performance of MediHallDetector. We hope this work can significantly improve the reliability of LVLMs in medical applications. All resources of this work will be released soon",,arXiv,,1,,,,,,,FALSE,TRUE,FALSE
235,Development of a culturally targeted chatbot to inform living kidney donor candidates of African ancestry about APOL1 genetic testing: a mixed methods study,"Clinical chatbots are increasingly used to help integrate genetic testing into clinical contexts, but no chatbot exists for Apolipoprotein L1 (APOL1) genetic testing of living kidney donor (LKD) candidates of African ancestry. Our study aimed to culturally adapt and assess perceptions of the Gia® chatbot to help integrate APOL1 testing into LKD evaluation. Ten focus groups and post-focus group surveys were conducted with 54 LKDs, community members, and kidney transplant recipients of African ancestry. Data were analyzed through thematic analysis and descriptive statistics. Key themes about making Gia culturally targeted included ensuring: (1) transparency by providing Black LKDs' testimonials, explaining patient privacy and confidentiality protections, and explaining how genetic testing can help LKD evaluation; (2) content is informative by educating Black LKDs about APOL1 testing instead of aiming to convince them to undergo testing, presenting statistics, and describing how genetic discrimination is legally prevented; and (3) content avoids stigma about living donation in the Black community. Most agreed Gia was neutral and unbiased (82%), trustworthy (82%), and words, phrases, and expressions were familiar to the intended audience (85%). Our culturally adapted APOL1 Gia chatbot was well regarded. Future research should assess how this chatbot could supplement provider discussion prior to genetic testing to scale APOL1 counseling and testing for LKD candidate clinical evaluation",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
236,Digital ECMT Cancer Trial Matching Tool: an Open Source Research Application to Support Oncologists in the Identification of Precision Medicine Clinical Trials,"Matching patients with cancer to precision medicine clinical trials on the basis of their tumor genotype has the potential to improve outcomes for patients who have exhausted standard-of-care treatment options. However, the matching process presents a substantial challenge because of the number of clinical trials available. We describe a free, open source research tool designed to extract relevant trial information to support oncologists in the matching process, and we illustrate its utility with recent case studies of patients who were matched to trials using this tool. Trial records are sourced from ClinicalTrials.gov and indexed using natural language processing techniques, including named entity recognition, term normalization, and relationship extraction. Relationships between trials and genetic alterations are assigned scores on the basis of a rule-based system. All data are updated daily. A user interface is provided via R Shiny app. An instance of the trial match tool, configured for UK clinical trials, is hosted by the digital Experimental Cancer Medicine Team (see link in Data Sharing Statement). Users select the relevant cancer type and genetic alteration(s). Matching studies are ranked according to the score assigned for the selected genetic alterations. Results may be downloaded and attached to the patient's health record if desired. The tool is currently being used to support the ongoing TARGET National study, which aims to match up to 6,000 patients to early phase clinical trials. We present three case studies that exemplify relationships between genetic alterations and studies. With increasing numbers of precision medicine treatments and as comprehensive molecular profiling of tumor samples becomes more common, decision support tools are likely to become increasingly important. This work represents an important step toward the development and wider implementation of such systems",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
237,Distinguishing clinical and genetic risk factors for suicidal ideation and behavior in a diverse hospital population,"Suicidal ideation (SI) and behavior (SB) are major public health concerns, but risk factors for their development and progression are poorly understood. We used ICD codes and a natural language processing algorithm to identify individuals in a hospital biobank with SI-only, SB, and controls without either. We compared the profiles of SB and SI-only patients to controls, and each other, using phenome-wide association studies (PheWAS) and polygenic risk scores (PRS). PheWAS identified many risk factors for SB and SI-only, plus specific psychiatric disorders which may be involved in progression from SI-only to SB. PRS for suicide attempt were only associated with SB, and even after accounting for psychiatric disorder PRS. SI PRS were only associated with SI-only, although not after accounting for psychiatric disorder PRS. These findings advance understanding of distinct genetic and clinical risk factors for SB and SI-only, which will aid in early detection and intervention efforts",,medrxiv,,1,,,,"NLP algorithm (not transformers), PheWAS, Polygenic Risk Scores (PRS); ML Task: Identification of clinical and genetic risk factors.",Risk factors for suicidal ideation and behavior; analysis of genomic (NGS) and clinical data.,Identifies genetic and clinical factors distinct to suicidal ideation and behavior using PRS and NLP.,FALSE,TRUE,FALSE
238,Echoes of Biases: How Stigmatizing Language Affects AI Performance,"Electronic health records (EHRs) serve as an essential data source for the envisioned artificial intelligence (AI)-driven transformation in healthcare. However, clinician biases reflected in EHR notes can lead to AI models inheriting and amplifying these biases, perpetuating health disparities. This study investigates the impact of stigmatizing language (SL) in EHR notes on mortality prediction using a Transformer-based deep learning model and explainable AI (XAI) techniques. Our findings demonstrate that SL written by clinicians adversely affects AI performance, particularly so for black patients, highlighting SL as a source of racial disparity in AI model development. To explore an operationally efficient way to mitigate SL's impact, we investigate patterns in the generation of SL through a clinicians' collaborative network, identifying central clinicians as having a stronger impact on racial disparity in the AI model. We find that removing SL written by central clinicians is a more efficient bias reduction strategy than eliminating all SL in the entire corpus of data. This study provides actionable insights for responsible AI development and contributes to understanding clinician behavior and EHR note writing in healthcare",,arXiv,,1,,,,,,,FALSE,TRUE,FALSE
239,Emerging Drug Combinations for Targeting Tongue Neoplasms Associated Proteins/Genes: Employing Graph Neural Networks within the RAIN Protocol,"BackgroundTongue Neoplasms is a common form of malignancy, with squamous cell carcinoma of the tongue being the most frequently diagnosed type due to regular mechanical stimulation. Its prevalence remains on the rise among neoplastic cancer cases. Finding effective combinations of drugs to target the genetic and protein elements contributing to the development of Managing Tongue Neoplasms poses a difficulty owing to the intricate and varied nature of the ailment.  MethodIn this research, we introduce a novel approach using Deep Modularity Networks (DMoN) to identify potential synergistic drug combinations for the condition, following the RAIN protocol. This procedure comprises three primary phases: First, employing Graph Neural Network (GNN) to propose drug combinations for treating the ailment by extracting embedding vectors of drugs and proteins from an extensive knowledge graph containing various biomedical data types, such as drug-protein interactions, gene expression, and drug-target interactions. Second, utilizing natural language processing to gather pertinent articles from clinical trials involving the previously recommended drugs. Finally, conducting network meta-analysis to evaluate the comparative efficacy of these drug combinations.  ResultWe utilized our approach on a dataset containing drugs and genes as nodes, connected by edges indicating their associated p-values. Our DMoN model identified Cisplatin, Bleomycin, and Fluorouracil as the optimal drug combination for targeting the human genes/proteins associated with this cancer. Subsequent scrutiny of clinical trials and literature confirmed the validity of our findings. Additionally, network meta-analysis substantiated the efficacy of these medications concerning the pertinent genes.  ConclusionThrough the utilization of DMoN as part of the RAIN protocol, our method introduces a fresh and effective way to suggest notable drug combinations for addressing proteins/genes linked to Tongue Neoplasms. This approach holds promise in assisting healthcare practitioners and researchers in pinpointing the best treatments for patients, as well as uncovering the fundamental mechanisms of the disease.  HighlightsO_LIA new method using Deep Modularity Networks and the RAIN protocol can find the best drug combinations for treating Tongue Neoplasms, a common and deadly form of cancer. C_LIO_LIThe method uses a Graph Neural Network to suggest drug pairings from a large knowledge graph of biomedical data, then searches for clinical trials and performs network meta-analysis to compare their effectiveness. C_LIO_LIThe method discovered that Cisplatin, Bleomycin, and Fluorouracil are suitable drugs for targeting the genes/proteins involved in this cancer, and confirmed this finding with literature review and statistical analysis. C_LIO_LIThe method offers a novel and powerful way to assist doctors and researchers in finding the optimal treatments for patients with Tongue Neoplasms, and to understand the underlying causes of the disease. C_LI    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=108 SRC=""FIGDIR/small/598402v1_ufig1.gif"" ALT=""Figure 1""> View larger version (44K): org.highwire.dtl.DTLVardef@56bc74org.highwire.dtl.DTLVardef@6e9308org.highwire.dtl.DTLVardef@177144aorg.highwire.dtl.DTLVardef@d53c5e_HPS_FORMAT_FIGEXP  M_FIG C_FIG",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
240,Enhanced family history-based algorithms increase the identification of individuals meeting criteria for genetic testing of hereditary cancer syndromes but would not reduce disparities on their own,"This study aimed to 1) investigate algorithm enhancements for identifying patients eligible for genetic testing of hereditary cancer syndromes using family history data from electronic health records (EHRs); and 2) assess their impact on relative differences across sex, race, ethnicity, and language preference. The study used EHR data from a tertiary academic medical center. A baseline rule-base algorithm, relying on structured family history data (structured data; SD), was enhanced using a natural language processing (NLP) component and a relaxed criteria algorithm (partial match [PM]). The identification rates and differences were analyzed considering sex, race, ethnicity, and language preference. Among 120,007 patients aged 25-60, detection rate differences were found across all groups using the SD (all P < 0.001). Both enhancements increased identification rates; NLP led to a 1.9 % increase and the relaxed criteria algorithm (PM) led to an 18.5 % increase (both P < 0.001). Combining SD with NLP and PM yielded a 20.4 % increase (P < 0.001). Similar increases were observed within subgroups. Relative differences persisted across most categories for the enhanced algorithms, with disproportionately higher identification of patients who are White, Female, non-Hispanic, and whose preferred language is English. Algorithm enhancements increased identification rates for patients eligible for genetic testing of hereditary cancer syndromes, regardless of sex, race, ethnicity, and language preference. However, differences in identification rates persisted, emphasizing the need for additional strategies to reduce disparities such as addressing underlying biases in EHR family health information and selectively applying algorithm enhancements for disadvantaged populations. Systematic assessment of differences in algorithm performance across population subgroups should be incorporated into algorithm development processes",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
241,Enhancing patient representation learning with inferred family pedigrees improves disease risk prediction,"Machine learning and deep learning are powerful tools for analyzing electronic health records (EHRs) in healthcare research. Although family health history has been recognized as a major predictor for a wide spectrum of diseases, research has so far adopted a limited view of family relations, essentially treating patients as independent samples in the analysis. To address this gap, we present ALIGATEHR, which models inferred family relations in a graph attention network augmented with an attention-based medical ontology representation, thus accounting for the complex influence of genetics, shared environmental exposures, and disease dependencies. Taking disease risk prediction as a use case, we demonstrate that explicitly modeling family relations significantly improves predictions across the disease spectrum. We then show how ALIGATEHR's attention mechanism, which links patients' disease risk to their relatives' clinical profiles, successfully captures genetic aspects of diseases using longitudinal EHR diagnosis data. Finally, we use ALIGATEHR to successfully distinguish the 2 main inflammatory bowel disease subtypes with highly shared risk factors and symptoms (Crohn's disease and ulcerative colitis). Overall, our results highlight that family relations should not be overlooked in EHR research and illustrate ALIGATEHR's great potential for enhancing patient representation learning for predictive and interpretable modeling of EHRs",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
242,Estimating prevalence of rare genetic disease diagnoses using electronic health records in a children's hospital,"Rare genetic diseases (RGDs) affect a significant number of individuals, particularly in pediatric populations. This study investigates the efficacy of identifying RGD diagnoses through electronic health records (EHRs) and natural language processing (NLP) tools, and analyzes the prevalence of identified RGDs for potential underdiagnosis at Cincinnati Children's Hospital Medical Center (CCHMC). EHR data from 659,139 pediatric patients at CCHMC were utilized. Diagnoses corresponding to RGDs in Orphanet were identified using rule-based and machine learning-based NLP methods. Manual evaluation assessed the precision of the NLP strategies, with 100 diagnosis descriptions reviewed for each method. The rule-based method achieved a precision of 97.5% (95% CI: 91.5%, 99.4%), while the machine-learning-based method had a precision of 73.5% (95% CI: 63.6%, 81.6%). A manual chart review of 70 randomly selected patients with RGD diagnoses confirmed the diagnoses in 90.3% (95% CI: 82.0%, 95.2%) of cases. A total of 37,326 pediatric patients were identified with 977 RGD diagnoses based on the rule-based method, resulting in a prevalence of 5.66% in this population. While a majority of the disorders showed a higher prevalence at CCHMC compared with Orphanet, some diseases, such as 1p36 deletion syndrome, indicated potential underdiagnosis. Analyses further uncovered disparities in RGD prevalence and age of diagnosis across gender and racial groups. This study demonstrates the utility of employing EHR data with NLP tools to systematically investigate RGD diagnoses in large cohorts. The identified disparities underscore the need for enhanced approaches to guarantee timely and accurate diagnosis and management of pediatric RGDs",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
243,"Etiology of Late-Onset Alzheimer's Disease, Biomarker Efficacy, and the Role of Machine Learning in Stage Diagnosis","Late-onset Alzheimer's disease (LOAD) is a subtype of dementia that manifests after the age of 65. It is characterized by progressive impairments in cognitive functions, behavioral changes, and learning difficulties. Given the progressive nature of the disease, early diagnosis is crucial. Early-onset Alzheimer's disease (EOAD) is solely attributable to genetic factors, whereas LOAD has multiple contributing factors. A complex pathway mechanism involving multiple factors contributes to LOAD progression. Employing a systems biology approach, our analysis encompassed the genetic, epigenetic, metabolic, and environmental factors that modulate the molecular networks and pathways. These factors affect the brain's structural integrity, functional capacity, and connectivity, ultimately leading to the manifestation of the disease. This study has aggregated diverse biomarkers associated with factors capable of altering the molecular networks and pathways that influence brain structure, functionality, and connectivity. These biomarkers serve as potential early indicators for AD diagnosis and are designated as early biomarkers. The other biomarker datasets associated with the brain structure, functionality, connectivity, and related parameters of an individual are broadly categorized as clinical-stage biomarkers. This study has compiled research papers on Alzheimer's disease (AD) diagnosis utilizing machine learning (ML) methodologies from both categories of biomarker data, including the applications of ML techniques for AD diagnosis. The broad objectives of our study are research gap identification, assessment of biomarker efficacy, and the most effective or prevalent ML technology used in AD diagnosis. This paper examines the predominant use of deep learning (DL) and convolutional neural networks (CNNs) in Alzheimer's disease (AD) diagnosis utilizing various types of biomarker data. Furthermore, this study has addressed the potential scope of using generative AI and the Synthetic Minority Oversampling Technique (SMOTE) for data augmentation",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
244,Evaluation of the Rosa Chatbot Providing Genetic Information to Patients at Risk of Hereditary Breast and Ovarian Cancer: Qualitative Interview Study,"Genetic testing has become an integrated part of health care for patients with breast or ovarian cancer, and the increasing demand for genetic testing is accompanied by an increasing need for easy access to reliable genetic information for patients. Therefore, we developed a chatbot app (Rosa) that is able to perform humanlike digital conversations about genetic BRCA testing. Before implementing this new information service in daily clinical practice, we wanted to explore 2 aspects of chatbot use: the perceived utility and trust in chatbot technology among healthy patients at risk of hereditary cancer and how interaction with a chatbot regarding sensitive information about hereditary cancer influences patients. Overall, 175 healthy individuals at risk of hereditary breast and ovarian cancer were invited to test the chatbot, Rosa, before and after genetic counseling. To secure a varied sample, participants were recruited from all cancer genetic clinics in Norway, and the selection was based on age, gender, and risk of having a BRCA pathogenic variant. Among the 34.9% (61/175) of participants who consented for individual interview, a selected subgroup (16/61, 26%) shared their experience through in-depth interviews via video. The semistructured interviews covered the following topics: usability, perceived usefulness, trust in the information received via the chatbot, how Rosa influenced the user, and thoughts about future use of digital tools in health care. The transcripts were analyzed using the stepwise-deductive inductive approach. The overall finding was that the chatbot was very welcomed by the participants. They appreciated the 24/7 availability wherever they were and the possibility to use it to prepare for genetic counseling and to repeat and ask questions about what had been said afterward. As Rosa was created by health care professionals, they also valued the information they received as being medically correct. Rosa was referred to as being better than Google because it provided specific and reliable answers to their questions. The findings were summed up in 3 concepts: ""Anytime, anywhere""; ""In addition, not instead""; and ""Trustworthy and true."" All participants (16/16) denied increased worry after reading about genetic testing and hereditary breast and ovarian cancer in Rosa. Our results indicate that a genetic information chatbot has the potential to contribute to easy access to uniform information for patients at risk of hereditary breast and ovarian cancer, regardless of geographical location. The 24/7 availability of quality-assured information, tailored to the specific situation, had a reassuring effect on our participants. It was consistent across concepts that Rosa was a tool for preparation and repetition; however, none of the participants (0/16) supported that Rosa could replace genetic counseling if hereditary cancer was confirmed. This indicates that a chatbot can be a well-suited digital companion to genetic counseling",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
246,Familial hypercholesterolaemia in children and adolescents from 48 countries: a cross-sectional study,"Approximately 450 000 children are born with familial hypercholesterolaemia worldwide every year, yet only 2·1% of adults with familial hypercholesterolaemia were diagnosed before age 18 years via current diagnostic approaches, which are derived from observations in adults. We aimed to characterise children and adolescents with heterozygous familial hypercholesterolaemia (HeFH) and understand current approaches to the identification and management of familial hypercholesterolaemia to inform future public health strategies. For this cross-sectional study, we assessed children and adolescents younger than 18 years with a clinical or genetic diagnosis of HeFH at the time of entry into the Familial Hypercholesterolaemia Studies Collaboration (FHSC) registry between Oct 1, 2015, and Jan 31, 2021. Data in the registry were collected from 55 regional or national registries in 48 countries. Diagnoses relying on self-reported history of familial hypercholesterolaemia and suspected secondary hypercholesterolaemia were excluded from the registry; people with untreated LDL cholesterol (LDL-C) of at least 13·0 mmol/L were excluded from this study. Data were assessed overall and by WHO region, World Bank country income status, age, diagnostic criteria, and index-case status. The main outcome of this study was to assess current identification and management of children and adolescents with familial hypercholesterolaemia. Of 63 093 individuals in the FHSC registry, 11 848 (18·8%) were children or adolescents younger than 18 years with HeFH and were included in this study; 5756 (50·2%) of 11 476 included individuals were female and 5720 (49·8%) were male. Sex data were missing for 372 (3·1%) of 11 848 individuals. Median age at registry entry was 9·6 years (IQR 5·8-13·2). 10 099 (89·9%) of 11 235 included individuals had a final genetically confirmed diagnosis of familial hypercholesterolaemia and 1136 (10·1%) had a clinical diagnosis. Genetically confirmed diagnosis data or clinical diagnosis data were missing for 613 (5·2%) of 11 848 individuals. Genetic diagnosis was more common in children and adolescents from high-income countries (9427 [92·4%] of 10 202) than in children and adolescents from non-high-income countries (199 [48·0%] of 415). 3414 (31·6%) of 10 804 children or adolescents were index cases. Familial-hypercholesterolaemia-related physical signs, cardiovascular risk factors, and cardiovascular disease were uncommon, but were more common in non-high-income countries. 7557 (72·4%) of 10 428 included children or adolescents were not taking lipid-lowering medication (LLM) and had a median LDL-C of 5·00 mmol/L (IQR 4·05-6·08). Compared with genetic diagnosis, the use of unadapted clinical criteria intended for use in adults and reliant on more extreme phenotypes could result in 50-75% of children and adolescents with familial hypercholesterolaemia not being identified. Clinical characteristics observed in adults with familial hypercholesterolaemia are uncommon in children and adolescents with familial hypercholesterolaemia, hence detection in this age group relies on measurement of LDL-C and genetic confirmation. Where genetic testing is unavailable, increased availability and use of LDL-C measurements in the first few years of life could help reduce the current gap between prevalence and detection, enabling increased use of combination LLM to reach recommended LDL-C targets early in life. Pfizer, Amgen, Merck Sharp & Dohme, Sanofi-Aventis, Daiichi Sankyo, and Regeneron",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
247,Feasibility of identifying factors related to Alzheimer's disease and related dementia in real-world data,"A comprehensive understanding of factors associated with Alzheimers disease (AD) and AD-related dementias (AD/ADRD) will significantly enhance efforts when designing new studies to develop new treatments and identify high-risk populations for prevention. We reviewed existing meta-analyses and review articles on AD/ADRD risk and preventive factors, extracting 477 risk factors across 10 categories from 537 studies. An interactive knowledge graph was created to share our study findings. Most risk factors can be found in structured Electronic Health Records (EHRs), with clinical narratives also providing valuable information. However, assessing genomic risk factors using real-world data (RWD) like EHRs remains a challenge, as genetic testing for AD/ADRD is still not a common practice and poorly documented in both structured and unstructured EHRs. Given the constant and rapid evolution of AD/ADRD research, using natural language processing (NLP) for literature mining emerges as a viable method to continually and automatically update our knowledge graph",,"medrxiv, arXiv,PubMed",,1,,,,,,,FALSE,TRUE,FALSE
248,Generating 3D Brain Tumor Regions in MRI using Vector-Quantization Generative Adversarial Networks,"Medical image analysis has significantly benefited from advancements in deep learning, particularly in the application of Generative Adversarial Networks (GANs) for generating realistic and diverse images that can augment training datasets. However, the effectiveness of such approaches is often limited by the amount of available data in clinical settings. Additionally, the common GAN-based approach is to generate entire image volumes, rather than solely the region of interest (ROI). Research on deep learning-based brain tumor classification using MRI has shown that it is easier to classify the tumor ROIs compared to the entire image volumes. In this work, we present a novel framework that uses vector-quantization GAN and a transformer incorporating masked token modeling to generate high-resolution and diverse 3D brain tumor ROIs that can be directly used as augmented data for the classification of brain tumor ROI. We apply our method to two imbalanced datasets where we augment the minority class: (1) the Multimodal Brain Tumor Segmentation Challenge (BraTS) 2019 dataset to generate new low-grade glioma (LGG) ROIs to balance with high-grade glioma (HGG) class; (2) the internal pediatric LGG (pLGG) dataset tumor ROIs with BRAF V600E Mutation genetic marker to balance with BRAF Fusion genetic marker class. We show that the proposed method outperforms various baseline models in both qualitative and quantitative measurements. The generated data was used to balance the data in the brain tumor types classification task. Using the augmented data, our approach surpasses baseline models by 6.4% in AUC on the BraTS 2019 dataset and 4.3% in AUC on our internal pLGG dataset. The results indicate the generated tumor ROIs can effectively address the imbalanced data problem. Our proposed method has the potential to facilitate an accurate diagnosis of rare brain tumors using MRI scans",,"PubMed, arXiv",,1,,,,,,,FALSE,TRUE,FALSE
249,Genetic counselors' utilization of ChatGPT in professional practice: A cross-sectional study,"The precision medicine era has seen increased utilization of artificial intelligence (AI) in the field of genetics. We sought to explore the ways that genetic counselors (GCs) currently use the publicly accessible AI tool Chat Generative Pre-trained Transformer (ChatGPT) in their work. GCs in North America were surveyed about how ChatGPT is used in different aspects of their work. Descriptive statistics were reported through frequencies and means. Of 118 GCs who completed the survey, 33.8% (40) reported using ChatGPT in their work; 47.5% (19) use it in clinical practice, 35% (14) use it in education, and 32.5% (13) use it in research. Most GCs (62.7%; 74) felt that it saves time on administrative tasks but the majority (82.2%; 97) felt that a paramount challenge was the risk of obtaining incorrect information. The majority of GCs not using ChatGPT (58.9%; 46) felt it was not necessary for their work. A considerable number of GCs in the field are using ChatGPT in different ways, but it is primarily helpful with tasks that involve writing. It has potential to streamline workflow issues encountered in clinical genetics, but practitioners need to be informed and uniformly trained about its limitations",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
250,Genetic deconvolution of embryonic and maternal cell-free DNA in spent culture medium of human preimplantation embryos through deep learning,"Noninvasive preimplantation genetic testing for aneuploidy based on embryonic cell-free DNA (cfDNA) released in spent embryo culture media (SECM) has brought hope in selecting embryos that are most likely to implant and grow into healthy babies during assisted reproduction. However, maternal DNA contamination in SECM significantly hampers the reliability of embryonic chromosome ploidy profiles, leading to false negative results, particularly at high contamination levels. Here, we present DECENT (deep copy number variation (CNV) reconstruction), a deep learning method to reconstruct embryonic CNVs and mitigate maternal contamination in SECM from single-cell methylation sequencing of cfDNA. DECENT integrates sequence features and methylation patterns by combining convolution modules, long-short memory, and attention mechanisms to infer the origin of cfDNA reads. The benchmarking study demonstrated DECENTs ability to estimate contamination proportions and restore embryonic chromosome aneuploidies in samples with varying contamination levels. In contaminated SECM clinical samples, including one with more than 80% maternal reads, DECENT achieved consistent CNV recovery with invasive tests. Overall, DECENT contributes to enhancing the diagnostic accuracy and effectiveness of cfDNA-based noninvasive preimplantation genetic testing, establishing a robust groundwork for its extensive clinical utilization in the field of reproductive medicine",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
251,Genetic influences on epilepsy outcomes: A whole-exome sequencing and health care records data linkage study,"This study was undertaken to develop a novel pathway linking genetic data with routinely collected data for people with epilepsy, and to analyze the influence of rare, deleterious genetic variants on epilepsy outcomes. We linked whole-exome sequencing (WES) data with routinely collected primary and secondary care data and natural language processing (NLP)-derived seizure frequency information for people with epilepsy within the Secure Anonymised Information Linkage Databank. The study participants were adults who had consented to participate in the Swansea Neurology Biobank, Wales, between 2016 and 2018. DNA sequencing was carried out as part of the Epi25 collaboration. For each individual, we calculated the total number and cumulative burden of rare and predicted deleterious genetic variants and the total of rare and deleterious variants in epilepsy and drug metabolism genes. We compared these measures with the following outcomes: (1) no unscheduled hospital admissions versus unscheduled admissions for epilepsy, (2) antiseizure medication (ASM) monotherapy versus polytherapy, and (3) at least 1 year of seizure freedom versus <1 year of seizure freedom. We linked genetic data for 107 individuals with epilepsy (52% female) to electronic health records. Twenty-six percent had unscheduled hospital admissions, and 70% were prescribed ASM polytherapy. Seizure frequency information was linked for 100 individuals, and 10 were seizure-free. There was no significant difference between the outcome groups in terms of the exome-wide and gene-based burden of rare and deleterious genetic variants. We successfully uploaded, annotated, and linked genetic sequence data and NLP-derived seizure frequency data to anonymized health care records in this proof-of-concept study. We did not detect a genetic influence on real-world epilepsy outcomes, but our study was limited by a small sample size. Future studies will require larger (WES) data to establish genetic variant contribution to epilepsy outcomes",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
252,Global hypomethylation in childhood asthma identified by genome-wide DNA-methylation sequencing preferentially affects enhancer regions,"Childhood asthma is a result of a complex interaction of genetic and environmental components causing epigenetic and immune dysregulation, airway inflammation and impaired lung function. Although different microarray based EWAS studies have been conducted, the impact of epigenetic regulation in asthma development is still widely unknown. We have therefore applied unbiased whole genome bisulfite sequencing (WGBS) to characterize global DNA-methylation profiles of asthmatic children compared to healthy controls. Peripheral blood samples of 40 asthmatic and 42 control children aged 5-15 years from three birth cohorts were sequenced together with paired cord blood samples. Identified differentially methylated regions (DMRs) were categorized in genotype-associated, cell-type-dependent, or prenatally primed. Network analysis and subsequent natural language processing of DMR-associated genes was complemented by targeted analysis of functional translation of epigenetic regulation on the transcriptional and protein level. In total, 158 DMRs were identified in asthmatic children compared to controls of which 37% were related to the eosinophil content. A global hypomethylation was identified affecting predominantly enhancer regions and regulating key immune genes such as IL4, IL5RA, and EPX. These DMRs were confirmed in n = 267 samples and could be linked to aberrant gene expression. Out of the 158 DMRs identified in the established phenotype, 56 were perturbed already at birth and linked, at least in part, to prenatal influences such as tobacco smoke exposure or phthalate exposure. This is the first epigenetic study based on whole genome sequencing to identify marked dysregulation of enhancer regions as a hallmark of childhood asthma",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
253,Gpmb-yolo: a lightweight model for efficient blood cell detection in medical imaging,"In the field of biomedical science, blood cell detection in microscopic images is crucial for aiding physicians in diagnosing blood-related diseases and plays a pivotal role in advancing medicine toward more precise and efficient treatment directions. Addressing the time-consuming and error-prone issues of traditional manual detection methods, as well as the challenge existing blood cell detection technologies face in meeting both high accuracy and real-time requirements, this study proposes a lightweight blood cell detection model based on YOLOv8n, named GPMB-YOLO. This model utilizes advanced lightweight strategies and PGhostC2f design, effectively reducing model complexity and enhancing detection speed. The integration of the simple parameter-free attention mechanism (SimAM) significantly enhances the model's feature extraction ability. Furthermore, we have designed a multidimensional attention-enhanced bidirectional feature pyramid network structure, MCA-BiFPN, optimizing the effect of multi-scale feature fusion. And use genetic algorithms for hyperparameter optimization, further improving detection accuracy. Experimental results validate the effectiveness of the GPMB-YOLO model, which realized a 3.2% increase in mean Average Precision (mAP) compared to the baseline YOLOv8n model and a marked reduction in model complexity. Furthermore, we have developed a blood cell detection system and deployed the model for application. This study serves as a valuable reference for the efficient detection of blood cells in medical images",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
254,Graph Attention Networks for Drug Combination Discovery: Targeting Pancreatic Cancer Genes with RAIN Protocol,"BackgroundMalignant neoplasm of the pancreas (MNP), a highly lethal illness with bleak outlook and few therapeutic avenues, entails numerous cellular transformations. These include irregular proliferation of ductal cells, activation of stellate cells, initiation of epithelial-to-mesenchymal transition, and changes in cell shape, movement, and attachment. Discovering potent drug cocktails capable of addressing the genetic and protein factors underlying pancreatic cancers development is formidable due to the diseases intricate and varied nature.  MethodIn this study, we introduce a fresh model utilizing Graph Attention Networks (GATs) to pinpoint potential drug pairings with synergistic effects for MNP, following the RAIN protocol. This protocol comprises three primary stages: Initially, employing Graph Neural Network (GNN) to suggest drug combinations for disease management by acquiring embedding vectors of drugs and proteins from a diverse knowledge graph encompassing various biomedical data types, such as drug-protein interactions, gene expression, and drug-target interactions. Subsequently, leveraging natural language processing to gather pertinent articles from clinical trials incorporating the previously recommended drugs. Finally, conducting network meta-analysis to assess the relative effectiveness of these drug combinations.  ResultWe implemented our approach on a network dataset featuring drugs and genes as nodes, connected by edges representing their respective p-values. Our GAT model identified Gemcitabine, Pancrelipase Amylase, and Octreotide as the optimal drug combination for targeting the human genes/proteins associated with this cancer. Subsequent scrutiny of clinical trials and literature confirmed the validity of our findings. Additionally, network meta-analysis confirmed the efficacy of these medications concerning the pertinent genes.  ConclusionBy employing GAT within the RAIN protocol, our approach represents a novel and efficient method for recommending prominent drug combinations to target proteins/genes associated with pancreatic cancer. This technique has the potential to aid healthcare professionals and researchers in identifying optimal treatments for patients while also unveiling underlying disease mechanisms.  HighlightsO_LIGraph Attention Networks (GATs) used to recommend drug combinations for pancreatic cancer C_LIO_LIRAIN protocol applied to extract relevant information from clinical trials and literature C_LIO_LIGemcitabine, Pancrelipase Amylase, and Octreotide identified as optimal drug combination C_LIO_LINetwork meta-analysis confirmed the effectiveness of the drug combination on gene targets C_LIO_LINovel and efficient method for drug discovery and disease mechanism elucidation C_LI    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=102 SRC=""FIGDIR/small/24302988v1_ufig1.gif"" ALT=""Figure 1""> View larger version (33K): org.highwire.dtl.DTLVardef@1cca51forg.highwire.dtl.DTLVardef@6caaa2org.highwire.dtl.DTLVardef@36a94aorg.highwire.dtl.DTLVardef@a46371_HPS_FORMAT_FIGEXP  M_FIG C_FIG",,medrxiv,,1,,,,,,,FALSE,TRUE,FALSE
255,"Graph-Based Fusion of Imaging, Genetic and Clinical Data for Degenerative Disease Diagnosis","Graph learning methods have achieved noteworthy performance in disease diagnosis due to their ability to represent unstructured information such as inter-subject relationships. While it has been shown that imaging, genetic and clinical data are crucial for degenerative disease diagnosis, existing methods rarely consider how best to use their relationships. How best to utilize information from imaging, genetic and clinical data remains a challenging problem. This study proposes a novel graph-based fusion (GBF) approach to meet this challenge. To extract effective imaging-genetic features, we propose an imaging-genetic fusion module which uses an attention mechanism to obtain modality-specific and joint representations within and between imaging and genetic data. Then, considering the effectiveness of clinical information for diagnosing degenerative diseases, we propose a multi-graph fusion module to further fuse imaging-genetic and clinical features, which adopts a learnable graph construction strategy and a graph ensemble method. Experimental results on two benchmarks for degenerative disease diagnosis (Alzheimers Disease Neuroimaging Initiative and Parkinson's Progression Markers Initiative) demonstrate its effectiveness compared to state-of-the-art graph-based methods. Our findings should help guide further development of graph-based models for dealing with imaging, genetic and clinical data",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
256,Harnessing explainable artificial intelligence for patient-to-clinical-trial matching: A proof-of-concept pilot study using phase I oncology trials,"This study aims to develop explainable AI methods for matching patients with phase 1 oncology clinical trials using Natural Language Processing (NLP) techniques to address challenges in patient recruitment for improved efficiency in drug development. A prototype system based on modern NLP techniques has been developed to match patient records with phase 1 oncology clinical trial protocols. Four criteria are considered for the matching: cancer type, performance status, genetic mutation, and measurable disease. The system outputs a summary matching score along with explanations of the evidence. The outputs of the AI system were evaluated against the ground truth matching results provided by the domain expert on a dataset of twelve synthesized dummy patient records and six clinical trial protocols. The system achieved a precision of 73.68%, sensitivity/recall of 56%, accuracy of 77.78%, and specificity of 89.36%. Further investigation into the misclassified cases indicated that ambiguity of abbreviation and misunderstanding of context are significant contributors to errors. The system found evidence of no matching for all false positive cases. To the best of our knowledge, no system in the public domain currently deploys an explainable AI-based approach to identify optimal patients for phase 1 oncology trials. This initial attempt to develop an AI system for patients and clinical trial matching in the context of phase 1 oncology trials showed promising results that are set to increase efficiency without sacrificing quality in patient-trial matching",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
257,Healthcare utilization and clinical characteristics of genetic epilepsy in electronic health records,"Understanding the clinical characteristics and medical treatment of individuals affected by genetic epilepsies is instrumental in guiding selection for genetic testing, defining the phenotype range of these rare disorders, optimizing patient care pathways and pinpointing unaddressed medical need by quantifying healthcare resource utilization. To date, a matched longitudinal cohort study encompassing the entire spectrum of clinical characteristics and medical treatment from childhood through adolescence has not been performed. We identified individuals with genetic and non-genetic epilepsies and onset at ages 0-5 years by linkage across the Cleveland Clinic Health System. We used natural language processing to extract medical terms and procedures from longitudinal electronic health records and tested for cross-sectional and temporal associations with genetic epilepsy. We implemented a two-stage design: in the discovery cohort, individuals were stratified as being 'likely genetic' or 'non-genetic' by a natural language processing algorithm, and controls did not receive genetic testing. The validation cohort consisted of cases with genetic epilepsy confirmed by manual chart review and an independent set of controls who received negative genetic testing. The discovery and validation cohorts consisted of 503 and 344 individuals with genetic epilepsy and matched controls, respectively. The median age at the first encounter was 0.1 years and 7.9 years at the last encounter, and the mean duration of follow-up was 8.2 years. We extracted 188,295 Unified Medical Language System annotations for statistical analysis across 9659 encounters. Individuals with genetic epilepsy received an earlier epilepsy diagnosis and had more frequent and complex encounters with the healthcare system. Notably, the highest enrichment of encounters compared with the non-genetic groups was found during the transition from paediatric to adult care. Our computational approach could validate established comorbidities of genetic epilepsies, such as behavioural abnormality and intellectual disability. We also revealed novel associations for genitourinary abnormalities (odds ratio 1.91, 95% confidence interval: 1.66-2.20, P = 6.16 × 10<sup>-19</sup>) linked to a spectrum of underrecognized epilepsy-associated genetic disorders. This case-control study leveraged real-world data to identify novel features associated with the likelihood of a genetic aetiology and quantified the healthcare utilization of genetic epilepsies compared with matched controls. Our results strongly recommend early genetic testing to stratify individuals into specialized care paths, thus improving the clinical management of people with genetic epilepsies",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
258,Healthcare utilization and clinical characteristics of genetic epilepsy syndromes: a longitudinal case-control study of electronic health records,"BackgroundUnderstanding disease progression, age-specific comorbidities, medical treatment patterns, and unmet needs can help improve the care pathway of individuals with rare genetic epilepsies. A matched longitudinal cohort study has not been performed for these variables from childhood to adolescence across the whole phenome.  MethodsWe identified individuals with likely genetic and non-genetic epilepsy syndromes and onset at ages 0-5 years by linkage across the Cleveland Clinic Health System. We used natural language processing to extract medical terms and procedures from longitudinal electronic health records (EHR) and tested for cross-sectional and temporal associations with genetic epilepsies.  FindingsWe identified 503 individuals with genetic epilepsy syndromes and matched controls with epilepsy that did not receive genetic testing. The median age at the first encounter was 0{middle dot}1 years, 7{middle dot}9 years at the last encounter, and the mean duration of follow-up was 8{middle dot}2 years. We extracted 188,295 Unified Medical Language System (UMLS) annotations for statistical analysis across 9,659 encounters. Individuals with genetic epilepsy syndromes received an earlier epilepsy diagnosis and had more frequent and complex encounters with the healthcare system. Notably, the highest enrichment of encounters compared to the non-genetic groups was found during the transition from paediatric to adult care. Our computational approach could validate established comorbidities of genetic epilepsies, such as behavioural abnormality and intellectual disability. We also revealed novel associations for genitourinary abnormalities (OR 1{middle dot}91, 95% CI: 1{middle dot}66-2{middle dot}19, p = 2{middle dot}39x10-19) linked to a spectrum of underrecognized genetic syndromes.  InterpretationThis study identified novel features associated with the likelihood of a genetic epilepsy syndrome and quantified the healthcare utilization of genetic epilepsies compared to matched controls with epilepsy who did not receive genetic testing. Our results strongly recommend early genetic testing to stratify individuals into specialized care paths, thus improving the clinical management of people with genetic epilepsies.  FundingNot applicable",,medrxiv,,1,,,,,,,FALSE,TRUE,FALSE
259,High clinical burden of classical homocystinuria in the United States: a retrospective analysis,"Classical homocystinuria (HCU) is a rare genetic metabolic disorder resulting in elevated homocysteine and methionine levels. The clinical characteristics and associated complications of HCU are well documented. However, there is limited published research on the clinical burden of patients with HCU, especially stratified by total homocysteine (tHcy) levels. This study aimed to describe the overall clinical burden of patients with HCU in the United States and key clinical events by tHcy levels using administrative claims data. This non-interventional retrospective cohort analysis from January 01, 2016, through September 30, 2021, used Optum's de-identified Market Clarity Data. Patients who had 1 or more International Classification of Diseases, Tenth Revision code for homocystinuria (E72.11) or the signs, disease, and symptoms term homocystinuria in the natural language processing dataset were included. To obtain a study population most likely to have HCU, stratifications by tHcy levels, clinical characteristics, and phenotypic expressions were applied to refine the cohort. Included patients were then stratified by highest tHcy level. Clinical burden was measured by category of HCU-related events. Descriptive statistics were reported. Six hundred thirty-three patients met the inclusion criteria, and 601 patients had a tHcy level: < 50 µM (n = 278), 50 to < 100 µM (n = 212), and ≥ 100 µM (n = 111). Among the 601 patients with a tHcy level, almost one-half (n = 297, 49.4%) had at least one thrombotic/thromboembolic, skeletal, ocular, or neurological event and 14.1% (n = 85) had multiple events. Thrombotic/thromboembolic events (n = 186, 30.9%) were the most common type of events, followed by skeletal (n = 100, 16.6%), ocular (n = 63, 10.5%), and neurological events (n = 50, 8.3%). During follow-up, 5.7% (n = 34) of the patients died. All events assessed were more prevalent in the 50 to < 100 µM group and ≥ 100 µM group compared with those in the < 50 µM group. As has been believed, patients with tHcy ≥ 100 µM carried a substantial clinical burden, but the burden is also very high in those whose levels were ≥ 50 µM. Thrombotic/thromboembolic events were more common than skeletal, ocular, or neurological events. Meaningfully lowered tHcy levels may help to reduce significant clinical events",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
260,Identification of pancreatic cancer risk factors from clinical notes using natural language processing,"Screening for pancreatic ductal adenocarcinoma (PDAC) is considered in high-risk individuals (HRIs) with established PDAC risk factors, such as family history and germline mutations in PDAC susceptibility genes. Accurate assessment of risk factor status is provider knowledge-dependent and requires extensive manual chart review by experts. Natural Language Processing (NLP) has shown promise in automated data extraction from the electronic health record (EHR). We aimed to use NLP for automated extraction of PDAC risk factors from unstructured clinical notes in the EHR. We first developed rule-based NLP algorithms to extract PDAC risk factors at the document-level, using an annotated corpus of 2091 clinical notes. Next, we further improved the NLP algorithms using a cohort of 1138 patients through patient-level training, validation, and testing, with comparison against a pre-specified reference standard. To minimize false-negative results we prioritized algorithm recall. In the test set (n = 807), the NLP algorithms achieved a recall of 0.933, precision of 0.790, and F<sub>1</sub>-score of 0.856 for family history of PDAC. For germline genetic mutations, the algorithm had a high recall of 0.851, while precision and F<sub>1</sub>-score were lower at 0.350 and 0.496 respectively. Most false positives for germline mutations resulted from erroneous recognition of tissue mutations. Rule-based NLP algorithms applied to unstructured clinical notes are highly sensitive for automated identification of PDAC risk factors. Further validation in a large primary-care patient population is warranted to assess real-world utility in identifying HRIs for pancreatic cancer screening",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
261,Identifying Family Structures from Obituaries and Matching them to Patients in an Electronic Heath Record,"Family data is a valuable data source in bioinformatic research. This is because family members often share common genetic and environmental exposures. Collecting this family data is traditionally very labor intensive but advances in electronic health record (EHR) data mining has proven useful when identifying pedigrees linked to longitudinal health histories. These are called e-pedigrees. Unfortunately, e-pedigrees tend to miss the oldest generations who inherently have the longest and richest health histories. A good source of family data from older generations includes obituaries, as they have a formulaic nature making them a good candidate for natural language processing that can extract relationships to the decedent. While there have been several studies on obtaining such data from obituaries, we demonstrate for the first-time approaches that tie that information to an EHR. NLP extraction resulted in 8,166,534 family members being abstracted from 567,279 obituaries published in the state of Wisconsin. After matching decedent and family members to patients in the EHR, we identified 109,365 unique patients that were put in 34,158 pedigrees. The largest pedigree consisted of 21 individuals. Heritability of adult height was quantified (H <sup>2</sup> = 0.51 +- .04, P=< 1.00e-07) demonstrating this data's use in genetic research. The heritability data, coupled with overlapping data in a biobank, suggested 80% - 90% of familial relationships were accurately defined. The totality of these findings demonstrate obituaries with the oldest generations can be highly informative for bioinformatic research. Code is available on GitHub at https://github.com/jgmayer672/ObituaryNLP 
==========
MotivationFamily data is a valuable data source in bioinformatic research. This is because family members often share common genetic and environmental exposures. Collecting this family data is traditionally very labor intensive but advances in electronic health record (EHR) data mining has proven useful when identifying pedigrees linked to longitudinal health histories. These are called e-pedigrees. Unfortunately, e-pedigrees tend to miss the oldest generations who inherently have the longest and richest health histories. A good source of family data from older generations includes obituaries, as they have a formulaic nature making them a good candidate for natural language processing that can extract relationships to the decedent. While there have been several studies on obtaining such data from obituaries, we demonstrate for the first-time approaches that tie that information to an EHR.  ResultsNLP extraction resulted in 8,166,534 family members being abstracted from 567,279 obituaries published in the state of Wisconsin. After matching decedent and family members to patients in the EHR, we identified 109,365 unique patients that were put in 34,158 pedigrees. The largest pedigree consisted of 21 individuals. Heritability of adult height was quantified (H2= 0.51 +- .04, P=< 1.00e-07) demonstrating this datas use in genetic research. The heritability data, coupled with overlapping data in a biobank, suggested 80% - 90% of familial relationships were accurately defined. The totality of these findings demonstrate obituaries with the oldest generations can be highly informative for bioinformatic research.  Availability and ImplementationCode is available on GitHub at https://github.com/jgmayer672/ObituaryNLP",,"PubMed,biorxiv",,1,,,,,,,FALSE,TRUE,FALSE
262,"Implementation of a culturally competent APOL1 genetic testing programme into living donor evaluation: A two-site, non-randomised, pre-post trial design","While living donor (LD) kidney transplantation is the optimal treatment for patients with kidney failure, LDs assume a higher risk of future kidney failure themselves. LDs of African ancestry have an even greater risk of kidney failure post-donation than White LDs. Because evidence suggests that Apolipoprotein L1 (APOL1) risk variants contribute to this greater risk, transplant nephrologists are increasingly using APOL1 genetic testing to evaluate LD candidates of African ancestry. However, nephrologists do not consistently perform genetic counselling with LD candidates about APOL1 due to a lack of knowledge and skill in counselling. Without proper counselling, APOL1 testing will magnify LD candidates' decisional conflict about donating, jeopardising their informed consent. Given cultural concerns about genetic testing among people of African ancestry, protecting LD candidates' safety is essential to improve informed decisions about donating. Clinical 'chatbots', mobile apps that provide genetic information to patients, can improve informed treatment decisions. No chatbot on APOL1 is available and no nephrologist training programmes are available to provide culturally competent counselling to LDs about APOL1. Given the shortage of genetic counsellors, increasing nephrologists' genetic literacy is critical to integrating genetic testing into practice. Using a non-randomised, pre-post trial design in two transplant centres (Chicago, IL, and Washington, DC), we will evaluate the effectiveness of culturally competent APOL1 testing, chatbot and counselling on LD candidates' decisional conflict about donating, preparedness for decision-making, willingness to donate and satisfaction with informed consent and longitudinally evaluate the implementation of this intervention into clinical practice using the <u>R</u>each, <u>E</u>ffectiveness, <u>A</u>doption, <u>I</u>mplementation and <u>M</u>aintenance framework. This study will create a model for APOL1 testing of LDs of African ancestry, which can be implemented nationally via implementation science approaches. APOL1 will serve as a model for integrating culturally competent genetic testing into transplant and other practices to improve informed consent. This study involves human participants and was approved by Northwestern University IRB (STU00214038). Participants gave informed consent to participate in the study before taking part. ClinicalTrials.gov Identifier: NCT04910867. Registered 8 May 2021, https://register. gov/prs/app/action/SelectProtocol?sid=S000AWZ6&selectaction=Edit&uid=U0001PPF&ts=7&cx=-8jv7m2 ClinicalTrials.gov Identifier: NCT04999436. Registered 5 November 2021, https://register. gov/prs/app/action/SelectProtocol?sid=S000AYWW&selectaction=Edit&uid=U0001PPF&ts=11&cx=9tny7v",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
263,Improving Automated Deep Phenotyping Through Large Language Models Using Retrieval Augmented Generation,"Diagnosing rare genetic disorders relies on precise phenotypic and genotypic analysis, with the Human Phenotype Ontology (HPO) providing a standardized language for capturing clinical phenotypes. Traditional HPO tools, such as Doc2HPO and ClinPhen, employ concept recognition to automate phenotype extraction but struggle with incomplete phenotype assignment, often requiring intensive manual review. While large language models (LLMs) hold promise for more context-driven phenotype extraction, they are prone to errors and ""hallucinations,"" making them less reliable without further refinement. We present RAG-HPO, a Python-based tool that leverages Retrieval-Augmented Generation (RAG) to elevate LLM accuracy in HPO term assignment, bypassing the limitations of baseline models while avoiding the time and resource intensive process of fine-tuning. RAG-HPO integrates a dynamic vector database, allowing real-time retrieval and contextual matching. The high-dimensional vector database utilized by RAG-HPO includes >54,000 phenotypic phrases mapped to HPO IDs, derived from the HPO database and supplemented with additional validated phrases. The RAG-HPO workflow uses an LLM to first extract phenotypic phrases that are then matched via semantic similarity to entries within a vector database before providing best term matches back to the LLM as context for final HPO term assignment. A benchmarking dataset of 120 published case reports with 1,792 manually-assigned HPO terms was developed, and the performance of RAG-HPO measured against existing published tools Doc2HPO, ClinPhen, and FastHPOCR. In evaluations, RAG-HPO, powered by Llama-3 70B and applied to a set of 120 case reports, achieved a mean precision of 0.84, recall of 0.78, and an F1 score of 0.80-significantly surpassing conventional tools (p<0.00001). False positive HPO term identification occurred for 15.8% (256/1,624) of terms, of which only 2.7% (7/256) represented hallucinations, and 33.6% (86/256) unrelated terms; the remainder of false positives (63.7%, 163/256) were relative terms of the target term. RAG-HPO is a user-friendly, adaptable tool designed for secure evaluation of clinical text and outperforms standard HPO-matching tools in precision, recall, and F1. Its enhanced precision and recall represent a substantial advancement in phenotypic analysis, accelerating the identification of genetic mechanisms underlying rare diseases and driving progress in genetic research and clinical genomics
==========
BackgroundDiagnosing rare genetic disorders relies on precise phenotypic and genotypic analysis, with the Human Phenotype Ontology (HPO) providing a standardized language for capturing clinical phenotypes. Traditional HPO tools, such as Doc2HPO and ClinPhen, employ concept recognition to automate phenotype extraction but struggle with incomplete phenotype assignment, often requiring intensive manual review. While large language models (LLMs) hold promise for more context-driven phenotype extraction, they are prone to errors and ""hallucinations,"" making them less reliable without further refinement. We present RAG-HPO, a Python-based tool that leverages Retrieval-Augmented Generation (RAG) to elevate LLM accuracy in HPO term assignment, bypassing the limitations of baseline models while avoiding the time and resource intensive process of fine-tuning. RAG-HPO integrates a dynamic vector database, allowing real-time retrieval and contextual matching.  MethodsThe high-dimensional vector database utilized by RAG-HPO includes >54,000 phenotypic phrases mapped to HPO IDs, derived from the HPO database and supplemented with additional validated phrases. The RAG-HPO workflow uses an LLM to first extract phenotypic phrases that are then matched via semantic similarity to entries within a vector database before providing best term matches back to the LLM as context for final HPO term assignment. A benchmarking dataset of 120 published case reports with 1,792 manually-assigned HPO terms was developed, and the performance of RAG-HPO measured against existing published tools Doc2HPO, ClinPhen, and FastHPOCR.  ResultsIn evaluations, RAG-HPO, powered by Llama-3 70B and applied to a set of 120 case reports, achieved a mean precision of 0.84, recall of 0.78, and an F1 score of 0.80--significantly surpassing conventional tools (p<0.00001). False positive HPO term identification occurred for 15.8% (256/1,624) of terms, of which only 2.7% (7/256) represented hallucinations, and 33.6% (86/256) unrelated terms; the remainder of false positives (63.7%, 163/256) were relative terms of the target term.  ConclusionsRAG-HPO is a user-friendly, adaptable tool designed for secure evaluation of clinical text and outperforms standard HPO-matching tools in precision, recall, and F1. Its enhanced precision and recall represent a substantial advancement in phenotypic analysis, accelerating the identification of genetic mechanisms underlying rare diseases and driving progress in genetic research and clinical genomics",,"PubMed,medrxiv",,1,,,,,,,FALSE,TRUE,FALSE
264,Improving performance in colorectal cancer histology decomposition using deep and ensemble machine learning,"In routine colorectal cancer management, histologic samples stained with hematoxylin and eosin are commonly used. Nonetheless, their potential for defining objective biomarkers for patient stratification and treatment selection is still being explored. The current gold standard relies on expensive and time-consuming genetic tests. However, recent research highlights the potential of convolutional neural networks (CNNs) to facilitate the extraction of clinically relevant biomarkers from these readily available images. These CNN-based biomarkers can predict patient outcomes comparably to golden standards, with the added advantages of speed, automation, and minimal cost. The predictive potential of CNN-based biomarkers fundamentally relies on the ability of CNNs to accurately classify diverse tissue types from whole slide microscope images. Consequently, enhancing the accuracy of tissue class decomposition is critical to amplifying the prognostic potential of imaging-based biomarkers. This study introduces a hybrid deep transfer learning and ensemble machine learning model that improves upon previous approaches, including a transformer and neural architecture search baseline for this task. We employed a pairing of the EfficientNetV2 architecture with a random forest classification head. Our model achieved 96.74% accuracy (95% CI: 96.3%-97.1%) on the external test set and 99.89% on the internal test set. Recognizing the potential of these models in the task, we have made them publicly available",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
265,Innovative Implementation Strategies for Familial Hypercholesterolemia Cascade Testing: The Impact of Genetic Counseling,"The IMPACT-FH study implemented strategies (packet, chatbot, direct contact) to promote family member cascade testing for familial hypercholesterolemia (FH). We evaluated the impact of genetic counseling (GC) on medical outcomes, strategy selection, and cascade testing. Probands (i.e., patients with FH) were recommended to complete GC and select sharing strategies. Comparisons were performed for both medical outcomes and strategy selection between probands with or without GC. GEE models for Poisson regression were used to examine the relationship between proband GC completion and first-degree relative (FDR) cascade testing. Overall, 46.3% (81/175) of probands completed GC. Probands with GC had a median LDL-C reduction of -13.0 mg/dL (-61.0, 4.0) versus -1.0 mg/dL (-16.0, 17.0) in probands without GC (p = 0.0054). Probands with and without GC selected sharing strategies for 65.3% and 40.3% of FDRs, respectively (p < 0.0001). Similarly, 27.1% of FDRs of probands with GC completed cascade testing, while 12.0% of FDRs of probands without GC completed testing (p = 0.0043). Direct contact was selected for 47 relatives in total and completed for 39, leading to the detection of 18 relatives with FH. Proband GC was associated with improved medical outcomes and increased FDR cascade testing. Direct contact effectively identified FH cases for the subset who participated",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
266,"Integrating clinical pharmacology and artificial intelligence: potential benefits, challenges, and role of clinical pharmacologists","The integration of artificial intelligence (AI) into clinical pharmacology could be a potential approach for accelerating drug discovery and development, improving patient care, and streamlining medical research processes. We reviewed the current state of AI applications in clinical pharmacology, focusing on drug discovery and development, precision medicine, pharmacovigilance, and other ventures. Key AI applications in clinical pharmacology are examined, including machine learning, natural language processing, deep learning, and reinforcement learning etc. Additionally, the evolving role of clinical pharmacologists, ethical considerations, and challenges in implementing AI in clinical pharmacology are discussed. The AI could be instrumental in accelerating drug discovery, predicting drug safety and efficacy, and optimizing clinical trial designs. It can play a vital role in precision medicine by helping in personalized drug dosing, treatment selection, and predicting drug response based on genetic, clinical, and environmental factors. The role of AI in pharmacovigilance, such as signal detection and adverse event prediction, is also promising. The collaboration between clinical pharmacologists and AI experts also poses certain ethical and practical challenges. Clinical pharmacologists can be instrumental in shaping the future of AI-driven clinical pharmacology and contribute to the improvement of healthcare systems",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
267,Integrating large scale genetic and clinical information to predict cases of heart failure,"BackgroundHeart failure (HF) is a major cause of death globally. Prediction of HF risk and early initiation of treatment could mitigate disease progression.  ObjectivesThe study aimed to improve the prediction accuracy of HF by integrating genome-wide association studies (GWAS)- and electronic health records (EHR)-derived risk scores.  MethodsWe previously performed the largest HF GWAS to date within the Global Biobank Meta-analysis Initiative to create a polygenic risk score (PRS). To extract clinical information from high-dimensional EHR data, we treated diagnosis codes as  words and leveraged natural language processing techniques to create a clinical risk score (ClinRS). Our method first learned code co-occurrence patterns and extracted 350 latent phenotypes (low-dimensional features) representing EHR codes, then used coefficients from regression of HF on the latent phenotypes in a training set as weights to calculate patient ClinRS in a validation set. Model performances were compared between baseline (age and sex) model and models with risk scores added: 1) PRS, 2) ClinRS, and 3) PRS+ClinRS. We further compared the proposed models with Atherosclerosis Risk in Communities (ARIC) heart failure risk score.  ResultsResults showed that PRS and ClinRS were each able to predict HF outcomes significantly better than the baseline model, up to eight years prior to HF diagnosis. By including both PRS and ClinRS in the model, we achieved superior performance in predicting HF up to ten years prior to HF diagnosis, two years earlier than using a single risk predictor alone. Additionally, we found that ClinRS performed significantly better than ARIC model at one year prior to disease diagnosis.  ConclusionsWe demonstrate the additive power of integrating GWAS- and EHR-derived risk scores to predict HF cases prior to diagnosis",,medrxiv,,1,,,,"Natural language processing (NOT transformers), polygenic risk scores (PRS); ML Task: Prediction of heart failure using genetic and clinical data.",Heart failure prediction; genomic data (GWAS) and electronic health records (EHR).,"Combines GWAS and EHR-based scores to predict heart failure, improving early detection.",FALSE,TRUE,FALSE
268,Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics,"Accurate molecular quantification is essential for advancing research and diagnostics in fields such as infectious diseases, cancer biology, and genetic disorders. Droplet digital PCR (ddPCR) has emerged as a gold standard for achieving absolute quantification. While computational ddPCR technologies have advanced significantly, achieving automatic interpretation and consistent adaptability across diverse operational environments remains a challenge. To address these limitations, we introduce the intelligent interpretable droplet digital PCR (I2ddPCR) assay, a comprehensive framework integrating front-end predictive models (for droplet segmentation and classification) with GPT-4o multimodal large language model (MLLM, for context-aware explanations and recommendations) to automate and enhance ddPCR image analysis. This approach surpasses the state-of-the-art models, affording 99.05% accuracy in processing complex ddPCR images containing over 300 droplets per image with varying signal-to-noise ratios (SNRs). By combining specialized neural networks and large language models, the I2ddPCR assay offers a robust and adaptable solution for absolute molecular quantification, achieving a sensitivity capable of detecting low-abundance targets as low as 90.32 copies/{\mu}L. Furthermore, it improves model's transparency through detailed explanation and troubleshooting guidance, empowering users to make informed decisions. This innovative framework has the potential to benefit molecular diagnostics, disease research, and clinical applications, especially in resource-constrained settings",,arXiv,,1,,,,,,,FALSE,TRUE,FALSE
269,Is artificial intelligence getting too much credit in medical genetics?,"Artificial intelligence has lately proven useful in the field of medical genetics. It is already being used to interpret genome sequences and diagnose patients based on facial recognition. More recently, large-language models (LLMs) such as ChatGPT have been tested for their capacity to provide medical genetics information. It was found that ChatGPT performed similarly to human respondents in factual and critical thinking questions, albeit with reduced accuracy in the latter. In particular, ChatGPT's performance in questions related to calculating the recurrence risk was dismal, despite only having to deal with a single disease. To see if challenging ChatGPT with more difficult problems may reveal its flaws and their bases, it was asked to solve recurrence risk problems dealing with two diseases instead of one. Interestingly, it managed to correctly understand the mode of inheritance of recessive diseases, yet it incorrectly calculated the probability of having a healthy child. Other LLMs were also tested and showed similar noise. This highlights a major limitation for clinical use. While this shortcoming may be solved in the near future, LLMs may not be ready yet to be used as an effective clinical tool in communicating medical genetics information",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
270,Knowledge Graph-based Thought: a knowledge graph enhanced LLMs framework for pan-cancer question answering,"BackgroundIn recent years, Large Language Models (LLMs) have shown promise in various domains, notably in biomedical sciences. However, their real-world application is often limited by issues like erroneous outputs and hallucinatory responses.  ResultsWe developed the Knowledge Graph-based Thought (KGT) framework, an innovative solution that integrates LLMs with Knowledge Graphs (KGs) to improve their initial responses by utilizing verifiable information from KGs, thus significantly reducing factual errors in reasoning. The KGT framework demonstrates strong adaptability and performs well across various open-source LLMs. Notably, KGT can facilitate the discovery of new uses for existing drugs through potential drug-cancer associations, and can assist in predicting resistance by analyzing relevant biomarkers and genetic mechanisms. To evaluate the Knowledge Graph Question Answering (KGQA) task within biomedicine, we utilize a pan-cancer knowledge graph to develop a pan-cancer question answering benchmark, named the Pan-cancer Question Answering (PcQA).  ConclusionsThe KGT framework substantially improves the accuracy and utility of LLMs in the biomedical field. This study serves as a proof-of-concept, demonstrating its exceptional performance in biomedical question answering.  Key PointsO_LIWe introduce a framework combining LLMs with KGs to improve factual accuracy in LLM reasoning. C_LIO_LIOur system is a flexible architecture that seamlessly integrates various LLMs. C_LIO_LIUtilizing a pan-cancer knowledge graph, we have proposed the first KGQA benchmark in the field of biomedicine. C_LIO_LICase studies reveal our method enhanced LLMs in addressing biomedical challenges such as drug repositioning, resistance research, individualized treatment, and biomarker analysis. C_LIO_LIThe method performs favorably in comparison to existing methods. C_LI",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
271,Knowledge graph-based thought: a knowledge graph-enhanced LLM framework for pan-cancer question answering,"In recent years, large language models (LLMs) have shown promise in various domains, notably in biomedical sciences. However, their real-world application is often limited by issues like erroneous outputs and hallucinatory responses. We developed the knowledge graph-based thought (KGT) framework, an innovative solution that integrates LLMs with knowledge graphs (KGs) to improve their initial responses by utilizing verifiable information from KGs, thus significantly reducing factual errors in reasoning. The KGT framework demonstrates strong adaptability and performs well across various open-source LLMs. Notably, KGT can facilitate the discovery of new uses for existing drugs through potential drug-cancer associations and can assist in predicting resistance by analyzing relevant biomarkers and genetic mechanisms. To evaluate the knowledge graph question answering task within biomedicine, we utilize a pan-cancer knowledge graph to develop a pan-cancer question answering benchmark, named pan-cancer question answering. The KGT framework substantially improves the accuracy and utility of LLMs in the biomedical field. This study serves as a proof of concept, demonstrating its exceptional performance in biomedical question answering",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
272,Latent Diffusion For Conditional Generation of Molecules,"AO_SCPLOWBSTRACTC_SCPLOWDesigning a small molecule therapeutic is a challenging multi-parameter optimization problem. Key properties, such as potency, selectivity, bioavailability, and safety must be jointly optimized to deliver an effective clinical candidate. We present COATI-LDM, a novel application of latent diffusion models to the conditional generation of property-optimized, drug-like small molecules. Diffusive generation of latent molecular encodings, rather than direct diffusive generation of molecular structures, offers an appealing way to handle the small and mismatched datasets that are common for molecular properties. We benchmark various diffusion guidance schemes and sampling methods against a pre-trained autoregressive transformer and genetic algorithms to evaluate control over potency, expert preference, and various physicochemical properties. We show that conditional diffusion allows control over the properties of generated molecules, with practical and performance advantages over competing methods. We also apply the recently introduced idea of particle guidance to enhance sample diversity. We prospectively survey a panel of medicinal chemists and determine that we can conditionally generate molecules that align with their preferences via a learned preference score. Finally, we present a partial diffusion method for the local optimization of molecular properties starting from a seed molecule. Conditional generation of small molecules using latent diffusion models on molecular encodings provides a highly practical and flexible alternative to prior molecular generation schemes",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
273,Leveraging hierarchical structures for genetic block interaction studies using the hierarchical transformer,"Initially introduced in 1909 by William Bateson, classic epistasis (genetic variant interaction) refers to the phenomenon that one variant prevents another variant from a different locus from manifesting its effects. The potential effects of genetic variant interactions on complex diseases have been recognized for the past decades. Moreover, It has been studied and demonstrated that leveraging the combined SNP effects within the genetic block can significantly increase calculation power, reducing background noise, ultimately leading to novel epistasis discovery that the single SNP statistical epistasis study might overlook. However, it is still an open question how we can best combine gene structure representation modelling and interaction learning into an end-to-end model for gene interaction searching. Here, in the current study, we developed a neural genetic block interaction searching model that can effectively process large SNP chip inputs and output the potential genetic block interaction heatmap. Our model augments a previously published hierarchical transformer architecture (Liu and Lapata, 2019) with the ability to model genetic blocks. The cross-block relationship mapping was achieved via a hierarchical attention mechanism which allows the sharing of information regarding specific phenotypes, as opposed to simple unsupervised dimensionality reduction methods e.g. PCA. Results on both simulation and UK Biobank studies show our model brings substantial improvements compared to traditional exhaustive searching and neural network methods
==========
1.Initially introduced in 1909 by William Bateson, classic epistasis (genetic variant interaction) refers to the phenomenon that one variant prevents another variant from a different locus from manifesting its effects. The potential effects of genetic variant interactions on complex diseases have been recognized for the past decades. Moreover, It has been studied and demonstrated that leveraging the combined SNP effects within the genetic block can significantly increase calculation power, reducing background noise, ultimately leading to novel epistasis discovery that the single SNP statistical epistasis study might overlook. However, it is still an open question how we can best combine gene structure representation modelling and interaction learning into an end-to-end model for gene interaction searching. Here, in the current study, we developed a neural genetic block interaction searching model that can effectively process large SNP chip inputs and output the potential genetic block interaction heatmap. Our model augments a previously published hierarchical transformer architecture (Liu and Lapata, 2019) with the ability to model genetic blocks. The cross-block relationship mapping was achieved via a hierarchical attention mechanism which allows the sharing of information regarding specific phenotypes, as opposed to simple unsupervised dimensionality reduction methods e.g. PCA. Results on both simulation and UK Biobank studies show our model brings substantial improvements compared to traditional exhaustive searching and neural network methods",,"PubMed,medrxiv",,1,,,,,,,FALSE,TRUE,FALSE
275,Linguistic profile automated characterisation in pluripotential clinical high-risk mental state (CHARMS) conditions: methodology of a multicentre observational study,"Language is usually considered the social vehicle of thought in intersubjective communications. However, the relationship between language and high-order cognition seems to evade this canonical and unidirectional description (ie, the notion of language as a simple means of thought communication). In recent years, clinical high at-risk mental state (CHARMS) criteria (evolved from the Ultra-High-Risk paradigm) and the introduction of the Clinical Staging system have been proposed to address the dynamicity of early psychopathology. At the same time, natural language processing (NLP) techniques have greatly evolved and have been successfully applied to investigate different neuropsychiatric conditions. The combination of at-risk mental state paradigm, clinical staging system and automated NLP methods, the latter applied on spoken language transcripts, could represent a useful and convenient approach to the problem of early psychopathological distress within a transdiagnostic risk paradigm. Help-seeking young people presenting psychological distress (CHARMS+/- and Clinical Stage 1a or 1b; target sample size for both groups n=90) will be assessed through several psychometric tools and multiple speech analyses during an observational period of 1-year, in the context of an Italian multicentric study. Subjects will be enrolled in different contexts: Department of Neuroscience, Rehabilitation, Ophthalmology, Genetics, Maternal and Child Health (DINOGMI), Section of Psychiatry, University of Genoa-IRCCS Ospedale Policlinico San Martino, Genoa, Italy; Mental Health Department-territorial mental services (ASL 3-Genoa), Genoa, Italy; and Mental Health Department-territorial mental services (AUSL-Piacenza), Piacenza, Italy. The conversion rate to full-blown psychopathology (CS 2) will be evaluated over 2 years of clinical observation, to further confirm the predictive and discriminative value of CHARMS criteria and to verify the possibility of enriching them with several linguistic features, derived from a fine-grained automated linguistic analysis of speech. The methodology described in this study adheres to ethical principles as formulated in the Declaration of Helsinki and is compatible with International Conference on Harmonization (ICH)-good clinical practice. The research protocol was reviewed and approved by two different ethics committees (CER Liguria approval code: 591/2020-id.10993; Comitato Etico dell'Area Vasta Emilia Nord approval code: 2022/0071963). Participants will provide their written informed consent prior to study enrolment and parental consent will be needed in the case of participants aged less than 18 years old. Experimental results will be carefully shared through publication in peer-reviewed journals, to ensure proper data reproducibility. DOI:10.17605/OSF.IO/BQZTN",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
276,LumVertCancNet: A novel 3D lumbar vertebral body cancellous bone location and segmentation method based on hybrid Swin-transformer,"Lumbar vertebral body cancellous bone location and segmentation is crucial in an automated lumbar spine processing pipeline. Accurate and reliable analysis of lumbar spine image is expected to advantage practical medical diagnosis and population-based analysis of bone strength. However, the design of automated algorithms for lumbar spine processing is demanding due to significant anatomical variations and scarcity of publicly available data. In recent years, convolutional neural network (CNN) and vision transformers (Vits) have been the de facto standard in medical image segmentation. Although adept at capturing global features, the inherent bias of locality and weight sharing of CNN constrains its capacity to model long-range dependency. In contrast, Vits excel at long-range dependency modeling, but they may not generalize well with limited datasets due to the lack of inductive biases inherent to CNN. In this paper, we propose a deep learning-based two-stage coarse-to-fine solution to address the problem of automatic location and segmentation of lumbar vertebral body cancellous bone. Specifically, in the first stage, a Swin-transformer based model is applied to predict the heatmap of lumbar vertebral body centroids. Considering the characteristic anatomical structure of lumbar spine, we propose a novel loss function called LumAnatomy loss, which enforces the order and bend of the predicted vertebral body centroids. To inherit the excellence of CNN and Vits while preventing their respective limitations, in the second stage, we propose an encoder-decoder network to segment the identified lumbar vertebral body cancellous bone, which consists of two parallel encoders, i.e., a Swin-transformer encoder and a CNN encoder. To enhance the combination of CNNs and Vits, we propose a novel multi-scale attention feature fusion module (MSA-FFM), which address issues that arise when fusing features given at different encoders. To tackle the issue of lack of data, we raise the first large-scale lumbar vertebral body cancellous bone segmentation dataset called LumVBCanSeg containing a total of 185 CT scans annotated at voxel level by 3 physicians. Extensive experimental results on the LumVBCanSeg dataset demonstrate the proposed algorithm outperform other state-of-the-art medical image segmentation methods. The data is publicly available at: https://zenodo.org/record/8181250. The implementation of the proposed method is available at: https://github.com/sia405yd/LumVertCancNet",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
277,Machine learning-based donor permission extraction from informed consent documents,"With more clinical trials are offering optional participation in the collection of bio-specimens for biobanking comes the increasing complexity of requirements of informed consent forms. The aim of this study is to develop an automatic natural language processing (NLP) tool to annotate informed consent documents to promote biorepository data regulation, sharing, and decision support. We collected informed consent documents from several publicly available sources, then manually annotated them, covering sentences containing permission information about the sharing of either bio-specimens or donor data, or conducting genetic research or future research using bio-specimens or donor data. We evaluated a variety of machine learning algorithms including random forest (RF) and support vector machine (SVM) for the automatic identification of these sentences. 120 informed consent documents containing 29,204 sentences were annotated, of which 1250 sentences (4.28%) provide answers to a permission question. A support vector machine (SVM) model achieved a F-1 score of 0.95 on classifying the sentences when using a gold standard, which is a prefiltered corpus containing all relevant sentences. This study provides the feasibility of using machine learning tools to classify permission-related sentences in informed consent documents",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
278,Modeling cancer dependency with deep graph models,"A fundamental premise for precision oncology is a catalog of diverse actionable targets that could enable personalized treatment. Large scale Genome-wide lost-of-function screens such as cancer dependency map have systematically identified single gene vulnerabilities in numerous cell lines. However, it remains challenging to scale such analyses to many clinical samples and untangle molecular networks underlying observed vulnerabilities. We developed a deep learning framework, DepGPS, combing graph neural networks with transformers to model the network interactions underlying tumor vulnerabilities. Our model demonstrated an improved ability to predict context-specific vulnerabilities over existing models and showed a higher responsiveness in perturbation analysis. Furthermore, perturbation induced dependency changes by our model demonstrated utility to support context-aware identification of synthetic lethal genes. Overall, our model represents a valuable tool to extend tumor vulnerability analyses to broader range of subjects and could help to decipher molecular networks dictating context-specific tumor vulnerabilities",,biorxiv,,1,,,,Combines Graph Neural Networks (GNN) and transformers.,"Precision oncology, focusing on identifying cancer vulnerabilities and modeling molecular networks for personalized treatment.",transformer-based models with GNNs to predict tumor vulnerabilities and enhance personalized cancer therapy strategies.,FALSE,TRUE,FALSE
279,Mouse-Geneformer: A Deep Learning Model for Mouse Single-Cell Transcriptome and Its Cross-Species Utility,"Deep learning techniques are increasingly utilized to analyze large-scale single-cell RNA sequencing (scRNA-seq) data, offering valuable insights from complex transcriptome datasets. Geneformer, a pre-trained model using a Transformer Encoder architecture and human scRNA-seq datasets, has demonstrated remarkable success in human transcriptome analysis. However, given the prominence of the mouse, Mus musculus, as a primary mammalian model in biological and medical research, there is an acute need for a mouse-specific version of Geneformer. In this study, we developed a mouse-specific Geneformer (mouse-Geneformer) by constructing a large transcriptome dataset consisting of 21 million mouse scRNA-seq profiles and pre-training Geneformer on this dataset. The mouse-Geneformer effectively models the mouse transcriptome and, upon fine-tuning for downstream tasks, enhances the accuracy of cell type classification. In silico perturbation experiments using mouse-Geneformer successfully identified disease-causing genes that have been validated in in vivo experiments. These results demonstrate the feasibility of analyzing mouse data with mouse-Geneformer and highlight the robustness of the Geneformer architecture, applicable to any species with large-scale transcriptome data available. Furthermore, we found that mouse-Geneformer can analyze human transcriptome data in a cross-species manner. After the ortholog-based gene name conversion, the analysis of human scRNA-seq data using mouse-Geneformer, followed by fine-tuning with human data, achieved cell type classification accuracy comparable to that obtained using the original human Geneformer. In in silico simulation experiments using human disease models, we obtained results similar to human-Geneformer for the myocardial infarction model but only partially consistent results for the COVID-19 model, a trait unique to humans (laboratory mice are not susceptible to SARS-CoV-2). These findings suggest the potential for cross-species application of the Geneformer model while emphasizing the importance of species-specific models for capturing the full complexity of disease mechanisms. Despite the existence of the original Geneformer tailored for humans, human research could benefit from mouse-Geneformer due to its inclusion of samples that are ethically or technically inaccessible for humans, such as embryonic tissues and certain disease models. Additionally, this cross-species approach indicates potential use for non-model organisms, where obtaining large-scale single-cell transcriptome data is challenging.  Author SummaryResearchers have developed Geneformer, a powerful tool that utilizes advanced deep learning techniques and large-scale single-cell transcriptome data to analyze human cell genetic activity. However, given the extensive use of mice (Mus musculus) in medical and biology research, there is a need for a similar tool tailored to this model organism. To address this gap, we developed mouse-Geneformer, an adaptation of Geneformer trained on a large dataset of mouse single-cell RNA sequencing data obtained from 20 million cells. Mouse-Geneformer demonstrates high accuracy in identifying distinct cell types and predicting disease-causing genes in gene manipulation simulation experiments. Moreover, mouse-Geneformer exhibited comparable accuracy to the original human Geneformer, even when applied to human cell data, suggesting its potential for cross-species use. For instance, it performed well in studying heart disease but was less consistent with COVID-19, likely due to the differences between species in how they react to the virus. Overall, mouse-Geneformer could be a valuable resource for studying not only mice but also other animals, especially when large-scale data are challenging to obtain. Furthermore, this cross-species approach may probe beneficial in human research, especially for tissues that are difficult to access, such as embryonic samples",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
280,Multi-ancestry genome- and phenome-wide association studies of diverticular disease in electronic health records with natural language processing enriched phenotyping algorithm,"Diverticular disease (DD) is one of the most prevalent conditions encountered by gastroenterologists, affecting ~50% of Americans before the age of 60. Our aim was to identify genetic risk variants and clinical phenotypes associated with DD, leveraging multiple electronic health record (EHR) data sources of 91,166 multi-ancestry participants with a Natural Language Processing (NLP) technique. We developed a NLP-enriched phenotyping algorithm that incorporated colonoscopy or abdominal imaging reports to identify patients with diverticulosis and diverticulitis from multicenter EHRs. We performed genome-wide association studies (GWAS) of DD in European, African and multi-ancestry participants, followed by phenome-wide association studies (PheWAS) of the risk variants to identify their potential comorbid/pleiotropic effects in clinical phenotypes. Our developed algorithm showed a significant improvement in patient classification performance for DD analysis (algorithm PPVs ≥ 0.94), with up to a 3.5 fold increase in terms of the number of identified patients than the traditional method. Ancestry-stratified analyses of diverticulosis and diverticulitis of the identified subjects replicated the well-established associations between ARHGAP15 loci with DD, showing overall intensified GWAS signals in diverticulitis patients compared to diverticulosis patients. Our PheWAS analyses identified significant associations between the DD GWAS variants and circulatory system, genitourinary, and neoplastic EHR phenotypes. As the first multi-ancestry GWAS-PheWAS study, we showcased that heterogenous EHR data can be mapped through an integrative analytical pipeline and reveal significant genotype-phenotype associations with clinical interpretation. A systematic framework to process unstructured EHR data with NLP could advance a deep and scalable phenotyping for better patient identification and facilitate etiological investigation of a disease with multilayered data",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
281,Multi-modal deep learning improves grain yield prediction in wheat breeding by fusing genomics and phenomics,"Developing new crop varieties with superior performance is highly important to ensure robust and sustainable global food security. The speed of variety development is limited by long field cycles and advanced generation selections in plant breeding programs. While methods to predict yield from genotype or phenotype data have been proposed, improved performance and integrated models are needed. We propose a machine learning model that leverages both genotype and phenotype measurements by fusing genetic variants with multiple data sources collected by unmanned aerial systems. We use a deep multiple instance learning framework with an attention mechanism that sheds light on the importance given to each input during prediction, enhancing interpretability. Our model reaches 0.754 ± 0.024 Pearson correlation coefficient when predicting yield in similar environmental conditions; a 34.8% improvement over the genotype-only linear baseline (0.559 ± 0.050). We further predict yield on new lines in an unseen environment using only genotypes, obtaining a prediction accuracy of 0.386 ± 0.010, a 13.5% improvement over the linear baseline. Our multi-modal deep learning architecture efficiently accounts for plant health and environment, distilling the genetic contribution and providing excellent predictions. Yield prediction algorithms leveraging phenotypic observations during training therefore promise to improve breeding programs, ultimately speeding up delivery of improved varieties. Available at https://github.com/BorgwardtLab/PheGeMIL (code) and https://doi.org/doi:10.5061/dryad.kprr4xh5p (data)",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
282,Multi-view graph learning for deciphering the dominant cell communication assembly of downstream functional events from single-cell RNA-seq data ======================== scDCA: deciphering the dominant cell communication assembly of downstream functional events from single-cell RNA-seq data,"Cell-cell communications (CCCs) involve signaling from multiple sender cells that collectively impact downstream functional processes in receiver cells. Currently, computational methods are lacking for quantifying the contribution of pairwise combinations of cell types to specific functional processes in receiver cells (e.g. target gene expression or cell states). This limitation has impeded understanding the underlying mechanisms of cancer progression and identifying potential therapeutic targets. Here, we proposed a deep learning-based method, scDCA, to decipher the dominant cell communication assembly (DCA) that have a higher impact on a particular functional event in receiver cells from single-cell RNA-seq data. Specifically, scDCA employed a multi-view graph convolution network to reconstruct the CCCs landscape at single-cell resolution, and then identified DCA by interpreting the model with the attention mechanism. Taking the samples from advanced renal cell carcinoma as a case study, the scDCA was successfully applied and validated in revealing the DCA affecting the crucial gene expression in immune cells. The scDCA was also applied and validated in revealing the DCA responsible for the variation of 14 typical functional states of malignant cells. Furthermore, the scDCA was applied and validated to explore the alteration of CCCs under clinical intervention by comparing the DCA for certain cytotoxic factors between patients with and without immunotherapy. In summary, scDCA provides a valuable and practical tool for deciphering the cell type combinations with the most dominant impact on a specific functional process of receiver cells, which is of great significance for precise cancer treatment. Our data and code are free available at a public GitHub repository: https://github.com/pengsl-lab/scDCA.git",,"biorxiv, PubMed",,1,,,,,,,FALSE,TRUE,FALSE
283,Multiomic analyses implicate a neurodevelopmental program in the pathogenesis of cerebral arachnoid cysts,"Cerebral arachnoid cysts (ACs) are one of the most common and poorly understood types of developmental brain lesion. To begin to elucidate AC pathogenesis, we performed an integrated analysis of 617 patient-parent (trio) exomes, 152,898 human brain and mouse meningeal single-cell RNA sequencing transcriptomes and natural language processing data of patient medical records. We found that damaging de novo variants (DNVs) were highly enriched in patients with ACs compared with healthy individuals (P = 1.57 × 10<sup>-33</sup>). Seven genes harbored an exome-wide significant DNV burden. AC-associated genes were enriched for chromatin modifiers and converged in midgestational transcription networks essential for neural and meningeal development. Unsupervised clustering of patient phenotypes identified four AC subtypes and clinical severity correlated with the presence of a damaging DNV. These data provide insights into the coordinated regulation of brain and meningeal development and implicate epigenomic dysregulation due to DNVs in AC pathogenesis. Our results provide a preliminary indication that, in the appropriate clinical context, ACs may be considered radiographic harbingers of neurodevelopmental pathology warranting genetic testing and neurobehavioral follow-up. These data highlight the utility of a systems-level, multiomics approach to elucidate sporadic structural brain disease",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
284,nanoBERT: A deep learning model for gene agnostic navigation of the nanobody mutational space,"Nanobodies are a subclass of immunoglobulins, whose binding site consists of only one peptide chain, bestowing favorable biophysical properties. Recently, the first nanobody therapy was approved, paving the way for further clinical applications of this antibody format. Further development of nanobody-based therapeutics could be streamlined by computational methods. One of such methods is infilling - positional prediction of biologically feasible mutations in nanobodies. Being able to identify possible positional substitutions based on sequence context, facilitates functional design of such molecules. Here we present nanoBERT, a nanobody-specific transformer to predict amino acids in a given position in a query sequence. We demonstrate the need to develop such machine-learning based protocol as opposed to gene-specific positional statistics since appropriate genetic reference is not available. We benchmark nanoBERT with respect to human-based language models and ESM-2, demonstrating the benefit for domain-specific language models. We also demonstrate the benefit of employing nanobody-specific predictions for fine-tuning on experimentally measured thermostability dataset. We hope that nanoBERT will help engineers in a range of predictive tasks for designing therapeutic nanobodies.  Availabilityhttps://huggingface.co/NaturalAntibody/",,"PubMed, biorxiv",,1,,,,,,,FALSE,TRUE,FALSE
285,Natural history of rare diseases using natural language processing of narrative unstructured electronic health records: The example of Dravet syndrome,"The increasing implementation of electronic health records allows the use of advanced text-mining methods for establishing new patient phenotypes and stratification, and for revealing outcome correlations. In this study, we aimed to explore the electronic narrative clinical reports of a cohort of patients with Dravet syndrome (DS) longitudinally followed at our center, to identify the capacity of this methodology to retrace natural history of DS during the early years. We used a document-based clinical data warehouse employing natural language processing to recognize the phenotype concepts in the narrative medical reports. We included patients with DS who have a medical report produced before the age of 2 years and a follow-up after the age of 3 years (""DS cohort,"" 56 individuals). We selected two control populations, a ""general control cohort"" (275 individuals) and a ""neurological control cohort"" (281 individuals), with similar characteristics in terms of gender, number of reports, and age at last report. To find concepts specifically associated with DS, we performed a phenome-wide association study using Cox regression, comparing the reports of the three cohorts. We then performed a qualitative analysis of the surviving concepts based on their median age at first appearance. A total of 76 concepts were prevalent in the reports of children with DS. Concepts appearing during the first 2 years were mostly related with the epilepsy features at the onset of DS (convulsive and prolonged seizures triggered by fever, often requiring in-hospital care). Subsequently, concepts related to new types of seizures and to drug resistance appeared. A series of non-seizure-related concepts emerged after the age of 2-3 years, referring to the nonseizure comorbidities classically associated with DS. The extraction of clinical terms by narrative reports of children with DS allows outlining the known natural history of this rare disease in early childhood. This original model of ""longitudinal phenotyping"" could be applied to other rare and very rare conditions with poor natural history description",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
287,Natural Language Processing in medicine and ophthalmology: A review for the 21st-century clinician,"Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and human language, enabling computers to understand, generate, and derive meaning from human language. NLP's potential applications in the medical field are extensive and vary from extracting data from Electronic Health Records -one of its most well-known and frequently exploited uses- to investigating relationships among genetics, biomarkers, drugs, and diseases for the proposal of new medications. NLP can be useful for clinical decision support, patient monitoring, or medical image analysis. Despite its vast potential, the real-world application of NLP is still limited due to various challenges and constraints, meaning that its evolution predominantly continues within the research domain. However, with the increasingly widespread use of NLP, particularly with the availability of large language models, such as ChatGPT, it is crucial for medical professionals to be aware of the status, uses, and limitations of these technologies",,PubMed,,1,,,,"large language models (e.g., GPT, ChatGPT); ML Task: NLP for clinical decision-making and medical text processing.","Clinical decision support, genetic research, and medical record analysis through NLP.","NLP applications in medicine, focusing on large language models and their real-world limitations.",FALSE,TRUE,FALSE
288,NeoGx: Machine-Recommended Rapid Genome Sequencing for Neonates,"Genetic disease is common in the Level IV Neonatal Intensive Care Unit (NICU), but neonatology providers are not always able to identify the need for genetic evaluation. We trained a machine learning (ML) algorithm to predict the need for genetic testing within the first 18 months of life using health record phenotypes. For a decade of NICU patients, we extracted Human Phenotype Ontology (HPO) terms from clinical text with Natural Language Processing tools. Considering multiple feature sets, classifier architectures, and hyperparameters, we selected a classifier and made predictions on a validation cohort of 2,241 Level IV NICU admits born 2020-2021. Our classifier had ROC AUC of 0.87 and PR AUC of 0.73 when making predictions during the first week in the Level IV NICU. We simulated testing policies under which subjects begin testing at the time of first ML prediction, estimating diagnostic odyssey length both with and without the additional benefit of pursuing rGS at this time. Just by using ML to accelerate initial genetic testing (without changing the tests ordered), the median time to first genetic test dropped from 10 days to 1 day, and the number of diagnostic odysseys resolved within 14 days of NICU admission increased by a factor of 1.8. By additionally requiring rGS at the time of positive ML prediction, the number of diagnostic odysseys resolved within 14 days was 3.8 times higher than the baseline. ML predictions of genetic testing need, together with the application of the right rapid testing modality, can help providers accelerate genetics evaluation and bring about earlier and better outcomes for patients
==========
BackgroundGenetic disease is common in the Level IV Neonatal Intensive Care Unit (NICU), but neonatology providers are not always able to identify the need for genetic evaluation. We trained a machine learning (ML) algorithm to predict the need for genetic testing within the first 18 months of life using health record phenotypes.  MethodsFor a decade of NICU patients, we extracted Human Phenotype Ontology (HPO) terms from clinical text with Natural Language Processing tools. Considering multiple feature sets, classifier architectures, and hyperparameters, we selected a classifier and made predictions on a validation cohort of 2,241 Level IV NICU admits born 2020-2021.  ResultsOur classifier had ROC AUC of 0.87 and PR AUC of 0.73 when making predictions during the first week in the Level IV NICU. We simulated testing policies under which subjects begin testing at the time of first ML prediction, estimating diagnostic odyssey length both with and without the additional benefit of pursuing rGS at this time. Just by using ML to accelerate initial genetic testing (without changing the tests ordered), the median time to first genetic test dropped from 10 days to 1 day, and the number of diagnostic odysseys resolved within 14 days of NICU admission increased by a factor of 1.8. By additionally requiring rGS at the time of positive ML prediction, the number of diagnostic odysseys resolved within 14 days was 3.8 times higher than the baseline.  ConclusionsML predictions of genetic testing need, together with the application of the right rapid testing modality, can help providers accelerate genetics evaluation and bring about earlier and better outcomes for patients",,"PubMed,medrxiv",,1,,,,NLP tools with machine learning classifiers (NOT transformers); ML Task: Genetic testing prediction from clinical text (phenotypes).,Genetic disease diagnostics in neonates; clinical text and health records data.,"NLP predicts need for genetic tests, reducing diagnostic time for neonatal genetic disorders.",FALSE,TRUE,FALSE
289,OncoCTMiner: streamlining precision oncology trial matching via molecular profile analysis,"SummaryOncoCTMiner is an innovative platform that streamlines precision oncology trial matching by integrating genetic profile analysis and clinical data. It utilizes manual tagging and automated entity recognition to identify six major biomedical concepts within clinical trial records. The platform currently contains a database of over 457,000 clinical trials, enabling quick and advanced search functionalities. Additionally, OncoCTMiner features an automated matching system based on genetic profiles and clinical data, providing real-time matching reports for suitable clinical trials. This platform aims to enhance patient enrollment in precision oncology trials, facilitating the development of personalized cancer therapies.  Availability and ImplementationOncoCTMiner is available at https://oncoctminer.chosenmedinfo.com.  Contactniubf@cnic.cn or qimingzhou@chosenmedtech.com  Supplementary informationSupplementary data are available at medRxiv online.  Graphic Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=152 SRC=""FIGDIR/small/23292477v1_ufig1.gif"" ALT=""Figure 1""> View larger version (26K): org.highwire.dtl.DTLVardef@1bbc959org.highwire.dtl.DTLVardef@1a03185org.highwire.dtl.DTLVardef@1346e2org.highwire.dtl.DTLVardef@192dd04_HPS_FORMAT_FIGEXP  M_FIG Graphic abstract:  A) OncoCTMiners role in precision oncology trial enrollment. B) OncoCTMiner takes clinical and genetic profiles as inputs and utilizes a trial matching and filtering system to generate a report of matched trials. C) Strategy for building the clinical trial eligibility criteria database. D) Automatic matching strategy for genomics-driven oncology trials.  C_FIG
==========
By establishing omics sequencing of patient tumors as a crucial element in cancer treatment, the extensive implementation of precision oncology necessitates effective and prompt execution of clinical studies for approving molecular-targeted therapies. However, the substantial volume of patient sequencing data, combined with strict clinical trial criteria, increasingly complicates the process of matching patients to precision oncology studies. To streamline enrollment in these studies, we developed OncoCTMiner, an automated pre-screening platform for molecular cancer clinical trials. Through manual tagging of eligibility criteria for 2227 oncology trials, we identified key bio-concepts such as cancer types, genes, alterations, drugs, biomarkers and therapies. Utilizing this manually annotated corpus along with open-source biomedical natural language processing tools, we trained multiple named entity recognition models specifically designed for precision oncology trials. These models analyzed 460 952 clinical trials, revealing 8.15 million precision medicine concepts, 9.32 million entity-criteria-trial triplets and a comprehensive precision oncology eligibility criteria database. Most significantly, we developed a patient-trial matching system based on cancer patients' clinical and genetic profiles, which can seamlessly integrate with the omics data analysis platform. This system expedites the pre-screening process for potentially suitable precision oncology trials, offering patients swifter access to promising treatment options. Database URL  https://oncoctminer.chosenmedinfo.com",,"PubMed,medrxiv",,1,,,,,,,FALSE,TRUE,FALSE
290,Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding,"Multimodal Large Language Models (MLLMs) inherit the superior text understanding capabilities of LLMs and extend these capabilities to multimodal scenarios. These models achieve excellent results in the general domain of multimodal tasks. However, in the medical domain, the substantial training costs and the requirement for extensive medical data pose challenges to the development of medical MLLMs. Furthermore, due to the free-text form of answers, tasks such as visual grounding that need to produce output in a prescribed form become difficult for MLLMs. So far, there have been no medical MLLMs works in medical visual grounding area. For the medical vision grounding task, which involves identifying locations in medical images based on short text descriptions, we propose Parameter-efficient Fine-tuning medical multimodal large language models for Medcial Visual Grounding (PFMVG). To validate the performance of the model, we evaluate it on a public benchmark dataset for medical visual grounding, where it achieves competitive results, and significantly outperforming GPT-4v. Our code will be open sourced after peer review",,arXiv,,1,,,,,,,FALSE,TRUE,FALSE
291,"Phenome-wide identification of therapeutic genetic targets, leveraging knowledge graphs, graph neural networks, and UK Biobank data","The ongoing expansion of human genomic datasets propels therapeutic target identification; however, extracting gene-disease associations from gene annotations remains challenging. Here, we introduce Mantis-ML 2.0, a framework integrating AstraZeneca's Biological Insights Knowledge Graph and numerous tabular datasets, to assess gene-disease probabilities throughout the phenome. We use graph neural networks, capturing the graph's holistic structure, and train them on hundreds of balanced datasets via a robust semi-supervised learning framework to provide gene-disease probabilities across the human exome. Mantis-ML 2.0 incorporates natural language processing to automate disease-relevant feature selection for thousands of diseases. The enhanced models demonstrate a 6.9% average classification power boost, achieving a median receiver operating characteristic (ROC) area under curve (AUC) score of 0.90 across 5220 diseases from Human Phenotype Ontology, OpenTargets, and Genomics England. Notably, Mantis-ML 2.0 prioritizes associations from an independent UK Biobank phenome-wide association study (PheWAS), providing a stronger form of triaging and mitigating against underpowered PheWAS associations. Results are exposed through an interactive web resource",,PubMed,,1,,,,Utilizes Graph Neural Networks (GNN) and integrates NLP through a framework (Mantis-ML 2.0) for disease-relevant feature extraction.,"Genomic data analysis for gene-disease associations using NLP for gene annotations, focusing on phenome-wide associations.",GNNs combined with NLP techniques enhance gene-disease target identification by leveraging large-scale genomic datasets.,FALSE,TRUE,FALSE
292,Precision Phenotyping for Curating Research Cohorts of Patients with Post-Acute Sequelae of COVID-19 (PASC) as a Diagnosis of Exclusion,"Scalable identification of patients with the post-acute sequelae of COVID-19 (PASC) is challenging due to a lack of reproducible precision phenotyping algorithms and the suboptimal accuracy, demographic biases, and underestimation of the PASC diagnosis code (ICD-10 U09.9). In a retrospective case-control study, we developed a precision phenotyping algorithm for identifying research cohorts of PASC patients, defined as a diagnosis of exclusion. We used longitudinal electronic health records (EHR) data from over 295 thousand patients from 14 hospitals and 20 community health centers in Massachusetts. The algorithm employs an attention mechanism to exclude sequelae that prior conditions can explain. We performed independent chart reviews to tune and validate our precision phenotyping algorithm. Our PASC phenotyping algorithm improves precision and prevalence estimation and reduces bias in identifying Long COVID patients compared to the U09.9 diagnosis code. Our algorithm identified a PASC research cohort of over 24 thousand patients (compared to about 6 thousand when using the U09.9 diagnosis code), with a 79.9 percent precision (compared to 77.8 percent from the U09.9 diagnosis code). Our estimated prevalence of PASC was 22.8 percent, which is close to the national estimates for the region. We also provide an in-depth analysis outlining the clinical attributes, encompassing identified lingering effects by organ, comorbidity profiles, and temporal differences in the risk of PASC. The PASC phenotyping method presented in this study boasts superior precision, accurately gauges the prevalence of PASC without underestimating it, and exhibits less bias in pinpointing Long COVID patients. The PASC cohort derived from our algorithm will serve as a springboard for delving into Long COVIDs genetic, metabolomic, and clinical intricacies, surmounting the constraints of recent PASC cohort studies, which were hampered by their limited size and available outcome data
==========
Scalable identification of patients with the post-acute sequelae of COVID-19 (PASC) is challenging due to a lack of reproducible precision phenotyping algorithms and the suboptimal accuracy, demographic biases, and underestimation of the PASC diagnosis code (ICD-10 U09.9). In a retrospective case-control study, we developed a precision phenotyping algorithm for identifying research cohorts of PASC patients, defined as a diagnosis of exclusion. We used longitudinal electronic health records (EHR) data from over 295 thousand patients from 14 hospitals and 20 community health centers in Massachusetts. The algorithm employs an attention mechanism to exclude sequelae that prior conditions can explain. We performed independent chart reviews to tune and validate our precision phenotyping algorithm. Our PASC phenotyping algorithm improves precision and prevalence estimation and reduces bias in identifying Long COVID patients compared to the U09.9 diagnosis code. Our algorithm identified a PASC research cohort of over 24 thousand patients (compared to about 6 thousand when using the U09.9 diagnosis code), with a 79.9 percent precision (compared to 77.8 percent from the U09.9 diagnosis code). Our estimated prevalence of PASC was 22.8 percent, which is close to the national estimates for the region. We also provide an in-depth analysis outlining the clinical attributes, encompassing identified lingering effects by organ, comorbidity profiles, and temporal differences in the risk of PASC. The PASC phenotyping method presented in this study boasts superior precision, accurately gauges the prevalence of PASC without underestimating it, and exhibits less bias in pinpointing Long COVID patients. The PASC cohort derived from our algorithm will serve as a springboard for delving into Long COVID's genetic, metabolomic, and clinical intricacies, surmounting the constraints of recent PASC cohort studies, which were hampered by their limited size and available outcome data",,"PubMed,medrxiv",,1,,,,,,,FALSE,TRUE,FALSE
293,Predicting BRCA mutation and stratifying targeted therapy response using multimodal learning: a multicenter study,"The status of BRCA1/2 genes plays a crucial role in the treatment decision-making process for multiple cancer types. However, due to high costs and limited resources, a demand for BRCA1/2 genetic testing among patients is currently unmet. Notably, not all patients with BRCA1/2 mutations achieve favorable outcomes with poly (ADP-ribose) polymerase inhibitors (PARPi), indicating the necessity for risk stratification. In this study, we aimed to develop and validate a multimodal model for predicting BRCA1/2 gene status and prognosis with PARPi treatment. We included 1695 slides from 1417 patients with ovarian, breast, prostate, and pancreatic cancers across three independent cohorts. Using a self-attention mechanism, we constructed a multi-instance attention model (MIAM) to detect BRCA1/2 gene status from hematoxylin and eosin (H&E) pathological images. We further combined tissue features from the MIAM model, cell features, and clinical factors (the MIAM-C model) to predict BRCA1/2 mutations and progression-free survival (PFS) with PARPi therapy. Model performance was evaluated using area under the curve (AUC) and Kaplan-Meier analysis. Morphological features contributing to MIAM-C were analyzed for interpretability. Across the four cancer types, MIAM-C outperformed the deep learning-based MIAM in identifying the BRCA1/2 genotype. Interpretability analysis revealed that high-attention regions included high-grade tumors and lymphocytic infiltration, which correlated with BRCA1/2 mutations. Notably, high lymphocyte ratios appeared characteristic of BRCA1/2 mutations. Furthermore, MIAM-C predicted PARPi therapy response (log-rank p < 0.05) and served as an independent prognostic factor for patients with BRCA1/2-mutant ovarian cancer (p < 0.05, hazard ratio:0.4, 95% confidence interval: 0.16-0.99). The MIAM-C model accurately detected BRCA1/2 gene status and effectively stratified prognosis for patients with BRCA1/2 mutations",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
294,Predicting Openness of Communication in Families With Hereditary Breast and Ovarian Cancer Syndrome: Natural Language Processing Analysis,"In health care research, patient-reported opinions are a critical element of personalized medicine and contribute to optimal health care delivery. The importance of integrating natural language processing (NLP) methods to extract patient-reported opinions has been gradually acknowledged over the past years. One form of NLP is sentiment analysis, which extracts and analyses information by detecting feelings (thoughts, emotions, attitudes, etc) behind words. Sentiment analysis has become particularly popular following the rise of digital interactions. However, NLP and sentiment analysis in the context of intrafamilial communication for genetic cancer risk is still unexplored. Due to privacy laws, intrafamilial communication is the main avenue to inform at-risk relatives about the pathogenic variant and the possibility of increased cancer risk. The study examined the role of sentiment in predicting openness of intrafamilial communication about genetic cancer risk associated with hereditary breast and ovarian cancer (HBOC) syndrome. We used narratives derived from 53 in-depth interviews with individuals from families that harbor pathogenic variants associated with HBOC: first, to quantify openness of communication about cancer risk, and second, to examine the role of sentiment in predicting openness of communication. The interviews were conducted between 2019 and 2021 in Switzerland and South Korea using the same interview guide. We used NLP to extract and quantify textual features to construct a handcrafted lexicon about interpersonal communication of genetic testing results and cancer risk associated with HBOC. Moreover, we examined the role of sentiment in predicting openness of communication using a stepwise linear regression model. To test model accuracy, we used a split-validation set. We measured the performance of the training and testing model using area under the curve, sensitivity, specificity, and root mean square error. Higher ""openness of communication"" scores were associated with higher overall net sentiment score of the narrative, higher fear, being single, having nonacademic education, and higher informational support within the family. Our results demonstrate that NLP was highly effective in analyzing unstructured texts from individuals of different cultural and linguistic backgrounds and could also reliably predict a measure of ""openness of communication"" (area under the curve=0.72) in the context of genetic cancer risk associated with HBOC. Our study showed that NLP can facilitate assessment of openness of communication in individuals carrying a pathogenic variant associated with HBOC. Findings provided promising evidence that various features from narratives such as sentiment and fear are important predictors of interpersonal communication and self-disclosure in this context. Our approach is promising and can be expanded in the field of personalized medicine and technology-mediated communication",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
295,Preliminary Screening for Hereditary Breast and Ovarian Cancer Using an AI Chatbot as a Genetic Counselor: Clinical Study,"Hereditary breast and ovarian cancer (HBOC) is a major type of hereditary cancer. Establishing effective screening to identify high-risk individuals for HBOC remains a challenge. We developed a prototype of a chatbot system that uses artificial intelligence (AI) for preliminary HBOC screening to determine whether individuals meet the National Comprehensive Cancer Network BRCA1/2 testing criteria. This study's objective was to validate the feasibility of this chatbot in a clinical setting by using it on a patient population that visited a hospital. We validated the medical accuracy of the chatbot system by performing a test on patients who consecutively visited the Kanagawa Cancer Center. The participants completed a preoperation questionnaire to understand their background, including information technology literacy. After the operation, qualitative interviews were conducted to collect data on the usability and acceptability of the system and examine points needing improvement. A total of 11 participants were enrolled between October and December 2020. All of the participants were women, and among them, 10 (91%) had cancer. According to the questionnaire, 6 (54%) participants had never heard of a chatbot, while 7 (64%) had never used one. All participants were able to complete the chatbot operation, and the average time required for the operation was 18.0 (SD 5.44) minutes. The determinations by the chatbot of whether the participants met the BRCA1/2 testing criteria based on their medical and family history were consistent with those by certified genetic counselors (CGCs). We compared the medical histories obtained from the participants by the CGCs with those by the chatbot. Of the 11 participants, 3 (27%) entered information different from that obtained by the CGCs. These discrepancies were caused by the participant's omissions or communication errors with the chatbot. Regarding the family histories, the chatbot provided new information for 3 (27%) of the 11 participants and complemented information for the family members of 5 (45%) participants not interviewed by the CGCs. The chatbot could not obtain some information on the family history of 6 (54%) participants due to several reasons, such as being outside of the scope of the chatbot's interview questions, the participant's omissions, and communication errors with the chatbot. Interview data were classified into the following: (1) features, (2) appearance, (3) usability and preferences, (4) concerns, (5) benefits, and (6) implementation. Favorable comments on implementation feasibility and comments on improvements were also obtained. This study demonstrated that the preliminary screening system for HBOC using an AI chatbot was feasible for real patients",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
296,Prescreening in oncology trials using medical records. Natural language processing applied on lung cancer multidisciplinary team meeting reports,"Defining profiles of patients that could benefit from relevant anti-cancer treatments is essential. An increasing number of specific criteria are necessary to be eligible to specific anti-cancer therapies. This study aimed to develop an automated algorithm able to detect patient and tumor characteristics to reduce the time-consuming prescreening for trial inclusions without delay. Hence, 640 anonymized multidisciplinary team meetings (MTM) reports concerning lung cancers from one French teaching hospital data warehouse between 2018 and 2020 were annotated. To automate the extraction of eight major eligibility criteria, corresponding to 52 classes, regular expressions were implemented. The RegEx's evaluation gave a F1-score of 93% in average, a positive predictive value (precision) of 98% and sensitivity (recall) of 92%. However, in MTM, fill rates variabilities among patient and tumor information remained important (from 31% to 100%). Genetic mutations and rearrangement test results were the least reported characteristics and also the hardest to automatically extract. To ease prescreening in clinical trials, the PreScIOUs study demonstrated the additional value of rule based and machine learning based methods applied on lung cancer MTM reports",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
297,Prospects of evolution-based artificial intelligence models in genome-wide studies to stratify genetic risk variants in nonalcoholic fatty liver disease,"The emergence of genome-wide association studies (GWAS) has identified genetic traits and polymorphisms that are associated with the progression of nonalcoholic fatty liver disease (NAFLD). Phospholipase domain-containing 3 and transmembrane 6 superfamily member 2 are genes commonly associated with NAFLD phenotypes. However, there are fewer studies and replicability in lesser-known genes such as LYPLAL1 and glucokinase regulator (GCKR). With the advent of artificial intelligence (AI) in clinical genetics, studies have utilized AI algorithms to identify phenotypes through electronic health records and utilize convolution neural networks to improve the accuracy of variant identification, predict the deleterious effects of variants, and conduct phenotype-to-genotype mapping. Natural language processing (NLP) and machine-learning (ML) algorithms are popular tools in GWAS studies and connect electronic health record phenotypes to genetic diagnoses using a combination of international classification disease (ICD)-based approaches. However, there are still limitations to machine-learning - and NLP-based models, such as the lack of replicability in larger cohorts and underpowered sample sizes, which prevent the accurate prediction of genetic variants that may increase the risk of NAFLD and its progression to advanced-stage liver fibrosis. This may be largely due to the lack of understanding of the clinical consequence in the majority of pathogenic variants. Though the concept of evolution-based AI models and evolutionary algorithms is relatively new, combining current international classification disease -based NLP models with phylogenetic and evolutionary data can improve prediction accuracy and create valuable connections between variants and their pathogenicity in NAFLD. Such developments can improve risk stratification within clinical genetics and research while overcoming limitations in GWAS studies that prevent community-wide interpretations",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
298,PubMed and Beyond: Biomedical Literature Search in the Age of Artificial Intelligence,"Biomedical research yields a wealth of information, much of which is only accessible through the literature. Consequently, literature search is an essential tool for building on prior knowledge in clinical and biomedical research. Although recent improvements in artificial intelligence have expanded functionality beyond keyword-based search, these advances may be unfamiliar to clinicians and researchers. In response, we present a survey of literature search tools tailored to both general and specific information needs in biomedicine, with the objective of helping readers efficiently fulfill their information needs. We first examine the widely used PubMed search engine, discussing recent improvements and continued challenges. We then describe literature search tools catering to five specific information needs: 1. Identifying high-quality clinical research for evidence-based medicine. 2. Retrieving gene-related information for precision medicine and genomics. 3. Searching by meaning, including natural language questions. 4. Locating related articles with literature recommendation. 5. Mining literature to discover associations between concepts such as diseases and genetic variants. Additionally, we cover practical considerations and best practices for choosing and using these tools. Finally, we provide a perspective on the future of literature search engines, considering recent breakthroughs in large language models such as ChatGPT. In summary, our survey provides a comprehensive view of biomedical literature search functionalities with 36 publicly available tools",,arXiv,,1,,,,,,,FALSE,TRUE,FALSE
299,Rare disease variant curation from literature: assessing gaps with creatine transport deficiency in focus,"Approximately 4-8% of the world suffers from a rare disease. Rare diseases are often difficult to diagnose, and many do not have approved therapies. Genetic sequencing has the potential to shorten the current diagnostic process, increase mechanistic understanding, and facilitate research on therapeutic approaches but is limited by the difficulty of novel variant pathogenicity interpretation and the communication of known causative variants. It is unknown how many published rare disease variants are currently accessible in the public domain. This study investigated the translation of knowledge of variants reported in published manuscripts to publicly accessible variant databases. Variants, symptoms, biochemical assay results, and protein function from literature on the SLC6A8 gene associated with X-linked Creatine Transporter Deficiency (CTD) were curated and reported as a highly annotated dataset of variants with clinical context and functional details. Variants were harmonized, their availability in existing variant databases was analyzed and pathogenicity assignments were compared with impact algorithm predictions. 24% of the pathogenic variants found in PubMed articles were not captured in any database used in this analysis while only 65% of the published variants received an accurate pathogenicity prediction from at least one impact prediction algorithm. Despite being published in the literature, pathogenicity data on patient variants may remain inaccessible for genetic diagnosis, therapeutic target identification, mechanistic understanding, or hypothesis generation. Clinical and functional details presented in the literature are important to make pathogenicity assessments. Impact predictions remain imperfect but are improving, especially for single nucleotide exonic variants, however such predictions are less accurate or unavailable for intronic and multi-nucleotide variants. Developing text mining workflows that use natural language processing for identifying diseases, genes and variants, along with impact prediction algorithms and integrating with details on clinical phenotypes and functional assessments might be a promising approach to scale literature mining of variants and assigning correct pathogenicity. The curated variants list created by this effort includes context details to improve any such efforts on variant curation for rare diseases",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
300,RegEMR: a natural language processing system to automatically identify premature ovarian decline from Chinese electronic medical records,"The ovarian reserve is a reservoir for reproductive potential. In clinical practice, early detection and treatment of premature ovarian decline characterized by abnormal ovarian reserve tests is regarded as a critical measure to prevent infertility. However, the relevant data are typically stored in an unstructured format in a hospital's electronic medical record (EMR) system, and their retrieval requires tedious manual abstraction by domain experts. Computational tools are therefore needed to reduce the workload. We presented RegEMR, an artificial intelligence tool composed of a rule-based natural language processing (NLP) extractor and a knowledge-based disease scoring model, to automatize the screening procedure of premature ovarian decline using Chinese reproductive EMRs. We used regular expressions (REs) as a text mining method and explored whether REs automatically synthesized by the genetic programming-based online platform RegexGenerator +  + could be as effective as manually formulated REs. We also investigated how the representativeness of the learning corpus affected the performance of machine-generated REs. Additionally, we translated the clinical diagnostic criteria into a programmable disease diagnostic model for disease scoring and risk stratification. Four hundred outpatient medical records were collected from a Chinese fertility center. Manual review served as the gold standard, and fivefold cross-validation was used for evaluation. The overall F-score of manually built REs was 0.9444 (95% CI 0.9373 to 0.9515), with no significant difference (paired t test p > 0.05) compared with machine-generated REs that could be affected by training set sizes and annotation portions. The extractor performed effectively in automatically tracing the dynamic changes in hormone levels (F-score 0.9518-0.9884) and ultrasonographic measures (F-score 0.9472-0.9822). Applying the extracted information to the proposed diagnostic model, the program obtained an accuracy of 0.98 and a sensitivity of 0.93 in risk screening. For each specific disease, the automatic diagnosis in 76% of patients was consistent with that of the clinical diagnosis, and the kappa coefficient was 0.63. A Chinese NLP system named RegEMR was developed to automatically identify high risk of early ovarian aging and diagnose related diseases from Chinese reproductive EMRs. We hope that this system can aid EMR-based data collection and clinical decision support in fertility centers",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
301,Role of artificial intelligence in predicting neurological outcomes in postcardiac resuscitation,"Being an extremely high mortality rate condition, cardiac arrest cases have rightfully been evaluated via various studies and scoring factors for effective resuscitative practices and neurological outcomes postresuscitation. This narrative review aims to explore the role of artificial intelligence (AI) in predicting neurological outcomes postcardiac resuscitation. The methodology involved a detailed review of all relevant recent studies of AI, different machine learning algorithms, prediction tools, and assessing their benefit in predicting neurological outcomes in postcardiac resuscitation cases as compared to more traditional prognostic scoring systems and tools. Previously, outcome determining clinical, blood, and radiological factors were prone to other influencing factors like limited accuracy and time constraints. Studies conducted also emphasized that to predict poor neurological outcomes, a more multimodal approach helped adjust for confounding factors, interpret diverse datasets, and provide a reliable prognosis, which only demonstrates the need for AI to help overcome challenges faced. Advanced machine learning algorithms like artificial neural networks (ANN) using supervised learning by AI have improved the accuracy of prognostic models outperforming conventional models. Several real-world cases of effective AI-powered algorithm models have been cited here. Studies comparing machine learning tools like XGBoost, AI Watson, hyperspectral imaging, ChatGPT-4, and AI-based gradient boosting have noted their beneficial uses. AI could help reduce workload, healthcare costs, and help personalize care, process vast genetic and lifestyle data and help reduce side effects from treatments. Limitations of AI have been covered extensively in this article, including data quality, bias, privacy issues, and transparency. Our objectives should be to use more diverse data sources, use interpretable data output giving process explanation, validation method, and implement policies to safeguard patient data. Despite the limitations, the advancements already made by AI and its potential in predicting neurological outcomes in postcardiac resuscitation cases has been quite promising and boosts a continually improving system, albeit requiring close human supervision with training and improving models, with plans to educate clinicians, the public and sharing collected data",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
302,SAFPred: synteny-aware gene function prediction for bacteria using protein embeddings,"Today, we know the function of only a small fraction of the protein sequences predicted from genomic data. This problem is even more salient for bacteria, which represent some of the most phylogenetically and metabolically diverse taxa on Earth. This low rate of bacterial gene annotation is compounded by the fact that most function prediction algorithms have focused on eukaryotes, and conventional annotation approaches rely on the presence of similar sequences in existing databases. However, often there are no such sequences for novel bacterial proteins. Thus, we need improved gene function prediction methods tailored for bacteria. Recently, transformer-based language models-adopted from the natural language processing field-have been used to obtain new representations of proteins, to replace amino acid sequences. These representations, referred to as protein embeddings, have shown promise for improving annotation of eukaryotes, but there have been only limited applications on bacterial genomes. To predict gene functions in bacteria, we developed SAFPred, a novel synteny-aware gene function prediction tool based on protein embeddings from state-of-the-art protein language models. SAFpred also leverages the unique operon structure of bacteria through conserved synteny. SAFPred outperformed both conventional sequence-based annotation methods and state-of-the-art methods on multiple bacterial species, including for distant homolog detection, where the sequence similarity to the proteins in the training set was as low as 40%. Using SAFPred to identify gene functions across diverse enterococci, of which some species are major clinical threats, we identified 11 previously unrecognized putative novel toxins, with potential significance to human and animal health. https://github.com/AbeelLab/safpred",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
303,SAP: Synteny-aware gene function prediction for bacteria using protein embeddings,"Today, we know the function of only a small fraction of the protein sequences predicted from genomic data. This problem is even more salient for bacteria, which represent some of the most phylogenetically and metabolically diverse taxa on Earth. This low rate of bacterial gene annotation is compounded by the fact that most function prediction algorithms have focused on eukaryotes, and conventional annotation approaches rely on the presence of similar sequences in existing databases. However, often there are no such sequences for novel bacterial proteins. Thus, we need improved gene function prediction methods tailored for prokaryotes. Recently, transformer-based language models - adopted from the natural language processing field - have been used to obtain new representations of proteins, to replace amino acid sequences. These representations, referred to as protein embeddings, have shown promise for improving annotation of eukaryotes, but there have been only limited applications on bacterial genomes. To predict gene functions in bacteria, we developed SAP, a novel synteny-aware gene function prediction tool based on protein embeddings from state-of-the-art protein language models. SAP also leverages the unique operon structure of bacteria through conserved synteny. SAP outperformed both conventional sequence-based annotation methods and state-of-the-art methods on multiple bacterial species, including for distant homolog detection, where the sequence similarity to the proteins in the training set was as low as 40%. Using SAP to identify gene functions across diverse enterococci, of which some species are major clinical threats, we identified 11 previously unrecognized putative novel toxins, with potential significance to human and animal health
==========
MotivationToday, we know the function of only a small fraction of the protein sequences predicted from genomic data. This problem is even more salient for bacteria, which represent some of the most phylogenetically and metabolically diverse taxa on Earth. This low rate of bacterial gene annotation is compounded by the fact that most function prediction algorithms have focused on eukaryotes, and conventional annotation approaches rely on the presence of similar sequences in existing databases. However, often there are no such sequences for novel bacterial proteins. Thus, we need improved gene function prediction methods tailored for prokaryotes. Recently, transformer-based language models - adopted from the natural language processing field - have been used to obtain new representations of proteins, to replace amino acid sequences. These representations, referred to as protein embeddings, have shown promise for improving annotation of eukaryotes, but there have been only limited applications on bacterial genomes.  ResultsTo predict gene functions in bacteria, we developed SAP, a novel synteny-aware gene function prediction tool based on protein embeddings from state-of-the-art protein language models. SAP also leverages the unique operon structure of bacteria through conserved synteny. SAP outperformed both conventional sequence-based annotation methods and state-of-the-art methods on multiple bacterial species, including for distant homolog detection, where the sequence similarity to the proteins in the training set was as low as 40%. Using SAP to identify gene functions across diverse enterococci, of which some species are major clinical threats, we identified 11 previously unrecognized putative novel toxins, with potential significance to human and animal health.  Availabilityhttps://github.com/AbeelLab/sap  Contactt.abeel@tudelft.nl  Supplementary informationSupplementary data are available at Bioinformatics online",,"PubMed,biorxiv",,1,,,,Transformer-based protein embeddings; ML Task: Gene function prediction.,"Genomic data, specifically for bacterial proteins and gene function prediction.","Uses protein embeddings to predict bacterial gene functions, identifying novel toxins with health significance.",FALSE,TRUE,FALSE
304,Sars-escape network for escape prediction of SARS-COV-2,"Viruses have coevolved with their hosts for over millions of years and learned to escape the host's immune system. Although not all genetic changes in viruses are deleterious, some significant mutations lead to the escape of neutralizing antibodies and weaken the immune system, which increases infectivity and transmissibility, thereby impeding the development of antiviral drugs or vaccines. Accurate and reliable identification of viral escape mutational sequences could be a good indicator for therapeutic design. We developed a computational model that recognizes significant mutational sequences based on escape feature identification using natural language processing along with prior knowledge of experimentally validated escape mutants. Our machine learning-based computational approach can recognize the significant spike protein sequences of severe acute respiratory syndrome coronavirus 2 using sequence data alone. This modelling approach can be applied to other viruses, such as influenza, monkeypox and HIV using knowledge of escape mutants and relevant protein sequence datasets. Complete source code and pre-trained models for escape prediction of severe acute respiratory syndrome coronavirus 2 protein sequences are available on Github at https://github.com/PremSinghBist/Sars-CoV-2-Escape-Model.git. The dataset is deposited to Zenodo at: doi: 10.5281/zenodo.7142638. The Python scripts are easy to run and customize as needed. premsing212@jbnu.ac.kr",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
305,SciConNav: Knowledge navigation through contextual learning of extensive scientific research trajectories,"New knowledge builds upon existing foundations, which means an interdependent relationship exists between knowledge, manifested in the historical development of the scientific system for hundreds of years. By leveraging natural language processing techniques, this study introduces the Scientific Concept Navigator (SciConNav), an embedding-based navigation model to infer the ""knowledge pathway"" from the research trajectories of millions of scholars. We validate that the learned representations effectively delineate disciplinary boundaries and capture the intricate relationships between diverse concepts. The utility of the inferred navigation space is showcased through multiple applications. Firstly, we demonstrated the multi-step analogy inferences within the knowledge space and the interconnectivity between concepts in different disciplines. Secondly, we formulated the attribute dimensions of knowledge across domains, observing the distributional shifts in the arrangement of 19 disciplines along these conceptual dimensions, including ""Theoretical"" to ""Applied"", and ""Chemical"" to ""Biomedical', highlighting the evolution of functional attributes within knowledge domains. Lastly, by analyzing the high-dimensional knowledge network structure, we found that knowledge connects with shorter global pathways, and interdisciplinary knowledge plays a critical role in the accessibility of the global knowledge network. Our framework offers a novel approach to mining knowledge inheritance pathways in extensive scientific literature, which is of great significance for understanding scientific progression patterns, tailoring scientific learning trajectories, and accelerating scientific progress",,arXiv,,1,,,,Embedding-based NLP model; NOT Transformers ML Task: Knowledge navigation and research trajectory mapping.,"Mapping interdisciplinary scientific concepts across domains (e.g., biomedical research).","Introduces a model to track knowledge pathways across scientific disciplines, aiding research progression.",FALSE,TRUE,FALSE
306,Semi-Automated Data Curation from Biomedical Literature,"Data curation is a bottleneck for many informatics pipelines. A specific example of this is aggregating data from preclinical studies to identify novel genetic pathways for atherosclerosis in humans. This requires extracting data from published mouse studies such as the perturbed gene and its impact on lesion sizes and plaque inflammation, which is non-trivial. Curation efforts are resource-heavy, with curators manually extracting data from hundreds of publications. In this work, we describe the development of a semi-automated curation tool to accelerate data extraction. We use natural language processing (NLP) methods to auto-populate a web-based form which is then reviewed by a curator. We conducted a controlled user study to evaluate the curation tool. Our NLP model has a 70% accuracy on categorical fields and our curation tool accelerates task completion time by 49% compared to manual curation",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
307,TaeC: A manually annotated text dataset for trait and phenotype extraction and entity linking in wheat breeding literature,"Wheat varieties show a large diversity of traits and phenotypes. Linking them to genetic variability is essential for shorter and more efficient wheat breeding programs. A growing number of plant molecular information networks provide interlinked interoperable data to support the discovery of gene-phenotype interactions. A large body of scientific literature and observational data obtained in-field and under controlled conditions document wheat breeding experiments. The cross-referencing of this complementary information is essential. Text from databases and scientific publications has been identified early on as a relevant source of information. However, the wide variety of terms used to refer to traits and phenotype values makes it difficult to find and cross-reference the textual information, e.g. simple dictionary lookup methods miss relevant terms. Corpora with manually annotated examples are thus needed to evaluate and train textual information extraction methods. While several corpora contain annotations of human and animal phenotypes, no corpus is available for plant traits. This hinders the evaluation of text mining-based crop knowledge graphs (e.g. AgroLD, KnetMiner, WheatIS-FAIDARE) and limits the ability to train machine learning methods and improve the quality of information. The Triticum aestivum trait Corpus is a new gold standard for traits and phenotypes of wheat. It consists of 528 PubMed references that are fully annotated by trait, phenotype, and species. We address the interoperability challenge of crossing sparse assay data and publications by using the Wheat Trait and Phenotype Ontology to normalize trait mentions and the species taxonomy of the National Center for Biotechnology Information to normalize species. The paper describes the construction of the corpus. A study of the performance of state-of-the-art language models for both named entity recognition and linking tasks trained on the corpus shows that it is suitable for training and evaluation. This corpus is currently the most comprehensive manually annotated corpus for natural language processing studies on crop phenotype information from the literature",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
308,Text-based Integration of Mutational Profiles for Classification and Biomarker Identification of Intraductal Papillary Mucinous Neoplasms of the Pancreas,"MotivationIntraductal Papillary Mucinous Neoplasms (IPMNs) are a common cystic precursor for pancreatic ductal adenocarcinoma (PDAC). Detecting these pre-malignant lesions poses a challenge for diagnostic tools due to their relatively low occurrence rate. However, a better understanding of the lesions composition could enable effective decision-making, risk assessment, treatment selection, and, most importantly, prevention.  MethodsIn this work, we introduce a new framework for integrating information from mutational profiles using transformer-based models for stratification and biomarker identification in IPMNs vs. PDAC. We show that the numerical descriptor vectors can be used to construct highly predictive Artificial Neural Networks for disease classification. The derived mutational representations can be supported by other data types (here, mRNA) and further improve the accuracy of the classifiers. Besides the AI-driven methodology for biomarker discovery in cancer research, we also propose methods to maximize AIs utility by recycling its knowledge to facilitate our limited understanding of the disease. We propose Natural Adversary Analysis - an AI-driven inference to detect IPMNs with a high probability of progression to malignancy.  ResultsThe proposed model supports 12 clinically relevant genetic biomarkers with high mutation rates (such as KRAS, GNAS, ARID1A, and CDKN2A) and suggests biomarkers not yet recognized (such as RADIL, TTN, and ZNF287). We broaden the studys scope by investigating rarely mutated genes and reveal 14 biomarkers with potential clinical importance. Several genes with low mutation rates, including TMPRSS1, CDH22, CCND2, CYFIP2, CBLL1, and OPCML, are also addressed as potential biomarkers by our framework. Finally, the predictive robustness of the identified biomarker set is validated externally on the patient data from the Moffitt Cancer Center study, including six pairs of matched tumor and normal IPMN samples. We show that the presented mutational profile (MP-derived) gene panel has equivalent predictive power to clinically driven panels.  ConclusionsHere, we show the proof-of-concept that AI can serve the clinic and discover biomarkers beyond clinically known regimes. In line with that, we propose a translational AI-based approach for 1) disease stratification (IPMNs vs. PDAC), 2) biomarker identification, and 3) transferring the model knowledge to predict cysts risk of progression",,medrxiv,,1,,,,,,,FALSE,TRUE,FALSE
309,The Case for Retaining Natural Language Descriptions of Phenotypes in Plant Databases and a Web Application as Proof of Concept,"Similarities in phenotypic descriptions can be indicative of shared genetics, metabolism, and stress responses, to name a few. Finding and measuring similarity across descriptions of phenotype is not straightforward, with previous successes in computation requiring a great deal of expert data curation. Natural language processing of free text descriptions of phenotype is often less resource intensive than applying expert curation. It is therefore critical to understand the performance of natural language processing techniques for organizing and analyzing biological datasets and for enabling biological discovery. For predicting similar phenotypes, a wide variety of approaches from the natural language processing domain perform as well as curation-based methods. These computational approaches also show promise both for helping curators organize and work with large datasets and for enabling researchers to explore relationships among available phenotype descriptions. Here we generate networks of phenotype similarity and share a web application for querying a dataset of associated plant genes using these text mining approaches. Example situations and species for which application of these techniques is most useful are discussed.  Database URLsThe database and analytical tool called QuOATS are available at https://quoats.dill-picl.org/. Code for the web application is available at https://git.io/Jtv9J. Datasets are available for direct access via https://zenodo.org/record/7947342#.ZGwAKOzMK3I. The code for the analyses performed for the publication is available at https://github.com/Dill-PICL/Plant-data and https://github.com/Dill-PICL/NLP-Plant-Phenotypes",,biorxiv,,1,,,,"NLP (different methods, including BERT, BioBERT for embeddings); ML Task: Phenotype similarity prediction from natural language descriptions.",Organizing and analyzing phenotype descriptions in plant genomics.,"NLP methods perform well in predicting phenotype similarities, enhancing biological data organization and discovery.",FALSE,TRUE,FALSE
310,"The clinical and genetic spectrum of paediatric speech and language disorders in 52,143 individuals","Speech and language disorders are known to have a substantial genetic contribution. Although frequently examined as components of other conditions, research on the genetic basis of linguistic differences as separate phenotypic subgroups has been limited so far. Here, we performed an in-depth characterization of speech and language disorders in 52,143 individuals, reconstructing clinical histories using a large-scale data mining approach of the Electronic Medical Records (EMR) from an entire large paediatric healthcare network. The reported frequency of these disorders was the highest between 2 and 5 years old and spanned a spectrum of twenty-six broad speech and language diagnoses. We used Natural Language Processing to assess to which degree clinical diagnosis in full-text notes were reflected in ICD-10 diagnosis codes. We found that aphasia and speech apraxia could be easily retrieved through ICD-10 diagnosis codes, while stuttering as a speech phenotype was only coded in 12% of individuals through appropriate ICD-10 codes. We found significant comorbidity of speech and language disorders in neurodevelopmental conditions (30.31%) and to a lesser degree with epilepsies (6.07%) and movement disorders (2.05%). The most common genetic disorders retrievable in our EMR analysis were STXBP1 (n=21), PTEN (n=20), and CACNA1A (n=18). When assessing associations of genetic diagnoses with specific linguistic phenotypes, we observed associations of STXBP1 and aphasia (P=8.57 × 10<sup>-7</sup>, CI=18.62-130.39) and MYO7A with speech and language development delay due to hearing loss (P=1.24 × 10<sup>-5</sup>, CI=17.46-Inf). Finally, in a sub-cohort of 726 individuals with whole exome sequencing data, we identified an enrichment of rare variants in synaptic protein and neuronal receptor pathways and associations of UQCRC1 with expressive aphasia and WASHC4 with abnormality of speech or vocalization. In summary, our study outlines the landscape of paediatric speech and language disorders, confirming the phenotypic complexity of linguistic traits and novel genotype-phenotype associations. Subgroups of paediatric speech and language disorders differ significantly with respect to the composition of monogenic aetiologies
==========
Speech and language disorders are known to have a substantial genetic contribution. Although frequently examined as components of other conditions, research on the genetic basis of linguistic differences as separate phenotypic subgroups has been limited so far.  Here, we performed an in-depth characterization of speech and language disorders in 52,143 individuals, reconstructing clinical histories using a large-scale data mining approach of the Electronic Medical Records (EMR) from an entire large paediatric healthcare network.  The reported frequency of these disorders was the highest between 2 and 5 years old and spanned a spectrum of twenty-six broad speech and language diagnoses. We used Natural Language Processing to assess to which degree clinical diagnosis in full-text notes were reflected in ICD-10 diagnosis codes. We found that aphasia and speech apraxia could be easily retrieved through ICD-10 diagnosis codes, while stuttering as a speech phenotype was only coded in 12% of individuals through appropriate ICD-10 codes. We found significant comorbidity of speech and language disorders in neurodevelopmental conditions (30.31%) and to a lesser degree with epilepsies (6.07%) and movement disorders (2.05%). The most common genetic disorders retrievable in our EMR analysis were STXBP1 (n=21), PTEN (n=20), and CACNA1A (n=18). When assessing associations of genetic diagnoses with specific linguistic phenotypes, we observed associations of STXBP1 and aphasia (P=8.57 x 10-7, CI=18.62-130.39) and MYO7A with speech and language development delay due to hearing loss (P=1.24 x 10-5, CI=17.46-Inf). Finally, in a sub-cohort of 726 individuals with whole exome sequencing data, we identified an enrichment of rare variants in synaptic protein and neuronal receptor pathways and associations of UQCRC1 with expressive aphasia and WASHC4 with abnormality of speech or vocalization.  In summary, our study outlines the landscape of paediatric speech and language disorders, confirming the phenotypic complexity of linguistic traits and novel genotype-phenotype associations. Subgroups of paediatric speech and language disorders differ significantly with respect to the composition of monogenic aetiologies",,"PubMed,medrxiv",,1,,,,,,,FALSE,TRUE,FALSE
311,"The Monarch Initiative in 2024: an analytic platform integrating phenotypes, genes and diseases across species","Bridging the gap between genetic variations, environmental determinants, and phenotypic outcomes is critical for supporting clinical diagnosis and understanding mechanisms of diseases. It requires integrating open data at a global scale. The Monarch Initiative advances these goals by developing open ontologies, semantic data models, and knowledge graphs for translational research. The Monarch App is an integrated platform combining data about genes, phenotypes, and diseases across species. Monarch's APIs enable access to carefully curated datasets and advanced analysis tools that support the understanding and diagnosis of disease for diverse applications such as variant prioritization, deep phenotyping, and patient profile-matching. We have migrated our system into a scalable, cloud-based infrastructure; simplified Monarch's data ingestion and knowledge graph integration systems; enhanced data mapping and integration standards; and developed a new user interface with novel search and graph navigation features. Furthermore, we advanced Monarch's analytic tools by developing a customized plugin for OpenAI's ChatGPT to increase the reliability of its responses about phenotypic data, allowing us to interrogate the knowledge in the Monarch graph using state-of-the-art Large Language Models. The resources of the Monarch Initiative can be found at monarchinitiative.org and its corresponding code repository at github.com/monarch-initiative/monarch-app",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
312,Transfer Learning Of Gene Expression Using Reactome,"AO_SCPLOWBSTRACTC_SCPLOWIn clinical research, translating findings from model organisms to human applications remains challenging due to biological differences between species as well as limitations of orthologous, and homologous, gene comparisons, which is fraugt with information loss as well as many-to-many mapping. To address these issues, we introduce a novel Universal Gene Embedding (UGE) model that leverages transformer-based few-shot learning for species-agnostic transfer learning with heterogeneous domain adaptation. The UGE model, trained on a dataset of gene expression from ten organs across rats and mice, establishes a unified biological latent space that effectively represents genes from any organ or species. By focusing on reactomes--comprehensive profiles of gene expression responses to drugs--the UGE model enables functional gene mapping across species based on the similarities of these profiles. Our contributions include a gene reactome vector prediction module, a robust framework for mapping drug-induced gene expression patterns across species, strategies for optimizing experimental design, and enhanced gene mapping precision. These advancements provide a new tool for genetic research and a new paradigm for cross-species insights, potentially revolutionizing our understanding of gene function, drug responses, and the translation of findings from model organisms to human clinical applications",,biorxiv,,1,,,,,,,FALSE,TRUE,FALSE
313,Uptake of Cancer Genetic Services for Chatbot vs Standard-of-Care Delivery Models: The BRIDGE Randomized Clinical Trial,"Increasing numbers of unaffected individuals could benefit from genetic evaluation for inherited cancer susceptibility. Automated conversational agents (ie, chatbots) are being developed for cancer genetics contexts; however, randomized comparisons with standard of care (SOC) are needed. To examine whether chatbot and SOC approaches are equivalent in completion of pretest cancer genetic services and genetic testing. This equivalence trial (Broadening the Reach, Impact, and Delivery of Genetic Services [BRIDGE] randomized clinical trial) was conducted between August 15, 2020, and August 31, 2023, at 2 US health care systems (University of Utah Health and NYU Langone Health). Participants were aged 25 to 60 years, had had a primary care visit in the previous 3 years, were eligible for cancer genetic evaluation, were English or Spanish speaking, had no prior cancer diagnosis other than nonmelanoma skin cancer, had no prior cancer genetic counseling or testing, and had an electronic patient portal account. Participants were randomized 1:1 at the patient level to the study groups at each site. In the chatbot intervention group, patients were invited in a patient portal outreach message to complete a pretest genetics education chat. In the enhanced SOC control group, patients were invited to complete an SOC pretest appointment with a certified genetic counselor. Primary outcomes were completion of pretest cancer genetic services (ie, pretest genetics education chat or pretest genetic counseling appointment) and completion of genetic testing. Equivalence hypothesis testing was used to compare the study groups. This study included 3073 patients (1554 in the chatbot group and 1519 in the enhanced SOC control group). Their mean (SD) age at outreach was 43.8 (9.9) years, and most (2233 of 3063 [72.9%]) were women. A total of 204 patients (7.3%) were Black, 317 (11.4%) were Latinx, and 2094 (75.0%) were White. The estimated percentage point difference for completion of pretest cancer genetic services between groups was 2.0 (95% CI, -1.1 to 5.0). The estimated percentage point difference for completion of genetic testing was -1.3 (95% CI, -3.7 to 1.1). Analyses suggested equivalence in the primary outcomes. The findings of the BRIDGE equivalence trial support the use of chatbot approaches to offer cancer genetic services. Chatbot tools can be a key component of sustainable and scalable population health management strategies to enhance access to cancer genetic services. ClinicalTrials.gov Identifier: NCT03985852",,PubMed,,1,,,,Chatbot using NLP; ML Task: Cancer genetic service delivery.,Cancer genetic evaluation through chatbot-based education; clinical genetic services.,"Chatbot is as effective as standard care for pretest genetic services, improving access to cancer genetics.",FALSE,TRUE,FALSE
314,Use of topic modeling to assess research trends in the journal Gynecologic Oncology,"There is scant research identifying thematic trends within medical research. This work may provide insight into how a given field values certain topics. We assessed the feasibility of using a machine learning approach to determine the most common research themes published in Gynecologic Oncology over a thirty-year period and to subsequently evaluate how interest in these topics changed over time. We retrieved the abstracts of all original research published in Gynecologic Oncology from 1990 to 2020 using PubMed. Abstract text was processed through a natural language processing algorithm and clustered into topical themes using latent Dirichlet allocation (LDA) prior to manual labeling. Topics were investigated for temporal trends. We retrieved 12,586 original research articles, of which 11,217 were evaluable for subsequent analysis. Twenty-three research topics were selected at the completion of topic modeling. The topics of basic science genetics, epidemiologic methods, and chemotherapy experienced the greatest increase over the time period, while postoperative outcomes, reproductive age cancer management, and cervical dysplasia experienced the greatest decline. Interest in basic science research remained relatively constant. Topics were additionally reviewed for words indicative of either surgical or medical therapy. Both surgical and medical topics saw increasing interest, with surgical topics experiencing a greater increase and representing a higher proportion of published topics. Topic modeling, a type of unsupervised machine learning, was successfully used to identify trends in research themes. The application of this technique provided insight into how the field of gynecologic oncology values the components of its scope of practice and therefore how it may choose to allocate grant funding, disseminate research, and participate in the public discourse",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
315,Using a Natural Language Processing Approach to Support Rapid Knowledge Acquisition,"Implementing artificial intelligence to extract insights from large, real-world clinical data sets can supplement and enhance knowledge management efforts for health sciences research and clinical care. At Vanderbilt University Medical Center (VUMC), the in-house developed Word Cloud natural language processing system extracts coded concepts from patient records in VUMC's electronic health record repository using the Unified Medical Language System terminology. Through this process, the Word Cloud extracts the most prominent concepts found in the clinical documentation of a specific patient or population. The Word Cloud provides added value for clinical care decision-making and research. This viewpoint paper describes a use case for how the VUMC Center for Knowledge Management leverages the condition-disease associations represented by the Word Cloud to aid in the knowledge generation needed to inform the interpretation of phenome-wide association studies",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE
316,Using LLMs to label medical papers according to the CIViC evidence model,"We introduce the sequence classification problem CIViC Evidence to the field of medical NLP. CIViC Evidence denotes the multi-label classification problem of assigning labels of clinical evidence to abstracts of scientific papers which have examined various combinations of genomic variants, cancer types, and treatment approaches. We approach CIViC Evidence using different language models: We fine-tune pretrained checkpoints of BERT and RoBERTa on the CIViC Evidence dataset and challenge their performance with models of the same architecture which have been pretrained on domain-specific text. In this context, we find that BiomedBERT and BioLinkBERT can outperform BERT on CIViC Evidence (+0.8% and +0.9% absolute improvement in class-support weighted F1 score). All transformer-based models show a clear performance edge when compared to a logistic regression trained on bigram tf-idf scores (+1.5 - 2.7% improved F1 score). We compare the aforementioned BERT-like models to OpenAI's GPT-4 in a few-shot setting (on a small subset of our original test dataset), demonstrating that, without additional prompt-engineering or fine-tuning, GPT-4 performs worse on CIViC Evidence than our six fine-tuned models (66.1% weighted F1 score compared to 71.8% for the best fine-tuned model). However, performance gets reasonably close to the benchmark of a logistic regression model trained on bigram tf-idf scores (67.7% weighted F1 score)",,arXiv,,1,,,,"BERT, RoBERTa, BioMedBERT, BioLinkBERT, GPT-4; ML Task: Multi-label classification of scientific paper abstracts (sequence classification).","Classification of clinical evidence related to genomic variants, cancer types, and treatments.",Fine-tuned BERT-based models outperform GPT-4 in labeling medical papers for CIViC evidence classification.,FALSE,TRUE,FALSE
317,"Virtual Labs and Designer Bugs - Generative AI, Synthetic Biology and National Security","AI technologies can pose a major national security concern. AI programs could be used to develop chemical and biological agents which circumvent existing protective measures or medical treatments, or to design pathogens with capabilities they do not naturally possess (gain-of-function research). Although Australia has a strong legislative framework relating to research into genetically modified organisms, the framework requires the interaction of more than 10 different government departments, universities and funding agencies. Further, there are few guidelines about the responsible use of AI in biological research where existing laws and policies do not apply to research that is conducted ""virtually"", even where that research may have national security implications. This article explores these under-scrutinised concepts in Australia's biological security frameworks",,PubMed,,1,,,,No specific transformer-based models like GPT or BERT mentioned.,Genetic research with a focus on synthetic biology and security implications; related to the design of pathogens (gain-of-function research).,"AI's role in genetic research and biological security, emphasizing synthetic biology and national security risks.",FALSE,TRUE,FALSE
318,ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy,"Large-scale cell microscopy screens are used in drug discovery and molecular biology research to study the effects of millions of chemical and genetic perturbations on cells. To use these images in downstream analysis, we need models that can map each image into a feature space that represents diverse biological phenotypes consistently, in the sense that perturbations with similar biological effects have similar representations. In this work, we present the largest foundation model for cell microscopy data to date, a new 1.9 billion-parameter ViT-G/8 MAE trained on over 8 billion microscopy image crops. Compared to a previous published ViT-L/8 MAE, our new model achieves a 60% improvement in linear separability of genetic perturbations and obtains the best overall performance on whole-genome biological relationship recall and replicate consistency benchmarks. Beyond scaling, we developed two key methods that improve performance: (1) training on a curated and diverse dataset; and, (2) using biologically motivated linear probing tasks to search across each transformer block for the best candidate representation of whole-genome screens. We find that many self-supervised vision transformers, pretrained on either natural or microscopy images, yield significantly more biologically meaningful representations of microscopy images in their intermediate blocks than in their typically used final blocks. More broadly, our approach and results provide insights toward a general strategy for successfully building foundation models for large-scale biological data",,arXiv,,1,,,,,,,FALSE,TRUE,FALSE
320,Z-flipon variants reveal the many roles of Z-DNA and Z-RNA in health and disease,"Identifying roles for Z-DNA remains challenging given their dynamic nature. Here, we perform genome-wide interrogation with the DNABERT transformer algorithm trained on experimentally identified Z-DNA forming sequences (Z-flipons). The algorithm yields large performance enhancements (F1 = 0.83) over existing approaches and implements computational mutagenesis to assess the effects of base substitution on Z-DNA formation. We show Z-flipons are enriched in promoters and telomeres, overlapping quantitative trait loci for RNA expression, RNA editing, splicing, and disease-associated variants. We cross-validate across a number of orthogonal databases and define BZ junction motifs. Surprisingly, many effects we delineate are likely mediated through Z-RNA formation. A shared Z-RNA motif is identified in SCARF2, SMAD1, and CACNA1 transcripts, whereas other motifs are present in noncoding RNAs. We provide evidence for a Z-RNA fold that promotes adaptive immunity through alternative splicing of KRAB domain zinc finger proteins. An analysis of OMIM and presumptive gnomAD loss-of-function datasets reveals an overlap of Z-flipons with disease-causing variants in 8.6% and 2.9% of Mendelian disease genes, respectively, greatly extending the range of phenotypes mapped to Z-flipons",,PubMed,,1,,,,,,,FALSE,TRUE,FALSE